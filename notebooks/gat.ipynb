{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : False,\n",
    "    \n",
    "    \"duplicate_examples\" : True,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : True,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GAT\",\n",
    "    \"num_heads\" : [8, 1],\n",
    "    \"hidden_dims\" : [8],\n",
    "    \"dropout\" : 0.6,\n",
    "    \n",
    "    \"epochs\" : 50,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 5e-4,\n",
    "    \"weight_decay\" : 1e-3,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : False,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 2048\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (attn): ModuleList(\n",
      "    (0): GraphAttention(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Linear(in_features=274, out_features=8, bias=True)\n",
      "        (1): Linear(in_features=274, out_features=8, bias=True)\n",
      "        (2): Linear(in_features=274, out_features=8, bias=True)\n",
      "        (3): Linear(in_features=274, out_features=8, bias=True)\n",
      "        (4): Linear(in_features=274, out_features=8, bias=True)\n",
      "        (5): Linear(in_features=274, out_features=8, bias=True)\n",
      "        (6): Linear(in_features=274, out_features=8, bias=True)\n",
      "        (7): Linear(in_features=274, out_features=8, bias=True)\n",
      "      )\n",
      "      (a): ModuleList(\n",
      "        (0): Linear(in_features=16, out_features=1, bias=True)\n",
      "        (1): Linear(in_features=16, out_features=1, bias=True)\n",
      "        (2): Linear(in_features=16, out_features=1, bias=True)\n",
      "        (3): Linear(in_features=16, out_features=1, bias=True)\n",
      "        (4): Linear(in_features=16, out_features=1, bias=True)\n",
      "        (5): Linear(in_features=16, out_features=1, bias=True)\n",
      "        (6): Linear(in_features=16, out_features=1, bias=True)\n",
      "        (7): Linear(in_features=16, out_features=1, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.6)\n",
      "      (softmax): Softmax()\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): GraphAttention(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "      )\n",
      "      (a): ModuleList(\n",
      "        (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0.6)\n",
      "      (softmax): Softmax()\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.6)\n",
      "  (elu): ELU(alpha=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.GAT(input_dim, config['hidden_dims'],\n",
    "                   output_dim, config['num_heads'],\n",
    "                   config['dropout'], config['device'])\n",
    "model.to(config['device'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "ROC-AUC score: 0.7099\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 50\n",
      "    Batch 3 / 354: loss 0.6930\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 6 / 354: loss 0.6925\n",
      "    ROC-AUC score: 0.3455\n",
      "    Batch 9 / 354: loss 0.6928\n",
      "    ROC-AUC score: 0.8583\n",
      "    Batch 12 / 354: loss 0.6923\n",
      "    ROC-AUC score: 0.7363\n",
      "    Batch 15 / 354: loss 0.6931\n",
      "    ROC-AUC score: 0.9109\n",
      "    Batch 18 / 354: loss 0.6926\n",
      "    ROC-AUC score: 0.5972\n",
      "    Batch 21 / 354: loss 0.7008\n",
      "    ROC-AUC score: 0.5992\n",
      "    Batch 24 / 354: loss 0.6925\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 354: loss 0.6904\n",
      "    ROC-AUC score: 0.2667\n",
      "    Batch 30 / 354: loss 0.6944\n",
      "    ROC-AUC score: 0.5425\n",
      "    Batch 33 / 354: loss 0.6929\n",
      "    ROC-AUC score: 0.9211\n",
      "    Batch 36 / 354: loss 0.6930\n",
      "    ROC-AUC score: 0.7686\n",
      "    Batch 39 / 354: loss 0.6938\n",
      "    ROC-AUC score: 0.8482\n",
      "    Batch 42 / 354: loss 0.6924\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 45 / 354: loss 0.6924\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 48 / 354: loss 0.6958\n",
      "    ROC-AUC score: 0.6875\n",
      "    Batch 51 / 354: loss 0.6924\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 54 / 354: loss 0.6924\n",
      "    ROC-AUC score: 0.6562\n",
      "    Batch 57 / 354: loss 0.6929\n",
      "    ROC-AUC score: 0.7996\n",
      "    Batch 60 / 354: loss 0.6921\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 63 / 354: loss 0.6925\n",
      "    ROC-AUC score: 0.5176\n",
      "    Batch 66 / 354: loss 0.6926\n",
      "    ROC-AUC score: 0.6944\n",
      "    Batch 69 / 354: loss 0.6931\n",
      "    ROC-AUC score: 0.7031\n",
      "    Batch 72 / 354: loss 0.6928\n",
      "    ROC-AUC score: 0.4375\n",
      "    Batch 75 / 354: loss 0.6928\n",
      "    ROC-AUC score: 0.6699\n",
      "    Batch 78 / 354: loss 0.6918\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 81 / 354: loss 0.6927\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 84 / 354: loss 0.6915\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 87 / 354: loss 0.6912\n",
      "    ROC-AUC score: 0.5853\n",
      "    Batch 90 / 354: loss 0.6921\n",
      "    ROC-AUC score: 0.7917\n",
      "    Batch 93 / 354: loss 0.6910\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 354: loss 0.6903\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 99 / 354: loss 0.6906\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 102 / 354: loss 0.6913\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 105 / 354: loss 0.6915\n",
      "    ROC-AUC score: 0.7617\n",
      "    Batch 108 / 354: loss 0.6905\n",
      "    ROC-AUC score: 0.8438\n",
      "    Batch 111 / 354: loss 0.6924\n",
      "    ROC-AUC score: 0.8393\n",
      "    Batch 114 / 354: loss 0.6854\n",
      "    ROC-AUC score: 0.8250\n",
      "    Batch 117 / 354: loss 0.6883\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 120 / 354: loss 0.6888\n",
      "    ROC-AUC score: 0.8672\n",
      "    Batch 123 / 354: loss 0.6888\n",
      "    ROC-AUC score: 0.8659\n",
      "    Batch 126 / 354: loss 0.6833\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 129 / 354: loss 0.6762\n",
      "    ROC-AUC score: 0.9083\n",
      "    Batch 132 / 354: loss 0.6799\n",
      "    ROC-AUC score: 0.7833\n",
      "    Batch 135 / 354: loss 0.6828\n",
      "    ROC-AUC score: 0.9667\n",
      "    Batch 138 / 354: loss 0.6828\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 141 / 354: loss 0.6747\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 144 / 354: loss 0.6822\n",
      "    ROC-AUC score: 0.8375\n",
      "    Batch 147 / 354: loss 0.6708\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 150 / 354: loss 0.6795\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 153 / 354: loss 0.6736\n",
      "    ROC-AUC score: 0.8294\n",
      "    Batch 156 / 354: loss 0.6742\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 159 / 354: loss 0.6697\n",
      "    ROC-AUC score: 0.8543\n",
      "    Batch 162 / 354: loss 0.6740\n",
      "    ROC-AUC score: 0.8259\n",
      "    Batch 165 / 354: loss 0.6780\n",
      "    ROC-AUC score: 0.9118\n",
      "    Batch 168 / 354: loss 0.6712\n",
      "    ROC-AUC score: 0.8182\n",
      "    Batch 171 / 354: loss 0.6933\n",
      "    ROC-AUC score: 0.8320\n",
      "    Batch 174 / 354: loss 0.6635\n",
      "    ROC-AUC score: 0.9043\n",
      "    Batch 177 / 354: loss 0.6655\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 180 / 354: loss 0.6628\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 183 / 354: loss 0.6541\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 186 / 354: loss 0.6576\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 189 / 354: loss 0.6524\n",
      "    ROC-AUC score: 0.8300\n",
      "    Batch 192 / 354: loss 0.6301\n",
      "    ROC-AUC score: 0.8613\n",
      "    Batch 195 / 354: loss 0.6593\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 198 / 354: loss 0.6617\n",
      "    ROC-AUC score: 0.8828\n",
      "    Batch 201 / 354: loss 0.6626\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 204 / 354: loss 0.6483\n",
      "    ROC-AUC score: 0.8441\n",
      "    Batch 207 / 354: loss 0.6575\n",
      "    ROC-AUC score: 0.8535\n",
      "    Batch 210 / 354: loss 0.6550\n",
      "    ROC-AUC score: 0.9246\n",
      "    Batch 213 / 354: loss 0.6412\n",
      "    ROC-AUC score: 0.7935\n",
      "    Batch 216 / 354: loss 0.6390\n",
      "    ROC-AUC score: 0.8178\n",
      "    Batch 219 / 354: loss 0.6419\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 222 / 354: loss 0.5907\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 225 / 354: loss 0.6709\n",
      "    ROC-AUC score: 0.9057\n",
      "    Batch 228 / 354: loss 0.5916\n",
      "    ROC-AUC score: 0.9517\n",
      "    Batch 231 / 354: loss 0.5819\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 234 / 354: loss 0.6160\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 237 / 354: loss 0.6466\n",
      "    ROC-AUC score: 0.8496\n",
      "    Batch 240 / 354: loss 0.6534\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 243 / 354: loss 0.6208\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 246 / 354: loss 0.5846\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 249 / 354: loss 0.5578\n",
      "    ROC-AUC score: 0.9542\n",
      "    Batch 252 / 354: loss 0.6053\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 255 / 354: loss 0.5875\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 258 / 354: loss 0.5508\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 261 / 354: loss 0.5812\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 264 / 354: loss 0.5710\n",
      "    ROC-AUC score: 0.7545\n",
      "    Batch 267 / 354: loss 0.5709\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 270 / 354: loss 0.6321\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 273 / 354: loss 0.5613\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 276 / 354: loss 0.6622\n",
      "    ROC-AUC score: 0.9042\n",
      "    Batch 279 / 354: loss 0.5716\n",
      "    ROC-AUC score: 0.9707\n",
      "    Batch 282 / 354: loss 0.5249\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 285 / 354: loss 0.6399\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 288 / 354: loss 0.5691\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 291 / 354: loss 0.5758\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 294 / 354: loss 0.6127\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 297 / 354: loss 0.5901\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 300 / 354: loss 0.6458\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 303 / 354: loss 0.5516\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 306 / 354: loss 0.5477\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 309 / 354: loss 0.6535\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 312 / 354: loss 0.6040\n",
      "    ROC-AUC score: 0.6333\n",
      "    Batch 315 / 354: loss 0.6490\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 318 / 354: loss 0.4843\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 321 / 354: loss 0.4936\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 324 / 354: loss 0.5537\n",
      "    ROC-AUC score: 0.9777\n",
      "    Batch 327 / 354: loss 0.5968\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 330 / 354: loss 0.5850\n",
      "    ROC-AUC score: 0.8627\n",
      "    Batch 333 / 354: loss 0.5958\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 336 / 354: loss 0.5666\n",
      "    ROC-AUC score: 0.8259\n",
      "    Batch 339 / 354: loss 0.5239\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 342 / 354: loss 0.5433\n",
      "    ROC-AUC score: 0.9549\n",
      "    Batch 345 / 354: loss 0.5858\n",
      "    ROC-AUC score: 0.9663\n",
      "    Batch 348 / 354: loss 0.5811\n",
      "    ROC-AUC score: 0.9121\n",
      "    Batch 351 / 354: loss 0.5646\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 354 / 354: loss 0.4929\n",
      "    ROC-AUC score: 1.0000\n",
      "Epoch 2 / 50\n",
      "    Batch 3 / 354: loss 0.5748\n",
      "    ROC-AUC score: 0.9771\n",
      "    Batch 6 / 354: loss 0.5287\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 9 / 354: loss 0.5879\n",
      "    ROC-AUC score: 0.8680\n",
      "    Batch 12 / 354: loss 0.5107\n",
      "    ROC-AUC score: 0.9089\n",
      "    Batch 15 / 354: loss 0.5658\n",
      "    ROC-AUC score: 0.7619\n",
      "    Batch 18 / 354: loss 0.5890\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 21 / 354: loss 0.6695\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 24 / 354: loss 0.6162\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 27 / 354: loss 0.5294\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 30 / 354: loss 0.7461\n",
      "    ROC-AUC score: 0.9104\n",
      "    Batch 33 / 354: loss 0.4792\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 36 / 354: loss 0.6509\n",
      "    ROC-AUC score: 0.7313\n",
      "    Batch 39 / 354: loss 0.5129\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 42 / 354: loss 0.6144\n",
      "    ROC-AUC score: 0.9125\n",
      "    Batch 45 / 354: loss 0.6077\n",
      "    ROC-AUC score: 0.7902\n",
      "    Batch 48 / 354: loss 0.6049\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 51 / 354: loss 0.6443\n",
      "    ROC-AUC score: 0.7961\n",
      "    Batch 54 / 354: loss 0.6421\n",
      "    ROC-AUC score: 0.8194\n",
      "    Batch 57 / 354: loss 0.5470\n",
      "    ROC-AUC score: 0.7817\n",
      "    Batch 60 / 354: loss 0.5097\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 63 / 354: loss 0.5389\n",
      "    ROC-AUC score: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 66 / 354: loss 0.5735\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 69 / 354: loss 0.5231\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 72 / 354: loss 0.5662\n",
      "    ROC-AUC score: 0.9667\n",
      "    Batch 75 / 354: loss 0.4763\n",
      "    ROC-AUC score: 0.9706\n",
      "    Batch 78 / 354: loss 0.5520\n",
      "    ROC-AUC score: 0.8115\n",
      "    Batch 81 / 354: loss 0.5258\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 84 / 354: loss 0.4921\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 87 / 354: loss 0.5935\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 90 / 354: loss 0.5156\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 93 / 354: loss 0.5455\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 96 / 354: loss 0.5557\n",
      "    ROC-AUC score: 0.7734\n",
      "    Batch 99 / 354: loss 0.5645\n",
      "    ROC-AUC score: 0.9118\n",
      "    Batch 102 / 354: loss 0.5724\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 105 / 354: loss 0.5303\n",
      "    ROC-AUC score: 0.8441\n",
      "    Batch 108 / 354: loss 0.5667\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 111 / 354: loss 0.4442\n",
      "    ROC-AUC score: 0.8682\n",
      "    Batch 114 / 354: loss 0.4965\n",
      "    ROC-AUC score: 0.8268\n",
      "    Batch 117 / 354: loss 0.5579\n",
      "    ROC-AUC score: 0.9565\n",
      "    Batch 120 / 354: loss 0.5342\n",
      "    ROC-AUC score: 0.8392\n",
      "    Batch 123 / 354: loss 0.5535\n",
      "    ROC-AUC score: 0.8988\n",
      "    Batch 126 / 354: loss 0.5944\n",
      "    ROC-AUC score: 0.7956\n",
      "    Batch 129 / 354: loss 0.5943\n",
      "    ROC-AUC score: 0.8708\n",
      "    Batch 132 / 354: loss 0.4996\n",
      "    ROC-AUC score: 0.7344\n",
      "    Batch 135 / 354: loss 0.5199\n",
      "    ROC-AUC score: 0.8684\n",
      "    Batch 138 / 354: loss 0.5612\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 141 / 354: loss 0.5034\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 144 / 354: loss 0.5357\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 147 / 354: loss 0.4729\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 150 / 354: loss 0.5820\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 153 / 354: loss 0.5072\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 156 / 354: loss 0.4963\n",
      "    ROC-AUC score: 0.8196\n",
      "    Batch 159 / 354: loss 0.6903\n",
      "    ROC-AUC score: 0.8948\n",
      "    Batch 162 / 354: loss 0.6782\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 165 / 354: loss 0.7092\n",
      "    ROC-AUC score: 0.8433\n",
      "    Batch 168 / 354: loss 0.4776\n",
      "    ROC-AUC score: 0.8866\n",
      "    Batch 171 / 354: loss 0.6109\n",
      "    ROC-AUC score: 0.8021\n",
      "    Batch 174 / 354: loss 0.5948\n",
      "    ROC-AUC score: 0.8219\n",
      "    Batch 177 / 354: loss 0.5952\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 180 / 354: loss 0.5919\n",
      "    ROC-AUC score: 0.7542\n",
      "    Batch 183 / 354: loss 0.6673\n",
      "    ROC-AUC score: 0.6944\n",
      "    Batch 186 / 354: loss 0.5517\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 189 / 354: loss 0.7116\n",
      "    ROC-AUC score: 0.7222\n",
      "    Batch 192 / 354: loss 0.5737\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 195 / 354: loss 0.6059\n",
      "    ROC-AUC score: 0.8375\n",
      "    Batch 198 / 354: loss 0.5791\n",
      "    ROC-AUC score: 0.8671\n",
      "    Batch 201 / 354: loss 0.4925\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 204 / 354: loss 0.5173\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 207 / 354: loss 0.5259\n",
      "    ROC-AUC score: 0.9130\n",
      "    Batch 210 / 354: loss 0.6189\n",
      "    ROC-AUC score: 0.9121\n",
      "    Batch 213 / 354: loss 0.5019\n",
      "    ROC-AUC score: 0.9238\n",
      "    Batch 216 / 354: loss 0.5106\n",
      "    ROC-AUC score: 0.9211\n",
      "    Batch 219 / 354: loss 0.4798\n",
      "    ROC-AUC score: 0.9226\n",
      "    Batch 222 / 354: loss 0.4747\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 225 / 354: loss 0.4800\n",
      "    ROC-AUC score: 0.9392\n",
      "    Batch 228 / 354: loss 0.5465\n",
      "    ROC-AUC score: 0.8343\n",
      "    Batch 231 / 354: loss 0.6684\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 234 / 354: loss 0.4599\n",
      "    ROC-AUC score: 0.8355\n",
      "    Batch 237 / 354: loss 0.5847\n",
      "    ROC-AUC score: 0.9118\n",
      "    Batch 240 / 354: loss 0.5440\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 243 / 354: loss 0.6193\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 246 / 354: loss 0.5378\n",
      "    ROC-AUC score: 0.8651\n",
      "    Batch 249 / 354: loss 0.4860\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 252 / 354: loss 0.5970\n",
      "    ROC-AUC score: 0.7632\n",
      "    Batch 255 / 354: loss 0.5089\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 258 / 354: loss 0.5621\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 261 / 354: loss 0.5339\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 264 / 354: loss 0.5047\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 267 / 354: loss 0.5835\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 270 / 354: loss 0.9069\n",
      "    ROC-AUC score: 0.8810\n",
      "    Batch 273 / 354: loss 0.5634\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 276 / 354: loss 0.5467\n",
      "    ROC-AUC score: 0.9458\n",
      "    Batch 279 / 354: loss 0.4850\n",
      "    ROC-AUC score: 0.9903\n",
      "    Batch 282 / 354: loss 0.6016\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 285 / 354: loss 0.6654\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 288 / 354: loss 0.5786\n",
      "    ROC-AUC score: 0.8841\n",
      "    Batch 291 / 354: loss 0.7578\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 294 / 354: loss 0.5324\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 297 / 354: loss 0.5662\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 300 / 354: loss 0.5392\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 303 / 354: loss 0.5965\n",
      "    ROC-AUC score: 0.9121\n",
      "    Batch 306 / 354: loss 0.5985\n",
      "    ROC-AUC score: 0.8187\n",
      "    Batch 309 / 354: loss 0.5444\n",
      "    ROC-AUC score: 0.8846\n",
      "    Batch 312 / 354: loss 0.5602\n",
      "    ROC-AUC score: 0.8979\n",
      "    Batch 315 / 354: loss 0.4794\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 318 / 354: loss 0.5857\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 321 / 354: loss 0.5119\n",
      "    ROC-AUC score: 0.7857\n",
      "    Batch 324 / 354: loss 0.6802\n",
      "    ROC-AUC score: 0.7738\n",
      "    Batch 327 / 354: loss 0.5846\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 330 / 354: loss 0.5390\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 333 / 354: loss 0.5272\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 336 / 354: loss 0.5422\n",
      "    ROC-AUC score: 0.9706\n",
      "    Batch 339 / 354: loss 0.5371\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 342 / 354: loss 0.6459\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 345 / 354: loss 0.6536\n",
      "    ROC-AUC score: 0.7773\n",
      "    Batch 348 / 354: loss 0.6425\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 351 / 354: loss 0.4870\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 354 / 354: loss 0.5174\n",
      "    ROC-AUC score: 0.5000\n",
      "Epoch 3 / 50\n",
      "    Batch 3 / 354: loss 0.5656\n",
      "    ROC-AUC score: 0.8355\n",
      "    Batch 6 / 354: loss 0.5065\n",
      "    ROC-AUC score: 0.8167\n",
      "    Batch 9 / 354: loss 0.5375\n",
      "    ROC-AUC score: 0.8603\n",
      "    Batch 12 / 354: loss 0.5631\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 15 / 354: loss 0.6774\n",
      "    ROC-AUC score: 0.9750\n",
      "    Batch 18 / 354: loss 0.5483\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 21 / 354: loss 0.4921\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 24 / 354: loss 0.4640\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 27 / 354: loss 0.5658\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 30 / 354: loss 0.5706\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 33 / 354: loss 0.4783\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 36 / 354: loss 0.5548\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 39 / 354: loss 0.6105\n",
      "    ROC-AUC score: 0.9534\n",
      "    Batch 42 / 354: loss 0.5671\n",
      "    ROC-AUC score: 0.9121\n",
      "    Batch 45 / 354: loss 0.6035\n",
      "    ROC-AUC score: 0.7765\n",
      "    Batch 48 / 354: loss 0.7028\n",
      "    ROC-AUC score: 0.7449\n",
      "    Batch 51 / 354: loss 0.6251\n",
      "    ROC-AUC score: 0.7715\n",
      "    Batch 54 / 354: loss 0.4776\n",
      "    ROC-AUC score: 0.8438\n",
      "    Batch 57 / 354: loss 0.5617\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 60 / 354: loss 0.5128\n",
      "    ROC-AUC score: 0.7705\n",
      "    Batch 63 / 354: loss 0.5354\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 66 / 354: loss 0.6084\n",
      "    ROC-AUC score: 0.9458\n",
      "    Batch 69 / 354: loss 0.5272\n",
      "    ROC-AUC score: 0.9318\n",
      "    Batch 72 / 354: loss 0.4786\n",
      "    ROC-AUC score: 0.7784\n",
      "    Batch 75 / 354: loss 0.6049\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 78 / 354: loss 0.5153\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 81 / 354: loss 0.6413\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 84 / 354: loss 0.6367\n",
      "    ROC-AUC score: 0.8684\n",
      "    Batch 87 / 354: loss 0.5147\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 354: loss 0.5428\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 93 / 354: loss 0.6467\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 96 / 354: loss 0.5068\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 99 / 354: loss 0.6172\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 102 / 354: loss 0.5375\n",
      "    ROC-AUC score: 0.8792\n",
      "    Batch 105 / 354: loss 0.5833\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 108 / 354: loss 0.5392\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 111 / 354: loss 0.4704\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 114 / 354: loss 0.5370\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 117 / 354: loss 0.4990\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 120 / 354: loss 0.6044\n",
      "    ROC-AUC score: 0.7996\n",
      "    Batch 123 / 354: loss 0.6067\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 126 / 354: loss 0.5222\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 129 / 354: loss 0.4884\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 132 / 354: loss 0.6476\n",
      "    ROC-AUC score: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 135 / 354: loss 0.4511\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 138 / 354: loss 0.4750\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 141 / 354: loss 0.5751\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 144 / 354: loss 0.5281\n",
      "    ROC-AUC score: 0.7686\n",
      "    Batch 147 / 354: loss 0.6065\n",
      "    ROC-AUC score: 0.9686\n",
      "    Batch 150 / 354: loss 0.5237\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 153 / 354: loss 0.4908\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 156 / 354: loss 0.5876\n",
      "    ROC-AUC score: 0.8381\n",
      "    Batch 159 / 354: loss 0.5737\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 162 / 354: loss 0.4474\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 165 / 354: loss 0.5557\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 168 / 354: loss 0.4783\n",
      "    ROC-AUC score: 0.8047\n",
      "    Batch 171 / 354: loss 0.6109\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 174 / 354: loss 0.5802\n",
      "    ROC-AUC score: 0.9277\n",
      "    Batch 177 / 354: loss 0.5351\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 180 / 354: loss 0.5984\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 183 / 354: loss 0.6401\n",
      "    ROC-AUC score: 0.8867\n",
      "    Batch 186 / 354: loss 0.5332\n",
      "    ROC-AUC score: 0.8353\n",
      "    Batch 189 / 354: loss 0.6570\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 192 / 354: loss 0.5794\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 195 / 354: loss 0.5890\n",
      "    ROC-AUC score: 0.8516\n",
      "    Batch 198 / 354: loss 0.5840\n",
      "    ROC-AUC score: 0.9004\n",
      "    Batch 201 / 354: loss 0.5677\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 204 / 354: loss 0.5401\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 207 / 354: loss 0.4970\n",
      "    ROC-AUC score: 0.7917\n",
      "    Batch 210 / 354: loss 0.5336\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 213 / 354: loss 0.5391\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 216 / 354: loss 0.5412\n",
      "    ROC-AUC score: 0.9251\n",
      "    Batch 219 / 354: loss 0.5106\n",
      "    ROC-AUC score: 0.8804\n",
      "    Batch 222 / 354: loss 0.5001\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 225 / 354: loss 0.8148\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 228 / 354: loss 0.4945\n",
      "    ROC-AUC score: 0.9737\n",
      "    Batch 231 / 354: loss 0.5449\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 234 / 354: loss 0.6100\n",
      "    ROC-AUC score: 0.8421\n",
      "    Batch 237 / 354: loss 0.5748\n",
      "    ROC-AUC score: 0.8918\n",
      "    Batch 240 / 354: loss 0.5420\n",
      "    ROC-AUC score: 0.9394\n",
      "    Batch 243 / 354: loss 0.4815\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 246 / 354: loss 0.5690\n",
      "    ROC-AUC score: 0.9614\n",
      "    Batch 249 / 354: loss 0.5644\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 252 / 354: loss 0.5770\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 255 / 354: loss 0.5347\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 258 / 354: loss 0.5371\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 261 / 354: loss 0.5153\n",
      "    ROC-AUC score: 0.9345\n",
      "    Batch 264 / 354: loss 0.5067\n",
      "    ROC-AUC score: 0.9157\n",
      "    Batch 267 / 354: loss 0.5027\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 270 / 354: loss 0.5681\n",
      "    ROC-AUC score: 0.7923\n",
      "    Batch 273 / 354: loss 0.4958\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 276 / 354: loss 0.5518\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 279 / 354: loss 0.5548\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 282 / 354: loss 0.5333\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 285 / 354: loss 0.5839\n",
      "    ROC-AUC score: 0.7895\n",
      "    Batch 288 / 354: loss 0.5333\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 291 / 354: loss 0.4646\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 294 / 354: loss 0.5924\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 297 / 354: loss 0.5725\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 300 / 354: loss 0.5380\n",
      "    ROC-AUC score: 0.9773\n",
      "    Batch 303 / 354: loss 0.5180\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 306 / 354: loss 0.5384\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 309 / 354: loss 0.6321\n",
      "    ROC-AUC score: 0.8294\n",
      "    Batch 312 / 354: loss 0.5164\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 315 / 354: loss 0.5290\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 318 / 354: loss 0.5742\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 321 / 354: loss 0.5964\n",
      "    ROC-AUC score: 0.9190\n",
      "    Batch 324 / 354: loss 0.5231\n",
      "    ROC-AUC score: 0.8281\n",
      "    Batch 327 / 354: loss 0.5586\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 330 / 354: loss 0.5350\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 333 / 354: loss 0.5264\n",
      "    ROC-AUC score: 0.8214\n",
      "    Batch 336 / 354: loss 0.5606\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 339 / 354: loss 0.6239\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 342 / 354: loss 0.6705\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 345 / 354: loss 0.4859\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 348 / 354: loss 0.5394\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 351 / 354: loss 0.5003\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 354 / 354: loss 0.5527\n",
      "Epoch 4 / 50\n",
      "    Batch 3 / 354: loss 0.5798\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 6 / 354: loss 0.5640\n",
      "    ROC-AUC score: 0.8636\n",
      "    Batch 9 / 354: loss 0.6124\n",
      "    ROC-AUC score: 0.8393\n",
      "    Batch 12 / 354: loss 0.4927\n",
      "    ROC-AUC score: 0.9568\n",
      "    Batch 15 / 354: loss 0.5562\n",
      "    ROC-AUC score: 0.8175\n",
      "    Batch 18 / 354: loss 0.4541\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 21 / 354: loss 0.5706\n",
      "    ROC-AUC score: 0.8562\n",
      "    Batch 24 / 354: loss 0.6790\n",
      "    ROC-AUC score: 0.6157\n",
      "    Batch 27 / 354: loss 0.5038\n",
      "    ROC-AUC score: 0.9782\n",
      "    Batch 30 / 354: loss 0.8011\n",
      "    ROC-AUC score: 0.6840\n",
      "    Batch 33 / 354: loss 0.5022\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 36 / 354: loss 0.5250\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 39 / 354: loss 0.4583\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 42 / 354: loss 0.7125\n",
      "    ROC-AUC score: 0.9118\n",
      "    Batch 45 / 354: loss 0.5321\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 48 / 354: loss 0.5688\n",
      "    ROC-AUC score: 0.9545\n",
      "    Batch 51 / 354: loss 0.5690\n",
      "    ROC-AUC score: 0.8810\n",
      "    Batch 54 / 354: loss 0.4184\n",
      "    ROC-AUC score: 0.9706\n",
      "    Batch 57 / 354: loss 0.5250\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 60 / 354: loss 0.7292\n",
      "    ROC-AUC score: 0.9118\n",
      "    Batch 63 / 354: loss 0.5368\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 66 / 354: loss 0.5174\n",
      "    ROC-AUC score: 0.9648\n",
      "    Batch 69 / 354: loss 0.4787\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 72 / 354: loss 0.5063\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 75 / 354: loss 0.5416\n",
      "    ROC-AUC score: 0.8235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-70aa9c2cf8b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mall_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=400, gamma=0.8)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 300], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "ROC-AUC score: 0.8883\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "Threshold: 0.0128, accuracy: 0.8898\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.90      5649\n",
      "         1.0       0.94      0.84      0.88      5649\n",
      "\n",
      "    accuracy                           0.89     11298\n",
      "   macro avg       0.89      0.89      0.89     11298\n",
      "weighted avg       0.89      0.89      0.89     11298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 14100\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 441: loss 0.5405, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 6 / 441: loss 0.5064, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 9 / 441: loss 0.5989, accuracy 0.6458\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 441: loss 0.5988, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 15 / 441: loss 0.5362, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 18 / 441: loss 0.4884, accuracy 0.7292\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 441: loss 0.5786, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 24 / 441: loss 0.5771, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9883\n",
      "    Batch 27 / 441: loss 0.5252, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 30 / 441: loss 0.5818, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9610\n",
      "    Batch 33 / 441: loss 0.5637, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 36 / 441: loss 0.5703, accuracy 0.6875\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 39 / 441: loss 0.5589, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 42 / 441: loss 0.5635, accuracy 0.6979\n",
      "    ROC-AUC score: 0.7738\n",
      "    Batch 45 / 441: loss 0.5236, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9227\n",
      "    Batch 48 / 441: loss 0.5569, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 51 / 441: loss 0.5865, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9219\n",
      "    Batch 54 / 441: loss 0.4090, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 57 / 441: loss 0.5049, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 60 / 441: loss 0.5771, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 63 / 441: loss 0.5714, accuracy 0.6875\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 66 / 441: loss 0.4669, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9883\n",
      "    Batch 69 / 441: loss 0.5896, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 72 / 441: loss 0.5782, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 75 / 441: loss 0.5377, accuracy 0.7083\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 78 / 441: loss 0.5367, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 81 / 441: loss 0.4856, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 84 / 441: loss 0.6503, accuracy 0.6875\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 87 / 441: loss 0.5113, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 90 / 441: loss 0.5588, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9409\n",
      "    Batch 93 / 441: loss 0.4802, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 96 / 441: loss 0.5749, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 99 / 441: loss 0.5170, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 102 / 441: loss 0.6271, accuracy 0.6042\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 105 / 441: loss 0.6301, accuracy 0.6458\n",
      "    ROC-AUC score: 0.9952\n",
      "    Batch 108 / 441: loss 0.6197, accuracy 0.6979\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 111 / 441: loss 0.5318, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8532\n",
      "    Batch 114 / 441: loss 0.6622, accuracy 0.6146\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 117 / 441: loss 0.5273, accuracy 0.6979\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 120 / 441: loss 0.5875, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 123 / 441: loss 0.5356, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 126 / 441: loss 0.5750, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 129 / 441: loss 0.4876, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 132 / 441: loss 0.5557, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9273\n",
      "    Batch 135 / 441: loss 0.5327, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 138 / 441: loss 0.5593, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8364\n",
      "    Batch 141 / 441: loss 0.6361, accuracy 0.6667\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 144 / 441: loss 0.5650, accuracy 0.6979\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 147 / 441: loss 0.5658, accuracy 0.7083\n",
      "    ROC-AUC score: 0.7958\n",
      "    Batch 150 / 441: loss 0.5029, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 153 / 441: loss 0.4896, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8542\n",
      "    Batch 156 / 441: loss 0.5083, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 159 / 441: loss 0.5302, accuracy 0.6875\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 162 / 441: loss 0.4256, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9913\n",
      "    Batch 165 / 441: loss 0.5481, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 168 / 441: loss 0.5638, accuracy 0.6875\n",
      "    ROC-AUC score: 0.9297\n",
      "    Batch 171 / 441: loss 0.5542, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 174 / 441: loss 0.5821, accuracy 0.6979\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 177 / 441: loss 0.6142, accuracy 0.6250\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 180 / 441: loss 0.5398, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 183 / 441: loss 0.6140, accuracy 0.6354\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 186 / 441: loss 0.5467, accuracy 0.6979\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 189 / 441: loss 0.7035, accuracy 0.5417\n",
      "    ROC-AUC score: 0.9875\n",
      "    Batch 192 / 441: loss 0.6377, accuracy 0.6667\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 195 / 441: loss 0.5657, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 198 / 441: loss 0.4544, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8318\n",
      "    Batch 201 / 441: loss 0.5232, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9688\n",
      "    Batch 204 / 441: loss 0.5506, accuracy 0.6979\n",
      "    ROC-AUC score: 0.8828\n",
      "    Batch 207 / 441: loss 0.4942, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 210 / 441: loss 0.5185, accuracy 0.6875\n",
      "    ROC-AUC score: 0.9883\n",
      "    Batch 213 / 441: loss 0.5781, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 216 / 441: loss 0.5321, accuracy 0.7396\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 219 / 441: loss 0.4920, accuracy 0.7708\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 222 / 441: loss 0.4747, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9324\n",
      "    Batch 225 / 441: loss 0.5747, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 228 / 441: loss 0.5205, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 231 / 441: loss 0.4597, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9500\n",
      "    Batch 234 / 441: loss 0.6097, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 237 / 441: loss 0.6111, accuracy 0.6562\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 240 / 441: loss 0.5778, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8917\n",
      "    Batch 243 / 441: loss 0.6182, accuracy 0.6667\n",
      "    ROC-AUC score: 0.8833\n",
      "    Batch 246 / 441: loss 0.5440, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 249 / 441: loss 0.5148, accuracy 0.6875\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 252 / 441: loss 0.4696, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 255 / 441: loss 0.5938, accuracy 0.6979\n",
      "    ROC-AUC score: 0.9555\n",
      "    Batch 258 / 441: loss 0.5229, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 261 / 441: loss 0.5317, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 264 / 441: loss 0.6357, accuracy 0.6354\n",
      "    ROC-AUC score: 0.8867\n",
      "    Batch 267 / 441: loss 0.6027, accuracy 0.6667\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 270 / 441: loss 0.4715, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 273 / 441: loss 0.5579, accuracy 0.6979\n",
      "    ROC-AUC score: 0.8664\n",
      "    Batch 276 / 441: loss 0.4901, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9542\n",
      "    Batch 279 / 441: loss 0.4657, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 282 / 441: loss 0.6649, accuracy 0.6562\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 285 / 441: loss 0.5402, accuracy 0.6979\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 288 / 441: loss 0.4486, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 291 / 441: loss 0.5588, accuracy 0.6979\n",
      "    ROC-AUC score: 0.8785\n",
      "    Batch 294 / 441: loss 0.4523, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8833\n",
      "    Batch 297 / 441: loss 0.6637, accuracy 0.6042\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 300 / 441: loss 0.5306, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 303 / 441: loss 0.5933, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 306 / 441: loss 0.5304, accuracy 0.6979\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 309 / 441: loss 0.6535, accuracy 0.6354\n",
      "    ROC-AUC score: 0.8442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 312 / 441: loss 0.5729, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 315 / 441: loss 0.5000, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 318 / 441: loss 0.5363, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8708\n",
      "    Batch 321 / 441: loss 0.5045, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 324 / 441: loss 0.5862, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 327 / 441: loss 0.4531, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 330 / 441: loss 0.5070, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9570\n",
      "    Batch 333 / 441: loss 0.5495, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9686\n",
      "    Batch 336 / 441: loss 0.5082, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 339 / 441: loss 0.5231, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 342 / 441: loss 0.5934, accuracy 0.6667\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 345 / 441: loss 0.4324, accuracy 0.7812\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 348 / 441: loss 0.4677, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9662\n",
      "    Batch 351 / 441: loss 0.5489, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9313\n",
      "    Batch 354 / 441: loss 0.5949, accuracy 0.6458\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 357 / 441: loss 0.5987, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9833\n",
      "    Batch 360 / 441: loss 0.5269, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 363 / 441: loss 0.6072, accuracy 0.6458\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 366 / 441: loss 0.5311, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8917\n",
      "    Batch 369 / 441: loss 0.5591, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 372 / 441: loss 0.5173, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 375 / 441: loss 0.5888, accuracy 0.6458\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 378 / 441: loss 0.4983, accuracy 0.7188\n",
      "    ROC-AUC score: 0.7812\n",
      "    Batch 381 / 441: loss 0.5701, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8462\n",
      "    Batch 384 / 441: loss 0.6740, accuracy 0.6146\n",
      "    ROC-AUC score: 0.8138\n",
      "    Batch 387 / 441: loss 0.5683, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8516\n",
      "    Batch 390 / 441: loss 0.5366, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 393 / 441: loss 0.4896, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 396 / 441: loss 0.5564, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 399 / 441: loss 0.5213, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 402 / 441: loss 0.6391, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9565\n",
      "    Batch 405 / 441: loss 0.6398, accuracy 0.6146\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 408 / 441: loss 0.6232, accuracy 0.6667\n",
      "    ROC-AUC score: 0.9190\n",
      "    Batch 411 / 441: loss 0.4695, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9264\n",
      "    Batch 414 / 441: loss 0.5108, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 417 / 441: loss 0.5172, accuracy 0.6979\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 420 / 441: loss 0.4458, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 423 / 441: loss 0.4632, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9180\n",
      "    Batch 426 / 441: loss 0.5955, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8543\n",
      "    Batch 429 / 441: loss 0.5320, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 432 / 441: loss 0.5116, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9697\n",
      "    Batch 435 / 441: loss 0.7012, accuracy 0.5938\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 438 / 441: loss 0.4747, accuracy 0.6875\n",
      "    ROC-AUC score: 0.9570\n",
      "    Batch 441 / 441: loss 0.4954, accuracy 0.7143\n",
      "    ROC-AUC score: 1.0000\n",
      "Loss 0.5483, accuracy 0.7021\n",
      "ROC-AUC score: 0.9224\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.46      0.61      7050\n",
      "         1.0       0.64      0.94      0.76      7050\n",
      "\n",
      "    accuracy                           0.70     14100\n",
      "   macro avg       0.76      0.70      0.68     14100\n",
      "weighted avg       0.76      0.70      0.68     14100\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
