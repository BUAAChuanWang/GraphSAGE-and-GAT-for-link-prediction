{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : False,\n",
    "    \n",
    "    \"duplicate_examples\" : True,\n",
    "    \"repeat_examples\" : False,\n",
    "    \n",
    "    \"self_loop\" : True,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GAT\",\n",
    "    \"num_heads\" : [8, 1],\n",
    "    \"hidden_dims\" : [8],\n",
    "    \"dropout\" : 0.6,\n",
    "    \n",
    "    \"epochs\" : 8,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 5e-4,\n",
    "    \"weight_decay\" : 1e-3,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 4066\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()\n",
    "config['input_dim'], config['output_dim'] = input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=274, out_features=8, bias=True)\n",
      "    (1): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      "  (attn): ModuleList(\n",
      "    (0): GraphAttention(\n",
      "      (fc): Linear(in_features=16, out_features=8, bias=True)\n",
      "      (dropout): Dropout(p=0.6)\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): GraphAttention(\n",
      "      (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      "      (dropout): Dropout(p=0.6)\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.6)\n",
      "  (relu): ReLU()\n",
      "  (elu): ELU(alpha=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.get_model(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 128\n",
      "    Batch 2 / 128\n",
      "    Batch 3 / 128\n",
      "    Batch 4 / 128\n",
      "    Batch 5 / 128\n",
      "    Batch 6 / 128\n",
      "    Batch 7 / 128\n",
      "    Batch 8 / 128\n",
      "    Batch 9 / 128\n",
      "    Batch 10 / 128\n",
      "    Batch 11 / 128\n",
      "    Batch 12 / 128\n",
      "    Batch 13 / 128\n",
      "    Batch 14 / 128\n",
      "    Batch 15 / 128\n",
      "    Batch 16 / 128\n",
      "    Batch 17 / 128\n",
      "    Batch 18 / 128\n",
      "    Batch 19 / 128\n",
      "    Batch 20 / 128\n",
      "    Batch 21 / 128\n",
      "    Batch 22 / 128\n",
      "    Batch 23 / 128\n",
      "    Batch 24 / 128\n",
      "    Batch 25 / 128\n",
      "    Batch 26 / 128\n",
      "    Batch 27 / 128\n",
      "    Batch 28 / 128\n",
      "    Batch 29 / 128\n",
      "    Batch 30 / 128\n",
      "    Batch 31 / 128\n",
      "    Batch 32 / 128\n",
      "    Batch 33 / 128\n",
      "    Batch 34 / 128\n",
      "    Batch 35 / 128\n",
      "    Batch 36 / 128\n",
      "    Batch 37 / 128\n",
      "    Batch 38 / 128\n",
      "    Batch 39 / 128\n",
      "    Batch 40 / 128\n",
      "    Batch 41 / 128\n",
      "    Batch 42 / 128\n",
      "    Batch 43 / 128\n",
      "    Batch 44 / 128\n",
      "    Batch 45 / 128\n",
      "    Batch 46 / 128\n",
      "    Batch 47 / 128\n",
      "    Batch 48 / 128\n",
      "    Batch 49 / 128\n",
      "    Batch 50 / 128\n",
      "    Batch 51 / 128\n",
      "    Batch 52 / 128\n",
      "    Batch 53 / 128\n",
      "    Batch 54 / 128\n",
      "    Batch 55 / 128\n",
      "    Batch 56 / 128\n",
      "    Batch 57 / 128\n",
      "    Batch 58 / 128\n",
      "    Batch 59 / 128\n",
      "    Batch 60 / 128\n",
      "    Batch 61 / 128\n",
      "    Batch 62 / 128\n",
      "    Batch 63 / 128\n",
      "    Batch 64 / 128\n",
      "    Batch 65 / 128\n",
      "    Batch 66 / 128\n",
      "    Batch 67 / 128\n",
      "    Batch 68 / 128\n",
      "    Batch 69 / 128\n",
      "    Batch 70 / 128\n",
      "    Batch 71 / 128\n",
      "    Batch 72 / 128\n",
      "    Batch 73 / 128\n",
      "    Batch 74 / 128\n",
      "    Batch 75 / 128\n",
      "    Batch 76 / 128\n",
      "    Batch 77 / 128\n",
      "    Batch 78 / 128\n",
      "    Batch 79 / 128\n",
      "    Batch 80 / 128\n",
      "    Batch 81 / 128\n",
      "    Batch 82 / 128\n",
      "    Batch 83 / 128\n",
      "    Batch 84 / 128\n",
      "    Batch 85 / 128\n",
      "    Batch 86 / 128\n",
      "    Batch 87 / 128\n",
      "    Batch 88 / 128\n",
      "    Batch 89 / 128\n",
      "    Batch 90 / 128\n",
      "    Batch 91 / 128\n",
      "    Batch 92 / 128\n",
      "    Batch 93 / 128\n",
      "    Batch 94 / 128\n",
      "    Batch 95 / 128\n",
      "    Batch 96 / 128\n",
      "    Batch 97 / 128\n",
      "    Batch 98 / 128\n",
      "    Batch 99 / 128\n",
      "    Batch 100 / 128\n",
      "    Batch 101 / 128\n",
      "    Batch 102 / 128\n",
      "    Batch 103 / 128\n",
      "    Batch 104 / 128\n",
      "    Batch 105 / 128\n",
      "    Batch 106 / 128\n",
      "    Batch 107 / 128\n",
      "    Batch 108 / 128\n",
      "    Batch 109 / 128\n",
      "    Batch 110 / 128\n",
      "    Batch 111 / 128\n",
      "    Batch 112 / 128\n",
      "    Batch 113 / 128\n",
      "    Batch 114 / 128\n",
      "    Batch 115 / 128\n",
      "    Batch 116 / 128\n",
      "    Batch 117 / 128\n",
      "    Batch 118 / 128\n",
      "    Batch 119 / 128\n",
      "    Batch 120 / 128\n",
      "    Batch 121 / 128\n",
      "    Batch 122 / 128\n",
      "    Batch 123 / 128\n",
      "    Batch 124 / 128\n",
      "    Batch 125 / 128\n",
      "    Batch 126 / 128\n",
      "    Batch 127 / 128\n",
      "    Batch 128 / 128\n",
      "ROC-AUC score: 0.7011\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 8\n",
      "    Batch 3 / 128: loss 0.6959\n",
      "    ROC-AUC score: 0.6902\n",
      "    Batch 6 / 128: loss 0.6926\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 9 / 128: loss 0.6908\n",
      "    ROC-AUC score: 0.7895\n",
      "    Batch 12 / 128: loss 0.6912\n",
      "    ROC-AUC score: 0.8438\n",
      "    Batch 15 / 128: loss 0.6939\n",
      "    ROC-AUC score: 0.7421\n",
      "    Batch 18 / 128: loss 0.6916\n",
      "    ROC-AUC score: 0.6336\n",
      "    Batch 21 / 128: loss 0.6913\n",
      "    ROC-AUC score: 0.7294\n",
      "    Batch 24 / 128: loss 0.6912\n",
      "    ROC-AUC score: 0.7235\n",
      "    Batch 27 / 128: loss 0.6908\n",
      "    ROC-AUC score: 0.6602\n",
      "    Batch 30 / 128: loss 0.6945\n",
      "    ROC-AUC score: 0.6538\n",
      "    Batch 33 / 128: loss 0.6885\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 36 / 128: loss 0.6888\n",
      "    ROC-AUC score: 0.7146\n",
      "    Batch 39 / 128: loss 0.6914\n",
      "    ROC-AUC score: 0.6508\n",
      "    Batch 42 / 128: loss 0.6909\n",
      "    ROC-AUC score: 0.6522\n",
      "    Batch 45 / 128: loss 0.6895\n",
      "    ROC-AUC score: 0.7302\n",
      "    Batch 48 / 128: loss 0.6916\n",
      "    ROC-AUC score: 0.7530\n",
      "    Batch 51 / 128: loss 0.6921\n",
      "    ROC-AUC score: 0.7146\n",
      "    Batch 54 / 128: loss 0.6817\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 57 / 128: loss 0.6936\n",
      "    ROC-AUC score: 0.4708\n",
      "    Batch 60 / 128: loss 0.6860\n",
      "    ROC-AUC score: 0.5455\n",
      "    Batch 63 / 128: loss 0.6853\n",
      "    ROC-AUC score: 0.6055\n",
      "    Batch 66 / 128: loss 0.6902\n",
      "    ROC-AUC score: 0.6738\n",
      "    Batch 69 / 128: loss 0.6869\n",
      "    ROC-AUC score: 0.6471\n",
      "    Batch 72 / 128: loss 0.6880\n",
      "    ROC-AUC score: 0.7000\n",
      "    Batch 75 / 128: loss 0.6877\n",
      "    ROC-AUC score: 0.6356\n",
      "    Batch 78 / 128: loss 0.6915\n",
      "    ROC-AUC score: 0.7024\n",
      "    Batch 81 / 128: loss 0.6876\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 84 / 128: loss 0.6954\n",
      "    ROC-AUC score: 0.8157\n",
      "    Batch 87 / 128: loss 0.6887\n",
      "    ROC-AUC score: 0.6984\n",
      "    Batch 90 / 128: loss 0.6929\n",
      "    ROC-AUC score: 0.6875\n",
      "    Batch 93 / 128: loss 0.6851\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 96 / 128: loss 0.6854\n",
      "    ROC-AUC score: 0.7692\n",
      "    Batch 99 / 128: loss 0.6924\n",
      "    ROC-AUC score: 0.5745\n",
      "    Batch 102 / 128: loss 0.6842\n",
      "    ROC-AUC score: 0.7196\n",
      "    Batch 105 / 128: loss 0.6857\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 108 / 128: loss 0.6812\n",
      "    ROC-AUC score: 0.7070\n",
      "    Batch 111 / 128: loss 0.6853\n",
      "    ROC-AUC score: 0.5278\n",
      "    Batch 114 / 128: loss 0.6792\n",
      "    ROC-AUC score: 0.7441\n",
      "    Batch 117 / 128: loss 0.6775\n",
      "    ROC-AUC score: 0.7409\n",
      "    Batch 120 / 128: loss 0.6881\n",
      "    ROC-AUC score: 0.7431\n",
      "    Batch 123 / 128: loss 0.6741\n",
      "    ROC-AUC score: 0.6256\n",
      "    Batch 126 / 128: loss 0.6749\n",
      "    ROC-AUC score: 0.5833\n",
      "Epoch 2 / 8\n",
      "    Batch 3 / 128: loss 0.6736\n",
      "    ROC-AUC score: 0.7875\n",
      "    Batch 6 / 128: loss 0.6752\n",
      "    ROC-AUC score: 0.6314\n",
      "    Batch 9 / 128: loss 0.7094\n",
      "    ROC-AUC score: 0.5750\n",
      "    Batch 12 / 128: loss 0.6740\n",
      "    ROC-AUC score: 0.8020\n",
      "    Batch 15 / 128: loss 0.6652\n",
      "    ROC-AUC score: 0.8516\n",
      "    Batch 18 / 128: loss 0.6680\n",
      "    ROC-AUC score: 0.6500\n",
      "    Batch 21 / 128: loss 0.6646\n",
      "    ROC-AUC score: 0.7667\n",
      "    Batch 24 / 128: loss 0.6896\n",
      "    ROC-AUC score: 0.6812\n",
      "    Batch 27 / 128: loss 0.6520\n",
      "    ROC-AUC score: 0.8105\n",
      "    Batch 30 / 128: loss 0.6492\n",
      "    ROC-AUC score: 0.8542\n",
      "    Batch 33 / 128: loss 0.6538\n",
      "    ROC-AUC score: 0.7750\n",
      "    Batch 36 / 128: loss 0.6356\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 39 / 128: loss 0.6471\n",
      "    ROC-AUC score: 0.7773\n",
      "    Batch 42 / 128: loss 0.6442\n",
      "    ROC-AUC score: 0.5961\n",
      "    Batch 45 / 128: loss 0.6335\n",
      "    ROC-AUC score: 0.7667\n",
      "    Batch 48 / 128: loss 0.6721\n",
      "    ROC-AUC score: 0.6875\n",
      "    Batch 51 / 128: loss 0.6736\n",
      "    ROC-AUC score: 0.6417\n",
      "    Batch 54 / 128: loss 0.6317\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 57 / 128: loss 0.6857\n",
      "    ROC-AUC score: 0.6429\n",
      "    Batch 60 / 128: loss 0.6489\n",
      "    ROC-AUC score: 0.8225\n",
      "    Batch 63 / 128: loss 0.6282\n",
      "    ROC-AUC score: 0.7798\n",
      "    Batch 66 / 128: loss 0.6363\n",
      "    ROC-AUC score: 0.6941\n",
      "    Batch 69 / 128: loss 0.6188\n",
      "    ROC-AUC score: 0.6761\n",
      "    Batch 72 / 128: loss 0.6427\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 75 / 128: loss 0.6443\n",
      "    ROC-AUC score: 0.7344\n",
      "    Batch 78 / 128: loss 0.6621\n",
      "    ROC-AUC score: 0.7417\n",
      "    Batch 81 / 128: loss 0.5714\n",
      "    ROC-AUC score: 0.9004\n",
      "    Batch 84 / 128: loss 0.6351\n",
      "    ROC-AUC score: 0.7857\n",
      "    Batch 87 / 128: loss 0.6397\n",
      "    ROC-AUC score: 0.7738\n",
      "    Batch 90 / 128: loss 0.6036\n",
      "    ROC-AUC score: 0.7656\n",
      "    Batch 93 / 128: loss 0.5873\n",
      "    ROC-AUC score: 0.7222\n",
      "    Batch 96 / 128: loss 0.6800\n",
      "    ROC-AUC score: 0.7188\n",
      "    Batch 99 / 128: loss 0.6105\n",
      "    ROC-AUC score: 0.7529\n",
      "    Batch 102 / 128: loss 0.5768\n",
      "    ROC-AUC score: 0.6191\n",
      "    Batch 105 / 128: loss 0.6696\n",
      "    ROC-AUC score: 0.5098\n",
      "    Batch 108 / 128: loss 0.6571\n",
      "    ROC-AUC score: 0.7659\n",
      "    Batch 111 / 128: loss 0.5974\n",
      "    ROC-AUC score: 0.6599\n",
      "    Batch 114 / 128: loss 0.6044\n",
      "    ROC-AUC score: 0.7409\n",
      "    Batch 117 / 128: loss 0.6485\n",
      "    ROC-AUC score: 0.5000\n",
      "    Batch 120 / 128: loss 0.5602\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 123 / 128: loss 0.6037\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 126 / 128: loss 0.5794\n",
      "    ROC-AUC score: 0.7656\n",
      "Epoch 3 / 8\n",
      "    Batch 3 / 128: loss 0.6959\n",
      "    ROC-AUC score: 0.7529\n",
      "    Batch 6 / 128: loss 0.6121\n",
      "    ROC-AUC score: 0.8137\n",
      "    Batch 9 / 128: loss 0.6546\n",
      "    ROC-AUC score: 0.8138\n",
      "    Batch 12 / 128: loss 0.5835\n",
      "    ROC-AUC score: 0.8594\n",
      "    Batch 15 / 128: loss 0.5720\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 18 / 128: loss 0.6783\n",
      "    ROC-AUC score: 0.7294\n",
      "    Batch 21 / 128: loss 0.7429\n",
      "    ROC-AUC score: 0.7597\n",
      "    Batch 24 / 128: loss 0.6616\n",
      "    ROC-AUC score: 0.6250\n",
      "    Batch 27 / 128: loss 0.6606\n",
      "    ROC-AUC score: 0.5506\n",
      "    Batch 30 / 128: loss 0.5223\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 33 / 128: loss 0.6121\n",
      "    ROC-AUC score: 0.8039\n",
      "    Batch 36 / 128: loss 0.6926\n",
      "    ROC-AUC score: 0.6905\n",
      "    Batch 39 / 128: loss 0.6254\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 42 / 128: loss 0.6114\n",
      "    ROC-AUC score: 0.7361\n",
      "    Batch 45 / 128: loss 0.6183\n",
      "    ROC-AUC score: 0.7686\n",
      "    Batch 48 / 128: loss 0.6025\n",
      "    ROC-AUC score: 0.8056\n",
      "    Batch 51 / 128: loss 0.6170\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 54 / 128: loss 0.5452\n",
      "    ROC-AUC score: 0.7938\n",
      "    Batch 57 / 128: loss 0.6590\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 60 / 128: loss 0.6014\n",
      "    ROC-AUC score: 0.8137\n",
      "    Batch 63 / 128: loss 0.5973\n",
      "    ROC-AUC score: 0.7059\n",
      "    Batch 66 / 128: loss 0.6061\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 69 / 128: loss 0.6473\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 72 / 128: loss 0.6019\n",
      "    ROC-AUC score: 0.8216\n",
      "    Batch 75 / 128: loss 0.6569\n",
      "    ROC-AUC score: 0.7163\n",
      "    Batch 78 / 128: loss 0.5417\n",
      "    ROC-AUC score: 0.8261\n",
      "    Batch 81 / 128: loss 0.5691\n",
      "    ROC-AUC score: 0.5754\n",
      "    Batch 84 / 128: loss 0.6328\n",
      "    ROC-AUC score: 0.8472\n",
      "    Batch 87 / 128: loss 0.5925\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 90 / 128: loss 0.5251\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 93 / 128: loss 0.6387\n",
      "    ROC-AUC score: 0.7085\n",
      "    Batch 96 / 128: loss 0.6578\n",
      "    ROC-AUC score: 0.8077\n",
      "    Batch 99 / 128: loss 0.6788\n",
      "    ROC-AUC score: 0.7338\n",
      "    Batch 102 / 128: loss 0.7661\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 105 / 128: loss 0.5542\n",
      "    ROC-AUC score: 0.6682\n",
      "    Batch 108 / 128: loss 0.6083\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 111 / 128: loss 0.5923\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 114 / 128: loss 0.5912\n",
      "    ROC-AUC score: 0.6818\n",
      "    Batch 117 / 128: loss 0.6232\n",
      "    ROC-AUC score: 0.7143\n",
      "    Batch 120 / 128: loss 0.6055\n",
      "    ROC-AUC score: 0.8452\n",
      "    Batch 123 / 128: loss 0.6437\n",
      "    ROC-AUC score: 0.6824\n",
      "    Batch 126 / 128: loss 0.6734\n",
      "    ROC-AUC score: 0.7500\n",
      "Epoch 4 / 8\n",
      "    Batch 3 / 128: loss 0.5822\n",
      "    ROC-AUC score: 0.7287\n",
      "    Batch 6 / 128: loss 0.5565\n",
      "    ROC-AUC score: 0.9107\n",
      "    Batch 9 / 128: loss 0.6303\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 12 / 128: loss 0.5909\n",
      "    ROC-AUC score: 0.8810\n",
      "    Batch 15 / 128: loss 0.5857\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 18 / 128: loss 0.6279\n",
      "    ROC-AUC score: 0.8485\n",
      "    Batch 21 / 128: loss 0.7273\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 24 / 128: loss 0.5566\n",
      "    ROC-AUC score: 0.6445\n",
      "    Batch 27 / 128: loss 0.6760\n",
      "    ROC-AUC score: 0.5863\n",
      "    Batch 30 / 128: loss 0.7035\n",
      "    ROC-AUC score: 0.6591\n",
      "    Batch 33 / 128: loss 0.6276\n",
      "    ROC-AUC score: 0.7996\n",
      "    Batch 36 / 128: loss 0.5462\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 39 / 128: loss 0.6298\n",
      "    ROC-AUC score: 0.7619\n",
      "    Batch 42 / 128: loss 0.6255\n",
      "    ROC-AUC score: 0.6508\n",
      "    Batch 45 / 128: loss 0.6072\n",
      "    ROC-AUC score: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 48 / 128: loss 0.5932\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 51 / 128: loss 0.6621\n",
      "    ROC-AUC score: 0.8157\n",
      "    Batch 54 / 128: loss 0.5733\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 57 / 128: loss 0.6138\n",
      "    ROC-AUC score: 0.7708\n",
      "    Batch 60 / 128: loss 0.6444\n",
      "    ROC-AUC score: 0.7368\n",
      "    Batch 63 / 128: loss 0.5969\n",
      "    ROC-AUC score: 0.9707\n",
      "    Batch 66 / 128: loss 0.5533\n",
      "    ROC-AUC score: 0.8292\n",
      "    Batch 69 / 128: loss 0.5954\n",
      "    ROC-AUC score: 0.7798\n",
      "    Batch 72 / 128: loss 0.6160\n",
      "    ROC-AUC score: 0.5676\n",
      "    Batch 75 / 128: loss 0.6969\n",
      "    ROC-AUC score: 0.7409\n",
      "    Batch 78 / 128: loss 0.5512\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 81 / 128: loss 0.5045\n",
      "    ROC-AUC score: 0.7891\n",
      "    Batch 84 / 128: loss 0.6016\n",
      "    ROC-AUC score: 0.6409\n",
      "    Batch 87 / 128: loss 0.6332\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 90 / 128: loss 0.6762\n",
      "    ROC-AUC score: 0.7176\n",
      "    Batch 93 / 128: loss 0.6030\n",
      "    ROC-AUC score: 0.7667\n",
      "    Batch 96 / 128: loss 0.5938\n",
      "    ROC-AUC score: 0.6111\n",
      "    Batch 99 / 128: loss 0.5983\n",
      "    ROC-AUC score: 0.7941\n",
      "    Batch 102 / 128: loss 0.6352\n",
      "    ROC-AUC score: 0.7686\n",
      "    Batch 105 / 128: loss 0.6927\n",
      "    ROC-AUC score: 0.7255\n",
      "    Batch 108 / 128: loss 0.6745\n",
      "    ROC-AUC score: 0.6230\n",
      "    Batch 111 / 128: loss 0.6056\n",
      "    ROC-AUC score: 0.7961\n",
      "    Batch 114 / 128: loss 0.5110\n",
      "    ROC-AUC score: 0.8907\n",
      "    Batch 117 / 128: loss 0.5635\n",
      "    ROC-AUC score: 0.8730\n",
      "    Batch 120 / 128: loss 0.5917\n",
      "    ROC-AUC score: 0.7188\n",
      "    Batch 123 / 128: loss 0.5557\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 126 / 128: loss 0.6530\n",
      "    ROC-AUC score: 0.7750\n",
      "Epoch 5 / 8\n",
      "    Batch 3 / 128: loss 0.6365\n",
      "    ROC-AUC score: 0.6680\n",
      "    Batch 6 / 128: loss 0.5798\n",
      "    ROC-AUC score: 0.7996\n",
      "    Batch 9 / 128: loss 0.6453\n",
      "    ROC-AUC score: 0.8708\n",
      "    Batch 12 / 128: loss 0.6990\n",
      "    ROC-AUC score: 0.4570\n",
      "    Batch 15 / 128: loss 0.6398\n",
      "    ROC-AUC score: 0.8176\n",
      "    Batch 18 / 128: loss 0.6384\n",
      "    ROC-AUC score: 0.7186\n",
      "    Batch 21 / 128: loss 0.6048\n",
      "    ROC-AUC score: 0.7000\n",
      "    Batch 24 / 128: loss 0.5527\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 27 / 128: loss 0.6751\n",
      "    ROC-AUC score: 0.6667\n",
      "    Batch 30 / 128: loss 0.6604\n",
      "    ROC-AUC score: 0.7676\n",
      "    Batch 33 / 128: loss 0.5769\n",
      "    ROC-AUC score: 0.7000\n",
      "    Batch 36 / 128: loss 0.7084\n",
      "    ROC-AUC score: 0.5794\n",
      "    Batch 39 / 128: loss 0.5665\n",
      "    ROC-AUC score: 0.7835\n",
      "    Batch 42 / 128: loss 0.6010\n",
      "    ROC-AUC score: 0.6471\n",
      "    Batch 45 / 128: loss 0.5766\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 48 / 128: loss 0.7033\n",
      "    ROC-AUC score: 0.6738\n",
      "    Batch 51 / 128: loss 0.5974\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 54 / 128: loss 0.6326\n",
      "    ROC-AUC score: 0.7980\n",
      "    Batch 57 / 128: loss 0.5950\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 60 / 128: loss 0.5975\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 63 / 128: loss 0.5986\n",
      "    ROC-AUC score: 0.7814\n",
      "    Batch 66 / 128: loss 0.5980\n",
      "    ROC-AUC score: 0.7287\n",
      "    Batch 69 / 128: loss 0.6715\n",
      "    ROC-AUC score: 0.6667\n",
      "    Batch 72 / 128: loss 0.5896\n",
      "    ROC-AUC score: 0.7412\n",
      "    Batch 75 / 128: loss 0.5911\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 78 / 128: loss 0.5930\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 81 / 128: loss 0.6169\n",
      "    ROC-AUC score: 0.6746\n",
      "    Batch 84 / 128: loss 0.5843\n",
      "    ROC-AUC score: 0.8458\n",
      "    Batch 87 / 128: loss 0.6693\n",
      "    ROC-AUC score: 0.6152\n",
      "    Batch 90 / 128: loss 0.6760\n",
      "    ROC-AUC score: 0.7874\n",
      "    Batch 93 / 128: loss 0.8100\n",
      "    ROC-AUC score: 0.3603\n",
      "    Batch 96 / 128: loss 0.6073\n",
      "    ROC-AUC score: 0.7897\n",
      "    Batch 99 / 128: loss 0.7244\n",
      "    ROC-AUC score: 0.5647\n",
      "    Batch 102 / 128: loss 0.6645\n",
      "    ROC-AUC score: 0.7196\n",
      "    Batch 105 / 128: loss 0.5991\n",
      "    ROC-AUC score: 0.9121\n",
      "    Batch 108 / 128: loss 0.5701\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 111 / 128: loss 0.5842\n",
      "    ROC-AUC score: 0.7773\n",
      "    Batch 114 / 128: loss 0.4553\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 117 / 128: loss 0.5406\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 120 / 128: loss 0.5992\n",
      "    ROC-AUC score: 0.7000\n",
      "    Batch 123 / 128: loss 0.7709\n",
      "    ROC-AUC score: 0.6316\n",
      "    Batch 126 / 128: loss 0.6485\n",
      "    ROC-AUC score: 0.7588\n",
      "Epoch 6 / 8\n",
      "    Batch 3 / 128: loss 0.6170\n",
      "    ROC-AUC score: 0.7183\n",
      "    Batch 6 / 128: loss 0.6194\n",
      "    ROC-AUC score: 0.6836\n",
      "    Batch 9 / 128: loss 0.5648\n",
      "    ROC-AUC score: 0.7738\n",
      "    Batch 12 / 128: loss 0.6369\n",
      "    ROC-AUC score: 0.7295\n",
      "    Batch 15 / 128: loss 0.6290\n",
      "    ROC-AUC score: 0.7109\n",
      "    Batch 18 / 128: loss 0.5431\n",
      "    ROC-AUC score: 0.7625\n",
      "    Batch 21 / 128: loss 0.6517\n",
      "    ROC-AUC score: 0.7206\n",
      "    Batch 24 / 128: loss 0.6454\n",
      "    ROC-AUC score: 0.6822\n",
      "    Batch 27 / 128: loss 0.6275\n",
      "    ROC-AUC score: 0.6833\n",
      "    Batch 30 / 128: loss 0.5784\n",
      "    ROC-AUC score: 0.7314\n",
      "    Batch 33 / 128: loss 0.6302\n",
      "    ROC-AUC score: 0.7470\n",
      "    Batch 36 / 128: loss 0.5381\n",
      "    ROC-AUC score: 0.8438\n",
      "    Batch 39 / 128: loss 0.5598\n",
      "    ROC-AUC score: 0.7857\n",
      "    Batch 42 / 128: loss 0.5209\n",
      "    ROC-AUC score: 0.7773\n",
      "    Batch 45 / 128: loss 0.6226\n",
      "    ROC-AUC score: 0.6032\n",
      "    Batch 48 / 128: loss 0.5819\n",
      "    ROC-AUC score: 0.6133\n",
      "    Batch 51 / 128: loss 0.7192\n",
      "    ROC-AUC score: 0.6364\n",
      "    Batch 54 / 128: loss 0.6000\n",
      "    ROC-AUC score: 0.5911\n",
      "    Batch 57 / 128: loss 0.6309\n",
      "    ROC-AUC score: 0.6457\n",
      "    Batch 60 / 128: loss 0.6217\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 63 / 128: loss 0.5532\n",
      "    ROC-AUC score: 0.8846\n",
      "    Batch 66 / 128: loss 0.6106\n",
      "    ROC-AUC score: 0.8008\n",
      "    Batch 69 / 128: loss 0.6092\n",
      "    ROC-AUC score: 0.7176\n",
      "    Batch 72 / 128: loss 0.5879\n",
      "    ROC-AUC score: 0.7000\n",
      "    Batch 75 / 128: loss 0.6120\n",
      "    ROC-AUC score: 0.6746\n",
      "    Batch 78 / 128: loss 0.6176\n",
      "    ROC-AUC score: 0.7460\n",
      "    Batch 81 / 128: loss 0.5809\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 84 / 128: loss 0.5937\n",
      "    ROC-AUC score: 0.6902\n",
      "    Batch 87 / 128: loss 0.5606\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 90 / 128: loss 0.5938\n",
      "    ROC-AUC score: 0.7143\n",
      "    Batch 93 / 128: loss 0.6004\n",
      "    ROC-AUC score: 0.6356\n",
      "    Batch 96 / 128: loss 0.6365\n",
      "    ROC-AUC score: 0.6042\n",
      "    Batch 99 / 128: loss 0.5689\n",
      "    ROC-AUC score: 0.8313\n",
      "    Batch 102 / 128: loss 0.6376\n",
      "    ROC-AUC score: 0.6599\n",
      "    Batch 105 / 128: loss 0.5893\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 108 / 128: loss 0.6261\n",
      "    ROC-AUC score: 0.6568\n",
      "    Batch 111 / 128: loss 0.5321\n",
      "    ROC-AUC score: 0.7705\n",
      "    Batch 114 / 128: loss 0.6949\n",
      "    ROC-AUC score: 0.6548\n",
      "    Batch 117 / 128: loss 0.6770\n",
      "    ROC-AUC score: 0.6314\n",
      "    Batch 120 / 128: loss 0.5883\n",
      "    ROC-AUC score: 0.8462\n",
      "    Batch 123 / 128: loss 0.5575\n",
      "    ROC-AUC score: 0.8438\n",
      "    Batch 126 / 128: loss 0.6367\n",
      "    ROC-AUC score: 0.6032\n",
      "Epoch 7 / 8\n",
      "    Batch 3 / 128: loss 0.7111\n",
      "    ROC-AUC score: 0.6855\n",
      "    Batch 6 / 128: loss 0.5892\n",
      "    ROC-AUC score: 0.7324\n",
      "    Batch 9 / 128: loss 0.5236\n",
      "    ROC-AUC score: 0.7949\n",
      "    Batch 12 / 128: loss 0.6122\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 15 / 128: loss 0.5592\n",
      "    ROC-AUC score: 0.8056\n",
      "    Batch 18 / 128: loss 0.5783\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 21 / 128: loss 0.6435\n",
      "    ROC-AUC score: 0.5714\n",
      "    Batch 24 / 128: loss 0.5764\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 27 / 128: loss 0.5453\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 30 / 128: loss 0.7361\n",
      "    ROC-AUC score: 0.6746\n",
      "    Batch 33 / 128: loss 0.5945\n",
      "    ROC-AUC score: 0.9329\n",
      "    Batch 36 / 128: loss 0.5606\n",
      "    ROC-AUC score: 0.9351\n",
      "    Batch 39 / 128: loss 0.5235\n",
      "    ROC-AUC score: 0.8918\n",
      "    Batch 42 / 128: loss 0.6287\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 45 / 128: loss 0.5463\n",
      "    ROC-AUC score: 0.6484\n",
      "    Batch 48 / 128: loss 0.5288\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 51 / 128: loss 0.5908\n",
      "    ROC-AUC score: 0.9130\n",
      "    Batch 54 / 128: loss 0.6414\n",
      "    ROC-AUC score: 0.7652\n",
      "    Batch 57 / 128: loss 0.6259\n",
      "    ROC-AUC score: 0.6825\n",
      "    Batch 60 / 128: loss 0.5388\n",
      "    ROC-AUC score: 0.7857\n",
      "    Batch 63 / 128: loss 0.6126\n",
      "    ROC-AUC score: 0.7098\n",
      "    Batch 66 / 128: loss 0.6457\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 69 / 128: loss 0.7009\n",
      "    ROC-AUC score: 0.5833\n",
      "    Batch 72 / 128: loss 0.6219\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 75 / 128: loss 0.5316\n",
      "    ROC-AUC score: 0.8651\n",
      "    Batch 78 / 128: loss 0.5912\n",
      "    ROC-AUC score: 0.6726\n",
      "    Batch 81 / 128: loss 0.5869\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 84 / 128: loss 0.6138\n",
      "    ROC-AUC score: 0.6627\n",
      "    Batch 87 / 128: loss 0.6533\n",
      "    ROC-AUC score: 0.7961\n",
      "    Batch 90 / 128: loss 0.5616\n",
      "    ROC-AUC score: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 93 / 128: loss 0.7209\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 96 / 128: loss 0.5988\n",
      "    ROC-AUC score: 0.5431\n",
      "    Batch 99 / 128: loss 0.6214\n",
      "    ROC-AUC score: 0.7529\n",
      "    Batch 102 / 128: loss 0.6043\n",
      "    ROC-AUC score: 0.8196\n",
      "    Batch 105 / 128: loss 0.5660\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 108 / 128: loss 0.5398\n",
      "    ROC-AUC score: 0.7391\n",
      "    Batch 111 / 128: loss 0.5482\n",
      "    ROC-AUC score: 0.7020\n",
      "    Batch 114 / 128: loss 0.6263\n",
      "    ROC-AUC score: 0.7619\n",
      "    Batch 117 / 128: loss 0.7881\n",
      "    ROC-AUC score: 0.7713\n",
      "    Batch 120 / 128: loss 0.5668\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 123 / 128: loss 0.7972\n",
      "    ROC-AUC score: 0.7659\n",
      "    Batch 126 / 128: loss 0.6264\n",
      "    ROC-AUC score: 0.8214\n",
      "Epoch 8 / 8\n",
      "    Batch 3 / 128: loss 0.6200\n",
      "    ROC-AUC score: 0.7078\n",
      "    Batch 6 / 128: loss 0.5850\n",
      "    ROC-AUC score: 0.7421\n",
      "    Batch 9 / 128: loss 0.7631\n",
      "    ROC-AUC score: 0.5843\n",
      "    Batch 12 / 128: loss 0.6371\n",
      "    ROC-AUC score: 0.6865\n",
      "    Batch 15 / 128: loss 0.6298\n",
      "    ROC-AUC score: 0.7599\n",
      "    Batch 18 / 128: loss 0.6489\n",
      "    ROC-AUC score: 0.6745\n",
      "    Batch 21 / 128: loss 0.5926\n",
      "    ROC-AUC score: 0.6738\n",
      "    Batch 24 / 128: loss 0.6066\n",
      "    ROC-AUC score: 0.8452\n",
      "    Batch 27 / 128: loss 0.6093\n",
      "    ROC-AUC score: 0.8047\n",
      "    Batch 30 / 128: loss 0.5797\n",
      "    ROC-AUC score: 0.7910\n",
      "    Batch 33 / 128: loss 0.6372\n",
      "    ROC-AUC score: 0.7625\n",
      "    Batch 36 / 128: loss 0.6229\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 39 / 128: loss 0.5155\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 42 / 128: loss 0.6386\n",
      "    ROC-AUC score: 0.9087\n",
      "    Batch 45 / 128: loss 0.6665\n",
      "    ROC-AUC score: 0.7451\n",
      "    Batch 48 / 128: loss 0.6815\n",
      "    ROC-AUC score: 0.6091\n",
      "    Batch 51 / 128: loss 0.5717\n",
      "    ROC-AUC score: 0.7692\n",
      "    Batch 54 / 128: loss 0.5743\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 57 / 128: loss 0.6673\n",
      "    ROC-AUC score: 0.7812\n",
      "    Batch 60 / 128: loss 0.6278\n",
      "    ROC-AUC score: 0.6409\n",
      "    Batch 63 / 128: loss 0.6595\n",
      "    ROC-AUC score: 0.5490\n",
      "    Batch 66 / 128: loss 0.6457\n",
      "    ROC-AUC score: 0.7451\n",
      "    Batch 69 / 128: loss 0.5645\n",
      "    ROC-AUC score: 0.7255\n",
      "    Batch 72 / 128: loss 0.5892\n",
      "    ROC-AUC score: 0.7458\n",
      "    Batch 75 / 128: loss 0.7159\n",
      "    ROC-AUC score: 0.7813\n",
      "    Batch 78 / 128: loss 0.5753\n",
      "    ROC-AUC score: 0.8687\n",
      "    Batch 81 / 128: loss 0.6459\n",
      "    ROC-AUC score: 0.7039\n",
      "    Batch 84 / 128: loss 0.5687\n",
      "    ROC-AUC score: 0.6797\n",
      "    Batch 87 / 128: loss 0.5859\n",
      "    ROC-AUC score: 0.7539\n",
      "    Batch 90 / 128: loss 0.6664\n",
      "    ROC-AUC score: 0.7045\n",
      "    Batch 93 / 128: loss 0.5359\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 96 / 128: loss 0.5571\n",
      "    ROC-AUC score: 0.8664\n",
      "    Batch 99 / 128: loss 0.6256\n",
      "    ROC-AUC score: 0.7004\n",
      "    Batch 102 / 128: loss 0.6051\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 105 / 128: loss 0.5749\n",
      "    ROC-AUC score: 0.7188\n",
      "    Batch 108 / 128: loss 0.5958\n",
      "    ROC-AUC score: 0.6290\n",
      "    Batch 111 / 128: loss 0.5677\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 114 / 128: loss 0.5841\n",
      "    ROC-AUC score: 0.7176\n",
      "    Batch 117 / 128: loss 0.6245\n",
      "    ROC-AUC score: 0.7305\n",
      "    Batch 120 / 128: loss 0.5524\n",
      "    ROC-AUC score: 0.8182\n",
      "    Batch 123 / 128: loss 0.5853\n",
      "    ROC-AUC score: 0.7045\n",
      "    Batch 126 / 128: loss 0.6697\n",
      "    ROC-AUC score: 0.7105\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=400, gamma=0.8)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 300], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 128\n",
      "    Batch 2 / 128\n",
      "    Batch 3 / 128\n",
      "    Batch 4 / 128\n",
      "    Batch 5 / 128\n",
      "    Batch 6 / 128\n",
      "    Batch 7 / 128\n",
      "    Batch 8 / 128\n",
      "    Batch 9 / 128\n",
      "    Batch 10 / 128\n",
      "    Batch 11 / 128\n",
      "    Batch 12 / 128\n",
      "    Batch 13 / 128\n",
      "    Batch 14 / 128\n",
      "    Batch 15 / 128\n",
      "    Batch 16 / 128\n",
      "    Batch 17 / 128\n",
      "    Batch 18 / 128\n",
      "    Batch 19 / 128\n",
      "    Batch 20 / 128\n",
      "    Batch 21 / 128\n",
      "    Batch 22 / 128\n",
      "    Batch 23 / 128\n",
      "    Batch 24 / 128\n",
      "    Batch 25 / 128\n",
      "    Batch 26 / 128\n",
      "    Batch 27 / 128\n",
      "    Batch 28 / 128\n",
      "    Batch 29 / 128\n",
      "    Batch 30 / 128\n",
      "    Batch 31 / 128\n",
      "    Batch 32 / 128\n",
      "    Batch 33 / 128\n",
      "    Batch 34 / 128\n",
      "    Batch 35 / 128\n",
      "    Batch 36 / 128\n",
      "    Batch 37 / 128\n",
      "    Batch 38 / 128\n",
      "    Batch 39 / 128\n",
      "    Batch 40 / 128\n",
      "    Batch 41 / 128\n",
      "    Batch 42 / 128\n",
      "    Batch 43 / 128\n",
      "    Batch 44 / 128\n",
      "    Batch 45 / 128\n",
      "    Batch 46 / 128\n",
      "    Batch 47 / 128\n",
      "    Batch 48 / 128\n",
      "    Batch 49 / 128\n",
      "    Batch 50 / 128\n",
      "    Batch 51 / 128\n",
      "    Batch 52 / 128\n",
      "    Batch 53 / 128\n",
      "    Batch 54 / 128\n",
      "    Batch 55 / 128\n",
      "    Batch 56 / 128\n",
      "    Batch 57 / 128\n",
      "    Batch 58 / 128\n",
      "    Batch 59 / 128\n",
      "    Batch 60 / 128\n",
      "    Batch 61 / 128\n",
      "    Batch 62 / 128\n",
      "    Batch 63 / 128\n",
      "    Batch 64 / 128\n",
      "    Batch 65 / 128\n",
      "    Batch 66 / 128\n",
      "    Batch 67 / 128\n",
      "    Batch 68 / 128\n",
      "    Batch 69 / 128\n",
      "    Batch 70 / 128\n",
      "    Batch 71 / 128\n",
      "    Batch 72 / 128\n",
      "    Batch 73 / 128\n",
      "    Batch 74 / 128\n",
      "    Batch 75 / 128\n",
      "    Batch 76 / 128\n",
      "    Batch 77 / 128\n",
      "    Batch 78 / 128\n",
      "    Batch 79 / 128\n",
      "    Batch 80 / 128\n",
      "    Batch 81 / 128\n",
      "    Batch 82 / 128\n",
      "    Batch 83 / 128\n",
      "    Batch 84 / 128\n",
      "    Batch 85 / 128\n",
      "    Batch 86 / 128\n",
      "    Batch 87 / 128\n",
      "    Batch 88 / 128\n",
      "    Batch 89 / 128\n",
      "    Batch 90 / 128\n",
      "    Batch 91 / 128\n",
      "    Batch 92 / 128\n",
      "    Batch 93 / 128\n",
      "    Batch 94 / 128\n",
      "    Batch 95 / 128\n",
      "    Batch 96 / 128\n",
      "    Batch 97 / 128\n",
      "    Batch 98 / 128\n",
      "    Batch 99 / 128\n",
      "    Batch 100 / 128\n",
      "    Batch 101 / 128\n",
      "    Batch 102 / 128\n",
      "    Batch 103 / 128\n",
      "    Batch 104 / 128\n",
      "    Batch 105 / 128\n",
      "    Batch 106 / 128\n",
      "    Batch 107 / 128\n",
      "    Batch 108 / 128\n",
      "    Batch 109 / 128\n",
      "    Batch 110 / 128\n",
      "    Batch 111 / 128\n",
      "    Batch 112 / 128\n",
      "    Batch 113 / 128\n",
      "    Batch 114 / 128\n",
      "    Batch 115 / 128\n",
      "    Batch 116 / 128\n",
      "    Batch 117 / 128\n",
      "    Batch 118 / 128\n",
      "    Batch 119 / 128\n",
      "    Batch 120 / 128\n",
      "    Batch 121 / 128\n",
      "    Batch 122 / 128\n",
      "    Batch 123 / 128\n",
      "    Batch 124 / 128\n",
      "    Batch 125 / 128\n",
      "    Batch 126 / 128\n",
      "    Batch 127 / 128\n",
      "    Batch 128 / 128\n",
      "ROC-AUC score: 0.7569\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 128\n",
      "    Batch 2 / 128\n",
      "    Batch 3 / 128\n",
      "    Batch 4 / 128\n",
      "    Batch 5 / 128\n",
      "    Batch 6 / 128\n",
      "    Batch 7 / 128\n",
      "    Batch 8 / 128\n",
      "    Batch 9 / 128\n",
      "    Batch 10 / 128\n",
      "    Batch 11 / 128\n",
      "    Batch 12 / 128\n",
      "    Batch 13 / 128\n",
      "    Batch 14 / 128\n",
      "    Batch 15 / 128\n",
      "    Batch 16 / 128\n",
      "    Batch 17 / 128\n",
      "    Batch 18 / 128\n",
      "    Batch 19 / 128\n",
      "    Batch 20 / 128\n",
      "    Batch 21 / 128\n",
      "    Batch 22 / 128\n",
      "    Batch 23 / 128\n",
      "    Batch 24 / 128\n",
      "    Batch 25 / 128\n",
      "    Batch 26 / 128\n",
      "    Batch 27 / 128\n",
      "    Batch 28 / 128\n",
      "    Batch 29 / 128\n",
      "    Batch 30 / 128\n",
      "    Batch 31 / 128\n",
      "    Batch 32 / 128\n",
      "    Batch 33 / 128\n",
      "    Batch 34 / 128\n",
      "    Batch 35 / 128\n",
      "    Batch 36 / 128\n",
      "    Batch 37 / 128\n",
      "    Batch 38 / 128\n",
      "    Batch 39 / 128\n",
      "    Batch 40 / 128\n",
      "    Batch 41 / 128\n",
      "    Batch 42 / 128\n",
      "    Batch 43 / 128\n",
      "    Batch 44 / 128\n",
      "    Batch 45 / 128\n",
      "    Batch 46 / 128\n",
      "    Batch 47 / 128\n",
      "    Batch 48 / 128\n",
      "    Batch 49 / 128\n",
      "    Batch 50 / 128\n",
      "    Batch 51 / 128\n",
      "    Batch 52 / 128\n",
      "    Batch 53 / 128\n",
      "    Batch 54 / 128\n",
      "    Batch 55 / 128\n",
      "    Batch 56 / 128\n",
      "    Batch 57 / 128\n",
      "    Batch 58 / 128\n",
      "    Batch 59 / 128\n",
      "    Batch 60 / 128\n",
      "    Batch 61 / 128\n",
      "    Batch 62 / 128\n",
      "    Batch 63 / 128\n",
      "    Batch 64 / 128\n",
      "    Batch 65 / 128\n",
      "    Batch 66 / 128\n",
      "    Batch 67 / 128\n",
      "    Batch 68 / 128\n",
      "    Batch 69 / 128\n",
      "    Batch 70 / 128\n",
      "    Batch 71 / 128\n",
      "    Batch 72 / 128\n",
      "    Batch 73 / 128\n",
      "    Batch 74 / 128\n",
      "    Batch 75 / 128\n",
      "    Batch 76 / 128\n",
      "    Batch 77 / 128\n",
      "    Batch 78 / 128\n",
      "    Batch 79 / 128\n",
      "    Batch 80 / 128\n",
      "    Batch 81 / 128\n",
      "    Batch 82 / 128\n",
      "    Batch 83 / 128\n",
      "    Batch 84 / 128\n",
      "    Batch 85 / 128\n",
      "    Batch 86 / 128\n",
      "    Batch 87 / 128\n",
      "    Batch 88 / 128\n",
      "    Batch 89 / 128\n",
      "    Batch 90 / 128\n",
      "    Batch 91 / 128\n",
      "    Batch 92 / 128\n",
      "    Batch 93 / 128\n",
      "    Batch 94 / 128\n",
      "    Batch 95 / 128\n",
      "    Batch 96 / 128\n",
      "    Batch 97 / 128\n",
      "    Batch 98 / 128\n",
      "    Batch 99 / 128\n",
      "    Batch 100 / 128\n",
      "    Batch 101 / 128\n",
      "    Batch 102 / 128\n",
      "    Batch 103 / 128\n",
      "    Batch 104 / 128\n",
      "    Batch 105 / 128\n",
      "    Batch 106 / 128\n",
      "    Batch 107 / 128\n",
      "    Batch 108 / 128\n",
      "    Batch 109 / 128\n",
      "    Batch 110 / 128\n",
      "    Batch 111 / 128\n",
      "    Batch 112 / 128\n",
      "    Batch 113 / 128\n",
      "    Batch 114 / 128\n",
      "    Batch 115 / 128\n",
      "    Batch 116 / 128\n",
      "    Batch 117 / 128\n",
      "    Batch 118 / 128\n",
      "    Batch 119 / 128\n",
      "    Batch 120 / 128\n",
      "    Batch 121 / 128\n",
      "    Batch 122 / 128\n",
      "    Batch 123 / 128\n",
      "    Batch 124 / 128\n",
      "    Batch 125 / 128\n",
      "    Batch 126 / 128\n",
      "    Batch 127 / 128\n",
      "    Batch 128 / 128\n",
      "Threshold: 0.0054, accuracy: 0.7536\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.93      0.79      2033\n",
      "         1.0       0.89      0.58      0.70      2033\n",
      "\n",
      "    accuracy                           0.75      4066\n",
      "   macro avg       0.79      0.75      0.75      4066\n",
      "weighted avg       0.79      0.75      0.75      4066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 4106\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 129: loss 0.6306, accuracy 0.6458\n",
      "    ROC-AUC score: 0.9083\n",
      "    Batch 6 / 129: loss 0.6180, accuracy 0.6354\n",
      "    ROC-AUC score: 0.7446\n",
      "    Batch 9 / 129: loss 0.6531, accuracy 0.5938\n",
      "    ROC-AUC score: 0.6953\n",
      "    Batch 12 / 129: loss 0.6477, accuracy 0.6354\n",
      "    ROC-AUC score: 0.7539\n",
      "    Batch 15 / 129: loss 0.6513, accuracy 0.5938\n",
      "    ROC-AUC score: 0.7148\n",
      "    Batch 18 / 129: loss 0.6447, accuracy 0.6562\n",
      "    ROC-AUC score: 0.7897\n",
      "    Batch 21 / 129: loss 0.6420, accuracy 0.6562\n",
      "    ROC-AUC score: 0.7045\n",
      "    Batch 24 / 129: loss 0.6447, accuracy 0.6146\n",
      "    ROC-AUC score: 0.8730\n",
      "    Batch 27 / 129: loss 0.6350, accuracy 0.6562\n",
      "    ROC-AUC score: 0.7765\n",
      "    Batch 30 / 129: loss 0.6219, accuracy 0.6562\n",
      "    ROC-AUC score: 0.8196\n",
      "    Batch 33 / 129: loss 0.6460, accuracy 0.6250\n",
      "    ROC-AUC score: 0.6235\n",
      "    Batch 36 / 129: loss 0.6276, accuracy 0.6458\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 39 / 129: loss 0.6515, accuracy 0.6458\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 42 / 129: loss 0.6333, accuracy 0.6667\n",
      "    ROC-AUC score: 0.7208\n",
      "    Batch 45 / 129: loss 0.5964, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8056\n",
      "    Batch 48 / 129: loss 0.6716, accuracy 0.5729\n",
      "    ROC-AUC score: 0.6032\n",
      "    Batch 51 / 129: loss 0.6231, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 54 / 129: loss 0.6315, accuracy 0.6354\n",
      "    ROC-AUC score: 0.7833\n",
      "    Batch 57 / 129: loss 0.6523, accuracy 0.6562\n",
      "    ROC-AUC score: 0.8961\n",
      "    Batch 60 / 129: loss 0.6551, accuracy 0.5625\n",
      "    ROC-AUC score: 0.6397\n",
      "    Batch 63 / 129: loss 0.6708, accuracy 0.6042\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 66 / 129: loss 0.6298, accuracy 0.6250\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 69 / 129: loss 0.6018, accuracy 0.6979\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 72 / 129: loss 0.6497, accuracy 0.5938\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 75 / 129: loss 0.6464, accuracy 0.6458\n",
      "    ROC-AUC score: 0.6784\n",
      "    Batch 78 / 129: loss 0.6326, accuracy 0.6875\n",
      "    ROC-AUC score: 0.6373\n",
      "    Batch 81 / 129: loss 0.6511, accuracy 0.6146\n",
      "    ROC-AUC score: 0.6941\n",
      "    Batch 84 / 129: loss 0.6442, accuracy 0.6250\n",
      "    ROC-AUC score: 0.8698\n",
      "    Batch 87 / 129: loss 0.7034, accuracy 0.4896\n",
      "    ROC-AUC score: 0.5312\n",
      "    Batch 90 / 129: loss 0.6468, accuracy 0.6354\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 93 / 129: loss 0.6106, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 96 / 129: loss 0.6369, accuracy 0.6250\n",
      "    ROC-AUC score: 0.7449\n",
      "    Batch 99 / 129: loss 0.6157, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 102 / 129: loss 0.6469, accuracy 0.6458\n",
      "    ROC-AUC score: 0.8785\n",
      "    Batch 105 / 129: loss 0.6506, accuracy 0.6042\n",
      "    ROC-AUC score: 0.6797\n",
      "    Batch 108 / 129: loss 0.6104, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 111 / 129: loss 0.6538, accuracy 0.6250\n",
      "    ROC-AUC score: 0.6196\n",
      "    Batch 114 / 129: loss 0.6251, accuracy 0.6667\n",
      "    ROC-AUC score: 0.8730\n",
      "    Batch 117 / 129: loss 0.6176, accuracy 0.6562\n",
      "    ROC-AUC score: 0.7812\n",
      "    Batch 120 / 129: loss 0.6573, accuracy 0.6354\n",
      "    ROC-AUC score: 0.7103\n",
      "    Batch 123 / 129: loss 0.6469, accuracy 0.6562\n",
      "    ROC-AUC score: 0.7381\n",
      "    Batch 126 / 129: loss 0.6684, accuracy 0.6354\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 129 / 129: loss 0.6567, accuracy 0.5676\n",
      "    ROC-AUC score: 0.8750\n",
      "Loss 0.6407, accuracy 0.6369\n",
      "ROC-AUC score: 0.7904\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.44      0.55      2053\n",
      "         1.0       0.60      0.83      0.70      2053\n",
      "\n",
      "    accuracy                           0.64      4106\n",
      "   macro avg       0.66      0.64      0.62      4106\n",
      "weighted avg       0.66      0.64      0.62      4106\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
