{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : True,\n",
    "    \"repeat_examples\" : False,\n",
    "    \n",
    "    \"self_loop\" : False,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0.5,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 3,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 4066\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()\n",
    "config['input_dim'], config['output_dim'] = input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=274, out_features=274, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=548, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.get_model(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 129\n",
      "    Batch 2 / 129\n",
      "    Batch 3 / 129\n",
      "    Batch 4 / 129\n",
      "    Batch 5 / 129\n",
      "    Batch 6 / 129\n",
      "    Batch 7 / 129\n",
      "    Batch 8 / 129\n",
      "    Batch 9 / 129\n",
      "    Batch 10 / 129\n",
      "    Batch 11 / 129\n",
      "    Batch 12 / 129\n",
      "    Batch 13 / 129\n",
      "    Batch 14 / 129\n",
      "    Batch 15 / 129\n",
      "    Batch 16 / 129\n",
      "    Batch 17 / 129\n",
      "    Batch 18 / 129\n",
      "    Batch 19 / 129\n",
      "    Batch 20 / 129\n",
      "    Batch 21 / 129\n",
      "    Batch 22 / 129\n",
      "    Batch 23 / 129\n",
      "    Batch 24 / 129\n",
      "    Batch 25 / 129\n",
      "    Batch 26 / 129\n",
      "    Batch 27 / 129\n",
      "    Batch 28 / 129\n",
      "    Batch 29 / 129\n",
      "    Batch 30 / 129\n",
      "    Batch 31 / 129\n",
      "    Batch 32 / 129\n",
      "    Batch 33 / 129\n",
      "    Batch 34 / 129\n",
      "    Batch 35 / 129\n",
      "    Batch 36 / 129\n",
      "    Batch 37 / 129\n",
      "    Batch 38 / 129\n",
      "    Batch 39 / 129\n",
      "    Batch 40 / 129\n",
      "    Batch 41 / 129\n",
      "    Batch 42 / 129\n",
      "    Batch 43 / 129\n",
      "    Batch 44 / 129\n",
      "    Batch 45 / 129\n",
      "    Batch 46 / 129\n",
      "    Batch 47 / 129\n",
      "    Batch 48 / 129\n",
      "    Batch 49 / 129\n",
      "    Batch 50 / 129\n",
      "    Batch 51 / 129\n",
      "    Batch 52 / 129\n",
      "    Batch 53 / 129\n",
      "    Batch 54 / 129\n",
      "    Batch 55 / 129\n",
      "    Batch 56 / 129\n",
      "    Batch 57 / 129\n",
      "    Batch 58 / 129\n",
      "    Batch 59 / 129\n",
      "    Batch 60 / 129\n",
      "    Batch 61 / 129\n",
      "    Batch 62 / 129\n",
      "    Batch 63 / 129\n",
      "    Batch 64 / 129\n",
      "    Batch 65 / 129\n",
      "    Batch 66 / 129\n",
      "    Batch 67 / 129\n",
      "    Batch 68 / 129\n",
      "    Batch 69 / 129\n",
      "    Batch 70 / 129\n",
      "    Batch 71 / 129\n",
      "    Batch 72 / 129\n",
      "    Batch 73 / 129\n",
      "    Batch 74 / 129\n",
      "    Batch 75 / 129\n",
      "    Batch 76 / 129\n",
      "    Batch 77 / 129\n",
      "    Batch 78 / 129\n",
      "    Batch 79 / 129\n",
      "    Batch 80 / 129\n",
      "    Batch 81 / 129\n",
      "    Batch 82 / 129\n",
      "    Batch 83 / 129\n",
      "    Batch 84 / 129\n",
      "    Batch 85 / 129\n",
      "    Batch 86 / 129\n",
      "    Batch 87 / 129\n",
      "    Batch 88 / 129\n",
      "    Batch 89 / 129\n",
      "    Batch 90 / 129\n",
      "    Batch 91 / 129\n",
      "    Batch 92 / 129\n",
      "    Batch 93 / 129\n",
      "    Batch 94 / 129\n",
      "    Batch 95 / 129\n",
      "    Batch 96 / 129\n",
      "    Batch 97 / 129\n",
      "    Batch 98 / 129\n",
      "    Batch 99 / 129\n",
      "    Batch 100 / 129\n",
      "    Batch 101 / 129\n",
      "    Batch 102 / 129\n",
      "    Batch 103 / 129\n",
      "    Batch 104 / 129\n",
      "    Batch 105 / 129\n",
      "    Batch 106 / 129\n",
      "    Batch 107 / 129\n",
      "    Batch 108 / 129\n",
      "    Batch 109 / 129\n",
      "    Batch 110 / 129\n",
      "    Batch 111 / 129\n",
      "    Batch 112 / 129\n",
      "    Batch 113 / 129\n",
      "    Batch 114 / 129\n",
      "    Batch 115 / 129\n",
      "    Batch 116 / 129\n",
      "    Batch 117 / 129\n",
      "    Batch 118 / 129\n",
      "    Batch 119 / 129\n",
      "    Batch 120 / 129\n",
      "    Batch 121 / 129\n",
      "    Batch 122 / 129\n",
      "    Batch 123 / 129\n",
      "    Batch 124 / 129\n",
      "    Batch 125 / 129\n",
      "    Batch 126 / 129\n",
      "    Batch 127 / 129\n",
      "    Batch 128 / 129\n",
      "    Batch 129 / 129\n",
      "ROC-AUC score: 0.3506\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 3\n",
      "    Batch 3 / 129: loss 0.6937\n",
      "    ROC-AUC score: 0.3651\n",
      "    Batch 6 / 129: loss 0.6931\n",
      "    ROC-AUC score: 0.4353\n",
      "    Batch 9 / 129: loss 0.6933\n",
      "    ROC-AUC score: 0.5167\n",
      "    Batch 12 / 129: loss 0.6928\n",
      "    ROC-AUC score: 0.6389\n",
      "    Batch 15 / 129: loss 0.6922\n",
      "    ROC-AUC score: 0.7879\n",
      "    Batch 18 / 129: loss 0.6920\n",
      "    ROC-AUC score: 0.8462\n",
      "    Batch 21 / 129: loss 0.6918\n",
      "    ROC-AUC score: 0.7148\n",
      "    Batch 24 / 129: loss 0.6916\n",
      "    ROC-AUC score: 0.5708\n",
      "    Batch 27 / 129: loss 0.6907\n",
      "    ROC-AUC score: 0.7695\n",
      "    Batch 30 / 129: loss 0.6891\n",
      "    ROC-AUC score: 0.8167\n",
      "    Batch 33 / 129: loss 0.6884\n",
      "    ROC-AUC score: 0.7659\n",
      "    Batch 36 / 129: loss 0.6881\n",
      "    ROC-AUC score: 0.8138\n",
      "    Batch 39 / 129: loss 0.6868\n",
      "    ROC-AUC score: 0.6758\n",
      "    Batch 42 / 129: loss 0.6851\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 45 / 129: loss 0.6812\n",
      "    ROC-AUC score: 0.7935\n",
      "    Batch 48 / 129: loss 0.6852\n",
      "    ROC-AUC score: 0.7255\n",
      "    Batch 51 / 129: loss 0.6845\n",
      "    ROC-AUC score: 0.7222\n",
      "    Batch 54 / 129: loss 0.6769\n",
      "    ROC-AUC score: 0.8625\n",
      "    Batch 57 / 129: loss 0.6802\n",
      "    ROC-AUC score: 0.7656\n",
      "    Batch 60 / 129: loss 0.6744\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 63 / 129: loss 0.6770\n",
      "    ROC-AUC score: 0.7773\n",
      "    Batch 66 / 129: loss 0.6765\n",
      "    ROC-AUC score: 0.7246\n",
      "    Batch 69 / 129: loss 0.6781\n",
      "    ROC-AUC score: 0.6111\n",
      "    Batch 72 / 129: loss 0.6726\n",
      "    ROC-AUC score: 0.8057\n",
      "    Batch 75 / 129: loss 0.6714\n",
      "    ROC-AUC score: 0.7227\n",
      "    Batch 78 / 129: loss 0.6664\n",
      "    ROC-AUC score: 0.7804\n",
      "    Batch 81 / 129: loss 0.6704\n",
      "    ROC-AUC score: 0.8413\n",
      "    Batch 84 / 129: loss 0.6638\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 87 / 129: loss 0.6668\n",
      "    ROC-AUC score: 0.8588\n",
      "    Batch 90 / 129: loss 0.6598\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 93 / 129: loss 0.6655\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 96 / 129: loss 0.6631\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 99 / 129: loss 0.6689\n",
      "    ROC-AUC score: 0.7812\n",
      "    Batch 102 / 129: loss 0.6502\n",
      "    ROC-AUC score: 0.9042\n",
      "    Batch 105 / 129: loss 0.6553\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 108 / 129: loss 0.6558\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 111 / 129: loss 0.6307\n",
      "    ROC-AUC score: 0.9864\n",
      "    Batch 114 / 129: loss 0.6456\n",
      "    ROC-AUC score: 0.7895\n",
      "    Batch 117 / 129: loss 0.6473\n",
      "    ROC-AUC score: 0.6292\n",
      "    Batch 120 / 129: loss 0.6327\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 123 / 129: loss 0.6437\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 126 / 129: loss 0.6388\n",
      "    ROC-AUC score: 0.8359\n",
      "    Batch 129 / 129: loss 0.6542\n",
      "    ROC-AUC score: 0.5417\n",
      "Epoch 2 / 3\n",
      "    Batch 3 / 129: loss 0.6500\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 6 / 129: loss 0.6391\n",
      "    ROC-AUC score: 0.6980\n",
      "    Batch 9 / 129: loss 0.6534\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 12 / 129: loss 0.6443\n",
      "    ROC-AUC score: 0.7262\n",
      "    Batch 15 / 129: loss 0.6340\n",
      "    ROC-AUC score: 0.9004\n",
      "    Batch 18 / 129: loss 0.6294\n",
      "    ROC-AUC score: 0.8826\n",
      "    Batch 21 / 129: loss 0.6427\n",
      "    ROC-AUC score: 0.8672\n",
      "    Batch 24 / 129: loss 0.6361\n",
      "    ROC-AUC score: 0.8500\n",
      "    Batch 27 / 129: loss 0.6337\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 30 / 129: loss 0.6239\n",
      "    ROC-AUC score: 0.9250\n",
      "    Batch 33 / 129: loss 0.6214\n",
      "    ROC-AUC score: 0.9087\n",
      "    Batch 36 / 129: loss 0.6237\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 39 / 129: loss 0.6150\n",
      "    ROC-AUC score: 0.7695\n",
      "    Batch 42 / 129: loss 0.6136\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 45 / 129: loss 0.5962\n",
      "    ROC-AUC score: 0.8583\n",
      "    Batch 48 / 129: loss 0.6363\n",
      "    ROC-AUC score: 0.7216\n",
      "    Batch 51 / 129: loss 0.6293\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 54 / 129: loss 0.5927\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 57 / 129: loss 0.6160\n",
      "    ROC-AUC score: 0.8945\n",
      "    Batch 60 / 129: loss 0.5907\n",
      "    ROC-AUC score: 0.8785\n",
      "    Batch 63 / 129: loss 0.6114\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 66 / 129: loss 0.6129\n",
      "    ROC-AUC score: 0.7536\n",
      "    Batch 69 / 129: loss 0.6171\n",
      "    ROC-AUC score: 0.7302\n",
      "    Batch 72 / 129: loss 0.6063\n",
      "    ROC-AUC score: 0.8502\n",
      "    Batch 75 / 129: loss 0.6057\n",
      "    ROC-AUC score: 0.8008\n",
      "    Batch 78 / 129: loss 0.5868\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 81 / 129: loss 0.6088\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 84 / 129: loss 0.5862\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 87 / 129: loss 0.5992\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 90 / 129: loss 0.5790\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 93 / 129: loss 0.5993\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 96 / 129: loss 0.6038\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 99 / 129: loss 0.6170\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 102 / 129: loss 0.5638\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 105 / 129: loss 0.5843\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 108 / 129: loss 0.5881\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 111 / 129: loss 0.5246\n",
      "    ROC-AUC score: 0.9955\n",
      "    Batch 114 / 129: loss 0.5709\n",
      "    ROC-AUC score: 0.8381\n",
      "    Batch 117 / 129: loss 0.5746\n",
      "    ROC-AUC score: 0.7000\n",
      "    Batch 120 / 129: loss 0.5444\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 123 / 129: loss 0.5731\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 126 / 129: loss 0.5664\n",
      "    ROC-AUC score: 0.8711\n",
      "    Batch 129 / 129: loss 0.6093\n",
      "    ROC-AUC score: 0.6667\n",
      "Epoch 3 / 3\n",
      "    Batch 3 / 129: loss 0.5939\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 6 / 129: loss 0.5726\n",
      "    ROC-AUC score: 0.7412\n",
      "    Batch 9 / 129: loss 0.6040\n",
      "    ROC-AUC score: 0.8292\n",
      "    Batch 12 / 129: loss 0.5900\n",
      "    ROC-AUC score: 0.7897\n",
      "    Batch 15 / 129: loss 0.5752\n",
      "    ROC-AUC score: 0.9134\n",
      "    Batch 18 / 129: loss 0.5613\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 21 / 129: loss 0.5904\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 24 / 129: loss 0.5796\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 27 / 129: loss 0.5754\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 30 / 129: loss 0.5556\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 33 / 129: loss 0.5551\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 36 / 129: loss 0.5571\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 39 / 129: loss 0.5433\n",
      "    ROC-AUC score: 0.8086\n",
      "    Batch 42 / 129: loss 0.5450\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 45 / 129: loss 0.5186\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 48 / 129: loss 0.5887\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 51 / 129: loss 0.5797\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 54 / 129: loss 0.5169\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 57 / 129: loss 0.5584\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 60 / 129: loss 0.5195\n",
      "    ROC-AUC score: 0.9109\n",
      "    Batch 63 / 129: loss 0.5564\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 66 / 129: loss 0.5616\n",
      "    ROC-AUC score: 0.7633\n",
      "    Batch 69 / 129: loss 0.5636\n",
      "    ROC-AUC score: 0.7817\n",
      "    Batch 72 / 129: loss 0.5570\n",
      "    ROC-AUC score: 0.8826\n",
      "    Batch 75 / 129: loss 0.5523\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 78 / 129: loss 0.5252\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 81 / 129: loss 0.5571\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 84 / 129: loss 0.5271\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 87 / 129: loss 0.5473\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 90 / 129: loss 0.5178\n",
      "    ROC-AUC score: 0.9190\n",
      "    Batch 93 / 129: loss 0.5531\n",
      "    ROC-AUC score: 0.9250\n",
      "    Batch 96 / 129: loss 0.5636\n",
      "    ROC-AUC score: 0.8413\n",
      "    Batch 99 / 129: loss 0.5776\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 102 / 129: loss 0.5019\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 105 / 129: loss 0.5346\n",
      "    ROC-AUC score: 0.9766\n",
      "    Batch 108 / 129: loss 0.5380\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 111 / 129: loss 0.4537\n",
      "    ROC-AUC score: 0.9955\n",
      "    Batch 114 / 129: loss 0.5195\n",
      "    ROC-AUC score: 0.8704\n",
      "    Batch 117 / 129: loss 0.5229\n",
      "    ROC-AUC score: 0.7875\n",
      "    Batch 120 / 129: loss 0.4876\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 123 / 129: loss 0.5296\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 126 / 129: loss 0.5198\n",
      "    ROC-AUC score: 0.8867\n",
      "    Batch 129 / 129: loss 0.5870\n",
      "    ROC-AUC score: 0.6667\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 80], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 129\n",
      "    Batch 2 / 129\n",
      "    Batch 3 / 129\n",
      "    Batch 4 / 129\n",
      "    Batch 5 / 129\n",
      "    Batch 6 / 129\n",
      "    Batch 7 / 129\n",
      "    Batch 8 / 129\n",
      "    Batch 9 / 129\n",
      "    Batch 10 / 129\n",
      "    Batch 11 / 129\n",
      "    Batch 12 / 129\n",
      "    Batch 13 / 129\n",
      "    Batch 14 / 129\n",
      "    Batch 15 / 129\n",
      "    Batch 16 / 129\n",
      "    Batch 17 / 129\n",
      "    Batch 18 / 129\n",
      "    Batch 19 / 129\n",
      "    Batch 20 / 129\n",
      "    Batch 21 / 129\n",
      "    Batch 22 / 129\n",
      "    Batch 23 / 129\n",
      "    Batch 24 / 129\n",
      "    Batch 25 / 129\n",
      "    Batch 26 / 129\n",
      "    Batch 27 / 129\n",
      "    Batch 28 / 129\n",
      "    Batch 29 / 129\n",
      "    Batch 30 / 129\n",
      "    Batch 31 / 129\n",
      "    Batch 32 / 129\n",
      "    Batch 33 / 129\n",
      "    Batch 34 / 129\n",
      "    Batch 35 / 129\n",
      "    Batch 36 / 129\n",
      "    Batch 37 / 129\n",
      "    Batch 38 / 129\n",
      "    Batch 39 / 129\n",
      "    Batch 40 / 129\n",
      "    Batch 41 / 129\n",
      "    Batch 42 / 129\n",
      "    Batch 43 / 129\n",
      "    Batch 44 / 129\n",
      "    Batch 45 / 129\n",
      "    Batch 46 / 129\n",
      "    Batch 47 / 129\n",
      "    Batch 48 / 129\n",
      "    Batch 49 / 129\n",
      "    Batch 50 / 129\n",
      "    Batch 51 / 129\n",
      "    Batch 52 / 129\n",
      "    Batch 53 / 129\n",
      "    Batch 54 / 129\n",
      "    Batch 55 / 129\n",
      "    Batch 56 / 129\n",
      "    Batch 57 / 129\n",
      "    Batch 58 / 129\n",
      "    Batch 59 / 129\n",
      "    Batch 60 / 129\n",
      "    Batch 61 / 129\n",
      "    Batch 62 / 129\n",
      "    Batch 63 / 129\n",
      "    Batch 64 / 129\n",
      "    Batch 65 / 129\n",
      "    Batch 66 / 129\n",
      "    Batch 67 / 129\n",
      "    Batch 68 / 129\n",
      "    Batch 69 / 129\n",
      "    Batch 70 / 129\n",
      "    Batch 71 / 129\n",
      "    Batch 72 / 129\n",
      "    Batch 73 / 129\n",
      "    Batch 74 / 129\n",
      "    Batch 75 / 129\n",
      "    Batch 76 / 129\n",
      "    Batch 77 / 129\n",
      "    Batch 78 / 129\n",
      "    Batch 79 / 129\n",
      "    Batch 80 / 129\n",
      "    Batch 81 / 129\n",
      "    Batch 82 / 129\n",
      "    Batch 83 / 129\n",
      "    Batch 84 / 129\n",
      "    Batch 85 / 129\n",
      "    Batch 86 / 129\n",
      "    Batch 87 / 129\n",
      "    Batch 88 / 129\n",
      "    Batch 89 / 129\n",
      "    Batch 90 / 129\n",
      "    Batch 91 / 129\n",
      "    Batch 92 / 129\n",
      "    Batch 93 / 129\n",
      "    Batch 94 / 129\n",
      "    Batch 95 / 129\n",
      "    Batch 96 / 129\n",
      "    Batch 97 / 129\n",
      "    Batch 98 / 129\n",
      "    Batch 99 / 129\n",
      "    Batch 100 / 129\n",
      "    Batch 101 / 129\n",
      "    Batch 102 / 129\n",
      "    Batch 103 / 129\n",
      "    Batch 104 / 129\n",
      "    Batch 105 / 129\n",
      "    Batch 106 / 129\n",
      "    Batch 107 / 129\n",
      "    Batch 108 / 129\n",
      "    Batch 109 / 129\n",
      "    Batch 110 / 129\n",
      "    Batch 111 / 129\n",
      "    Batch 112 / 129\n",
      "    Batch 113 / 129\n",
      "    Batch 114 / 129\n",
      "    Batch 115 / 129\n",
      "    Batch 116 / 129\n",
      "    Batch 117 / 129\n",
      "    Batch 118 / 129\n",
      "    Batch 119 / 129\n",
      "    Batch 120 / 129\n",
      "    Batch 121 / 129\n",
      "    Batch 122 / 129\n",
      "    Batch 123 / 129\n",
      "    Batch 124 / 129\n",
      "    Batch 125 / 129\n",
      "    Batch 126 / 129\n",
      "    Batch 127 / 129\n",
      "    Batch 128 / 129\n",
      "    Batch 129 / 129\n",
      "ROC-AUC score: 0.8955\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 129\n",
      "    Batch 2 / 129\n",
      "    Batch 3 / 129\n",
      "    Batch 4 / 129\n",
      "    Batch 5 / 129\n",
      "    Batch 6 / 129\n",
      "    Batch 7 / 129\n",
      "    Batch 8 / 129\n",
      "    Batch 9 / 129\n",
      "    Batch 10 / 129\n",
      "    Batch 11 / 129\n",
      "    Batch 12 / 129\n",
      "    Batch 13 / 129\n",
      "    Batch 14 / 129\n",
      "    Batch 15 / 129\n",
      "    Batch 16 / 129\n",
      "    Batch 17 / 129\n",
      "    Batch 18 / 129\n",
      "    Batch 19 / 129\n",
      "    Batch 20 / 129\n",
      "    Batch 21 / 129\n",
      "    Batch 22 / 129\n",
      "    Batch 23 / 129\n",
      "    Batch 24 / 129\n",
      "    Batch 25 / 129\n",
      "    Batch 26 / 129\n",
      "    Batch 27 / 129\n",
      "    Batch 28 / 129\n",
      "    Batch 29 / 129\n",
      "    Batch 30 / 129\n",
      "    Batch 31 / 129\n",
      "    Batch 32 / 129\n",
      "    Batch 33 / 129\n",
      "    Batch 34 / 129\n",
      "    Batch 35 / 129\n",
      "    Batch 36 / 129\n",
      "    Batch 37 / 129\n",
      "    Batch 38 / 129\n",
      "    Batch 39 / 129\n",
      "    Batch 40 / 129\n",
      "    Batch 41 / 129\n",
      "    Batch 42 / 129\n",
      "    Batch 43 / 129\n",
      "    Batch 44 / 129\n",
      "    Batch 45 / 129\n",
      "    Batch 46 / 129\n",
      "    Batch 47 / 129\n",
      "    Batch 48 / 129\n",
      "    Batch 49 / 129\n",
      "    Batch 50 / 129\n",
      "    Batch 51 / 129\n",
      "    Batch 52 / 129\n",
      "    Batch 53 / 129\n",
      "    Batch 54 / 129\n",
      "    Batch 55 / 129\n",
      "    Batch 56 / 129\n",
      "    Batch 57 / 129\n",
      "    Batch 58 / 129\n",
      "    Batch 59 / 129\n",
      "    Batch 60 / 129\n",
      "    Batch 61 / 129\n",
      "    Batch 62 / 129\n",
      "    Batch 63 / 129\n",
      "    Batch 64 / 129\n",
      "    Batch 65 / 129\n",
      "    Batch 66 / 129\n",
      "    Batch 67 / 129\n",
      "    Batch 68 / 129\n",
      "    Batch 69 / 129\n",
      "    Batch 70 / 129\n",
      "    Batch 71 / 129\n",
      "    Batch 72 / 129\n",
      "    Batch 73 / 129\n",
      "    Batch 74 / 129\n",
      "    Batch 75 / 129\n",
      "    Batch 76 / 129\n",
      "    Batch 77 / 129\n",
      "    Batch 78 / 129\n",
      "    Batch 79 / 129\n",
      "    Batch 80 / 129\n",
      "    Batch 81 / 129\n",
      "    Batch 82 / 129\n",
      "    Batch 83 / 129\n",
      "    Batch 84 / 129\n",
      "    Batch 85 / 129\n",
      "    Batch 86 / 129\n",
      "    Batch 87 / 129\n",
      "    Batch 88 / 129\n",
      "    Batch 89 / 129\n",
      "    Batch 90 / 129\n",
      "    Batch 91 / 129\n",
      "    Batch 92 / 129\n",
      "    Batch 93 / 129\n",
      "    Batch 94 / 129\n",
      "    Batch 95 / 129\n",
      "    Batch 96 / 129\n",
      "    Batch 97 / 129\n",
      "    Batch 98 / 129\n",
      "    Batch 99 / 129\n",
      "    Batch 100 / 129\n",
      "    Batch 101 / 129\n",
      "    Batch 102 / 129\n",
      "    Batch 103 / 129\n",
      "    Batch 104 / 129\n",
      "    Batch 105 / 129\n",
      "    Batch 106 / 129\n",
      "    Batch 107 / 129\n",
      "    Batch 108 / 129\n",
      "    Batch 109 / 129\n",
      "    Batch 110 / 129\n",
      "    Batch 111 / 129\n",
      "    Batch 112 / 129\n",
      "    Batch 113 / 129\n",
      "    Batch 114 / 129\n",
      "    Batch 115 / 129\n",
      "    Batch 116 / 129\n",
      "    Batch 117 / 129\n",
      "    Batch 118 / 129\n",
      "    Batch 119 / 129\n",
      "    Batch 120 / 129\n",
      "    Batch 121 / 129\n",
      "    Batch 122 / 129\n",
      "    Batch 123 / 129\n",
      "    Batch 124 / 129\n",
      "    Batch 125 / 129\n",
      "    Batch 126 / 129\n",
      "    Batch 127 / 129\n",
      "    Batch 128 / 129\n",
      "    Batch 129 / 129\n",
      "Threshold: 0.2140, accuracy: 0.8320\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.83      0.83      2053\n",
      "         1.0       0.83      0.83      0.83      2053\n",
      "\n",
      "    accuracy                           0.83      4106\n",
      "   macro avg       0.83      0.83      0.83      4106\n",
      "weighted avg       0.83      0.83      0.83      4106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 4106\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 129: loss 0.5067, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 6 / 129: loss 0.5235, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8259\n",
      "    Batch 9 / 129: loss 0.5283, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8250\n",
      "    Batch 12 / 129: loss 0.5058, accuracy 0.8125\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 15 / 129: loss 0.5745, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 18 / 129: loss 0.4606, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 21 / 129: loss 0.5150, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 24 / 129: loss 0.5327, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 27 / 129: loss 0.5020, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 30 / 129: loss 0.5364, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9246\n",
      "    Batch 33 / 129: loss 0.5597, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 36 / 129: loss 0.5482, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 39 / 129: loss 0.5397, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8788\n",
      "    Batch 42 / 129: loss 0.5252, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8502\n",
      "    Batch 45 / 129: loss 0.5560, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9180\n",
      "    Batch 48 / 129: loss 0.5715, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8409\n",
      "    Batch 51 / 129: loss 0.4885, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9087\n",
      "    Batch 54 / 129: loss 0.5670, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8615\n",
      "    Batch 57 / 129: loss 0.5299, accuracy 0.8229\n",
      "    ROC-AUC score: 0.7542\n",
      "    Batch 60 / 129: loss 0.5373, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8502\n",
      "    Batch 63 / 129: loss 0.5227, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 66 / 129: loss 0.5060, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9087\n",
      "    Batch 69 / 129: loss 0.5852, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 72 / 129: loss 0.5152, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 75 / 129: loss 0.5174, accuracy 0.8021\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 78 / 129: loss 0.4920, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 81 / 129: loss 0.5806, accuracy 0.8438\n",
      "    ROC-AUC score: 0.7895\n",
      "    Batch 84 / 129: loss 0.5484, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 87 / 129: loss 0.5449, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 90 / 129: loss 0.5655, accuracy 0.7708\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 93 / 129: loss 0.5439, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8958\n",
      "    Batch 96 / 129: loss 0.5295, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 99 / 129: loss 0.5133, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 102 / 129: loss 0.5431, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8442\n",
      "    Batch 105 / 129: loss 0.5193, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 108 / 129: loss 0.4990, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9246\n",
      "    Batch 111 / 129: loss 0.5236, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 114 / 129: loss 0.5177, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 117 / 129: loss 0.5023, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 120 / 129: loss 0.5311, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 123 / 129: loss 0.5726, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 126 / 129: loss 0.4967, accuracy 0.9062\n",
      "    ROC-AUC score: 0.8810\n",
      "    Batch 129 / 129: loss 0.5595, accuracy 0.7973\n",
      "    ROC-AUC score: 0.8000\n",
      "Loss 0.5311, accuracy 0.8356\n",
      "ROC-AUC score: 0.8918\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.83      0.83      2053\n",
      "         1.0       0.83      0.84      0.84      2053\n",
      "\n",
      "    accuracy                           0.84      4106\n",
      "   macro avg       0.84      0.84      0.84      4106\n",
      "weighted avg       0.84      0.84      0.84      4106\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
