{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : False,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : True,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 6,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 5e-4,\n",
    "    \"weight_decay\" : 5e-3,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 3124\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=274, out_features=274, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=548, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "agg_class = utils.get_agg_class(config['agg_class'])\n",
    "model = models.GraphSAGE(input_dim, config['hidden_dims'],\n",
    "                         output_dim, config['dropout'],\n",
    "                         agg_class, config['num_samples'],\n",
    "                         config['device'])\n",
    "model.to(config['device'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 98\n",
      "    Batch 2 / 98\n",
      "    Batch 3 / 98\n",
      "    Batch 4 / 98\n",
      "    Batch 5 / 98\n",
      "    Batch 6 / 98\n",
      "    Batch 7 / 98\n",
      "    Batch 8 / 98\n",
      "    Batch 9 / 98\n",
      "    Batch 10 / 98\n",
      "    Batch 11 / 98\n",
      "    Batch 12 / 98\n",
      "    Batch 13 / 98\n",
      "    Batch 14 / 98\n",
      "    Batch 15 / 98\n",
      "    Batch 16 / 98\n",
      "    Batch 17 / 98\n",
      "    Batch 18 / 98\n",
      "    Batch 19 / 98\n",
      "    Batch 20 / 98\n",
      "    Batch 21 / 98\n",
      "    Batch 22 / 98\n",
      "    Batch 23 / 98\n",
      "    Batch 24 / 98\n",
      "    Batch 25 / 98\n",
      "    Batch 26 / 98\n",
      "    Batch 27 / 98\n",
      "    Batch 28 / 98\n",
      "    Batch 29 / 98\n",
      "    Batch 30 / 98\n",
      "    Batch 31 / 98\n",
      "    Batch 32 / 98\n",
      "    Batch 33 / 98\n",
      "    Batch 34 / 98\n",
      "    Batch 35 / 98\n",
      "    Batch 36 / 98\n",
      "    Batch 37 / 98\n",
      "    Batch 38 / 98\n",
      "    Batch 39 / 98\n",
      "    Batch 40 / 98\n",
      "    Batch 41 / 98\n",
      "    Batch 42 / 98\n",
      "    Batch 43 / 98\n",
      "    Batch 44 / 98\n",
      "    Batch 45 / 98\n",
      "    Batch 46 / 98\n",
      "    Batch 47 / 98\n",
      "    Batch 48 / 98\n",
      "    Batch 49 / 98\n",
      "    Batch 50 / 98\n",
      "    Batch 51 / 98\n",
      "    Batch 52 / 98\n",
      "    Batch 53 / 98\n",
      "    Batch 54 / 98\n",
      "    Batch 55 / 98\n",
      "    Batch 56 / 98\n",
      "    Batch 57 / 98\n",
      "    Batch 58 / 98\n",
      "    Batch 59 / 98\n",
      "    Batch 60 / 98\n",
      "    Batch 61 / 98\n",
      "    Batch 62 / 98\n",
      "    Batch 63 / 98\n",
      "    Batch 64 / 98\n",
      "    Batch 65 / 98\n",
      "    Batch 66 / 98\n",
      "    Batch 67 / 98\n",
      "    Batch 68 / 98\n",
      "    Batch 69 / 98\n",
      "    Batch 70 / 98\n",
      "    Batch 71 / 98\n",
      "    Batch 72 / 98\n",
      "    Batch 73 / 98\n",
      "    Batch 74 / 98\n",
      "    Batch 75 / 98\n",
      "    Batch 76 / 98\n",
      "    Batch 77 / 98\n",
      "    Batch 78 / 98\n",
      "    Batch 79 / 98\n",
      "    Batch 80 / 98\n",
      "    Batch 81 / 98\n",
      "    Batch 82 / 98\n",
      "    Batch 83 / 98\n",
      "    Batch 84 / 98\n",
      "    Batch 85 / 98\n",
      "    Batch 86 / 98\n",
      "    Batch 87 / 98\n",
      "    Batch 88 / 98\n",
      "    Batch 89 / 98\n",
      "    Batch 90 / 98\n",
      "    Batch 91 / 98\n",
      "    Batch 92 / 98\n",
      "    Batch 93 / 98\n",
      "    Batch 94 / 98\n",
      "    Batch 95 / 98\n",
      "    Batch 96 / 98\n",
      "    Batch 97 / 98\n",
      "    Batch 98 / 98\n",
      "ROC-AUC score: 0.5672\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 6\n",
      "    Batch 3 / 98: loss 0.6927\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 6 / 98: loss 0.6902\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 98: loss 0.6863\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 12 / 98: loss 0.6778\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 15 / 98: loss 0.6768\n",
      "    ROC-AUC score: 0.7854\n",
      "    Batch 18 / 98: loss 0.6678\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 21 / 98: loss 0.6547\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 98: loss 0.6497\n",
      "    ROC-AUC score: 0.8320\n",
      "    Batch 27 / 98: loss 0.6427\n",
      "    ROC-AUC score: 0.8826\n",
      "    Batch 30 / 98: loss 0.6306\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 33 / 98: loss 0.6072\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 36 / 98: loss 0.6030\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 39 / 98: loss 0.5872\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 42 / 98: loss 0.5890\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 45 / 98: loss 0.5578\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 48 / 98: loss 0.5263\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 98: loss 0.5501\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 54 / 98: loss 0.4808\n",
      "    ROC-AUC score: 0.9913\n",
      "    Batch 57 / 98: loss 0.4934\n",
      "    ROC-AUC score: 0.9500\n",
      "    Batch 60 / 98: loss 0.4812\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 63 / 98: loss 0.4469\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 66 / 98: loss 0.4342\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 69 / 98: loss 0.4170\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 72 / 98: loss 0.4709\n",
      "    ROC-AUC score: 0.9792\n",
      "    Batch 75 / 98: loss 0.4363\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 78 / 98: loss 0.4565\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 81 / 98: loss 0.3648\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 84 / 98: loss 0.4186\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 87 / 98: loss 0.4022\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 98: loss 0.4483\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 93 / 98: loss 0.3637\n",
      "    ROC-AUC score: 0.9591\n",
      "    Batch 96 / 98: loss 0.3891\n",
      "    ROC-AUC score: 0.9569\n",
      "Epoch 2 / 6\n",
      "    Batch 3 / 98: loss 0.3815\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 6 / 98: loss 0.3517\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 9 / 98: loss 0.4011\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 98: loss 0.3755\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 15 / 98: loss 0.3743\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 98: loss 0.3206\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 98: loss 0.4069\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 98: loss 0.3236\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 98: loss 0.3162\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 30 / 98: loss 0.3899\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 98: loss 0.3599\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 36 / 98: loss 0.4051\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 39 / 98: loss 0.3689\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 42 / 98: loss 0.4068\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 45 / 98: loss 0.4124\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 48 / 98: loss 0.3786\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 98: loss 0.3371\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 98: loss 0.3793\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 57 / 98: loss 0.4031\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 60 / 98: loss 0.4057\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 63 / 98: loss 0.3552\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 66 / 98: loss 0.3583\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 69 / 98: loss 0.3232\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 98: loss 0.4031\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 98: loss 0.3696\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 78 / 98: loss 0.3889\n",
      "    ROC-AUC score: 0.9545\n",
      "    Batch 81 / 98: loss 0.3945\n",
      "    ROC-AUC score: 0.9955\n",
      "    Batch 84 / 98: loss 0.3304\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 87 / 98: loss 0.3535\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 98: loss 0.3107\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 93 / 98: loss 0.4106\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 98: loss 0.3931\n",
      "    ROC-AUC score: 0.9960\n",
      "Epoch 3 / 6\n",
      "    Batch 3 / 98: loss 0.3137\n",
      "    ROC-AUC score: 0.9784\n",
      "    Batch 6 / 98: loss 0.3327\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 98: loss 0.3228\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 98: loss 0.3992\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 15 / 98: loss 0.3502\n",
      "    ROC-AUC score: 0.9595\n",
      "    Batch 18 / 98: loss 0.3415\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 21 / 98: loss 0.3520\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 98: loss 0.3759\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 98: loss 0.3245\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 30 / 98: loss 0.3702\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 98: loss 0.3272\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 98: loss 0.4017\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 39 / 98: loss 0.4622\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 42 / 98: loss 0.4088\n",
      "    ROC-AUC score: 0.9805\n",
      "    Batch 45 / 98: loss 0.3809\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 48 / 98: loss 0.3927\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 51 / 98: loss 0.4354\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 54 / 98: loss 0.3638\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 57 / 98: loss 0.3720\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 60 / 98: loss 0.2776\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 63 / 98: loss 0.3989\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 66 / 98: loss 0.3338\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 69 / 98: loss 0.3082\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 98: loss 0.3788\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 98: loss 0.3432\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 78 / 98: loss 0.4169\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 81 / 98: loss 0.3203\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 84 / 98: loss 0.3176\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 87 / 98: loss 0.2980\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 98: loss 0.2741\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 93 / 98: loss 0.3347\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 98: loss 0.2992\n",
      "    ROC-AUC score: 1.0000\n",
      "Epoch 4 / 6\n",
      "    Batch 3 / 98: loss 0.3112\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 6 / 98: loss 0.3196\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 98: loss 0.3269\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 98: loss 0.3703\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 15 / 98: loss 0.2932\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 98: loss 0.2549\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 98: loss 0.3405\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 98: loss 0.2922\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 98: loss 0.3533\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 30 / 98: loss 0.2832\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 33 / 98: loss 0.2897\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 98: loss 0.3690\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 39 / 98: loss 0.4105\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 42 / 98: loss 0.3554\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 45 / 98: loss 0.3789\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 48 / 98: loss 0.3405\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 98: loss 0.3501\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 98: loss 0.3503\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 57 / 98: loss 0.3760\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 60 / 98: loss 0.4085\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 63 / 98: loss 0.3408\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 66 / 98: loss 0.2998\n",
      "    ROC-AUC score: 0.9903\n",
      "    Batch 69 / 98: loss 0.3416\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 72 / 98: loss 0.3119\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 98: loss 0.3173\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 78 / 98: loss 0.3685\n",
      "    ROC-AUC score: 0.9531\n",
      "    Batch 81 / 98: loss 0.2662\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 84 / 98: loss 0.4011\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 87 / 98: loss 0.4255\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 90 / 98: loss 0.4606\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 93 / 98: loss 0.3532\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 98: loss 0.3964\n",
      "    ROC-AUC score: 0.9960\n",
      "Epoch 5 / 6\n",
      "    Batch 3 / 98: loss 0.3324\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 6 / 98: loss 0.4238\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 98: loss 0.3139\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 98: loss 0.3731\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 15 / 98: loss 0.3270\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 18 / 98: loss 0.3968\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 98: loss 0.2889\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 98: loss 0.3290\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 98: loss 0.2874\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 30 / 98: loss 0.3007\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 33 / 98: loss 0.3929\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 98: loss 0.3923\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 39 / 98: loss 0.4426\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 42 / 98: loss 0.3354\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 45 / 98: loss 0.3311\n",
      "    ROC-AUC score: 0.9762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 48 / 98: loss 0.3190\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 51 / 98: loss 0.3667\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 98: loss 0.3384\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 57 / 98: loss 0.3245\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 60 / 98: loss 0.2857\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 63 / 98: loss 0.3131\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 66 / 98: loss 0.2741\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 69 / 98: loss 0.2889\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 98: loss 0.3680\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 98: loss 0.3652\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 78 / 98: loss 0.3050\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 81 / 98: loss 0.3577\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 84 / 98: loss 0.3563\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 87 / 98: loss 0.3241\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 98: loss 0.3114\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 93 / 98: loss 0.3161\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 98: loss 0.3158\n",
      "    ROC-AUC score: 1.0000\n",
      "Epoch 6 / 6\n",
      "    Batch 3 / 98: loss 0.2964\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 6 / 98: loss 0.3812\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 9 / 98: loss 0.2921\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 98: loss 0.3917\n",
      "    ROC-AUC score: 0.9500\n",
      "    Batch 15 / 98: loss 0.2533\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 98: loss 0.2913\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 98: loss 0.3072\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 98: loss 0.3550\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 27 / 98: loss 0.2451\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 30 / 98: loss 0.4043\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 98: loss 0.3493\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 98: loss 0.3834\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 39 / 98: loss 0.3241\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 42 / 98: loss 0.3333\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 45 / 98: loss 0.2867\n",
      "    ROC-AUC score: 0.9688\n",
      "    Batch 48 / 98: loss 0.3099\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 98: loss 0.2923\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 98: loss 0.4432\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 57 / 98: loss 0.3671\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 60 / 98: loss 0.3918\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 63 / 98: loss 0.4067\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 66 / 98: loss 0.2840\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 69 / 98: loss 0.2627\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 98: loss 0.3652\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 98: loss 0.4015\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 78 / 98: loss 0.3431\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 81 / 98: loss 0.3271\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 84 / 98: loss 0.3445\n",
      "    ROC-AUC score: 0.9909\n",
      "    Batch 87 / 98: loss 0.3450\n",
      "    ROC-AUC score: 0.9827\n",
      "    Batch 90 / 98: loss 0.2790\n",
      "    ROC-AUC score: 0.9595\n",
      "    Batch 93 / 98: loss 0.3216\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 98: loss 0.3022\n",
      "    ROC-AUC score: 1.0000\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 400], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 98\n",
      "    Batch 2 / 98\n",
      "    Batch 3 / 98\n",
      "    Batch 4 / 98\n",
      "    Batch 5 / 98\n",
      "    Batch 6 / 98\n",
      "    Batch 7 / 98\n",
      "    Batch 8 / 98\n",
      "    Batch 9 / 98\n",
      "    Batch 10 / 98\n",
      "    Batch 11 / 98\n",
      "    Batch 12 / 98\n",
      "    Batch 13 / 98\n",
      "    Batch 14 / 98\n",
      "    Batch 15 / 98\n",
      "    Batch 16 / 98\n",
      "    Batch 17 / 98\n",
      "    Batch 18 / 98\n",
      "    Batch 19 / 98\n",
      "    Batch 20 / 98\n",
      "    Batch 21 / 98\n",
      "    Batch 22 / 98\n",
      "    Batch 23 / 98\n",
      "    Batch 24 / 98\n",
      "    Batch 25 / 98\n",
      "    Batch 26 / 98\n",
      "    Batch 27 / 98\n",
      "    Batch 28 / 98\n",
      "    Batch 29 / 98\n",
      "    Batch 30 / 98\n",
      "    Batch 31 / 98\n",
      "    Batch 32 / 98\n",
      "    Batch 33 / 98\n",
      "    Batch 34 / 98\n",
      "    Batch 35 / 98\n",
      "    Batch 36 / 98\n",
      "    Batch 37 / 98\n",
      "    Batch 38 / 98\n",
      "    Batch 39 / 98\n",
      "    Batch 40 / 98\n",
      "    Batch 41 / 98\n",
      "    Batch 42 / 98\n",
      "    Batch 43 / 98\n",
      "    Batch 44 / 98\n",
      "    Batch 45 / 98\n",
      "    Batch 46 / 98\n",
      "    Batch 47 / 98\n",
      "    Batch 48 / 98\n",
      "    Batch 49 / 98\n",
      "    Batch 50 / 98\n",
      "    Batch 51 / 98\n",
      "    Batch 52 / 98\n",
      "    Batch 53 / 98\n",
      "    Batch 54 / 98\n",
      "    Batch 55 / 98\n",
      "    Batch 56 / 98\n",
      "    Batch 57 / 98\n",
      "    Batch 58 / 98\n",
      "    Batch 59 / 98\n",
      "    Batch 60 / 98\n",
      "    Batch 61 / 98\n",
      "    Batch 62 / 98\n",
      "    Batch 63 / 98\n",
      "    Batch 64 / 98\n",
      "    Batch 65 / 98\n",
      "    Batch 66 / 98\n",
      "    Batch 67 / 98\n",
      "    Batch 68 / 98\n",
      "    Batch 69 / 98\n",
      "    Batch 70 / 98\n",
      "    Batch 71 / 98\n",
      "    Batch 72 / 98\n",
      "    Batch 73 / 98\n",
      "    Batch 74 / 98\n",
      "    Batch 75 / 98\n",
      "    Batch 76 / 98\n",
      "    Batch 77 / 98\n",
      "    Batch 78 / 98\n",
      "    Batch 79 / 98\n",
      "    Batch 80 / 98\n",
      "    Batch 81 / 98\n",
      "    Batch 82 / 98\n",
      "    Batch 83 / 98\n",
      "    Batch 84 / 98\n",
      "    Batch 85 / 98\n",
      "    Batch 86 / 98\n",
      "    Batch 87 / 98\n",
      "    Batch 88 / 98\n",
      "    Batch 89 / 98\n",
      "    Batch 90 / 98\n",
      "    Batch 91 / 98\n",
      "    Batch 92 / 98\n",
      "    Batch 93 / 98\n",
      "    Batch 94 / 98\n",
      "    Batch 95 / 98\n",
      "    Batch 96 / 98\n",
      "    Batch 97 / 98\n",
      "    Batch 98 / 98\n",
      "ROC-AUC score: 0.9912\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 98\n",
      "    Batch 2 / 98\n",
      "    Batch 3 / 98\n",
      "    Batch 4 / 98\n",
      "    Batch 5 / 98\n",
      "    Batch 6 / 98\n",
      "    Batch 7 / 98\n",
      "    Batch 8 / 98\n",
      "    Batch 9 / 98\n",
      "    Batch 10 / 98\n",
      "    Batch 11 / 98\n",
      "    Batch 12 / 98\n",
      "    Batch 13 / 98\n",
      "    Batch 14 / 98\n",
      "    Batch 15 / 98\n",
      "    Batch 16 / 98\n",
      "    Batch 17 / 98\n",
      "    Batch 18 / 98\n",
      "    Batch 19 / 98\n",
      "    Batch 20 / 98\n",
      "    Batch 21 / 98\n",
      "    Batch 22 / 98\n",
      "    Batch 23 / 98\n",
      "    Batch 24 / 98\n",
      "    Batch 25 / 98\n",
      "    Batch 26 / 98\n",
      "    Batch 27 / 98\n",
      "    Batch 28 / 98\n",
      "    Batch 29 / 98\n",
      "    Batch 30 / 98\n",
      "    Batch 31 / 98\n",
      "    Batch 32 / 98\n",
      "    Batch 33 / 98\n",
      "    Batch 34 / 98\n",
      "    Batch 35 / 98\n",
      "    Batch 36 / 98\n",
      "    Batch 37 / 98\n",
      "    Batch 38 / 98\n",
      "    Batch 39 / 98\n",
      "    Batch 40 / 98\n",
      "    Batch 41 / 98\n",
      "    Batch 42 / 98\n",
      "    Batch 43 / 98\n",
      "    Batch 44 / 98\n",
      "    Batch 45 / 98\n",
      "    Batch 46 / 98\n",
      "    Batch 47 / 98\n",
      "    Batch 48 / 98\n",
      "    Batch 49 / 98\n",
      "    Batch 50 / 98\n",
      "    Batch 51 / 98\n",
      "    Batch 52 / 98\n",
      "    Batch 53 / 98\n",
      "    Batch 54 / 98\n",
      "    Batch 55 / 98\n",
      "    Batch 56 / 98\n",
      "    Batch 57 / 98\n",
      "    Batch 58 / 98\n",
      "    Batch 59 / 98\n",
      "    Batch 60 / 98\n",
      "    Batch 61 / 98\n",
      "    Batch 62 / 98\n",
      "    Batch 63 / 98\n",
      "    Batch 64 / 98\n",
      "    Batch 65 / 98\n",
      "    Batch 66 / 98\n",
      "    Batch 67 / 98\n",
      "    Batch 68 / 98\n",
      "    Batch 69 / 98\n",
      "    Batch 70 / 98\n",
      "    Batch 71 / 98\n",
      "    Batch 72 / 98\n",
      "    Batch 73 / 98\n",
      "    Batch 74 / 98\n",
      "    Batch 75 / 98\n",
      "    Batch 76 / 98\n",
      "    Batch 77 / 98\n",
      "    Batch 78 / 98\n",
      "    Batch 79 / 98\n",
      "    Batch 80 / 98\n",
      "    Batch 81 / 98\n",
      "    Batch 82 / 98\n",
      "    Batch 83 / 98\n",
      "    Batch 84 / 98\n",
      "    Batch 85 / 98\n",
      "    Batch 86 / 98\n",
      "    Batch 87 / 98\n",
      "    Batch 88 / 98\n",
      "    Batch 89 / 98\n",
      "    Batch 90 / 98\n",
      "    Batch 91 / 98\n",
      "    Batch 92 / 98\n",
      "    Batch 93 / 98\n",
      "    Batch 94 / 98\n",
      "    Batch 95 / 98\n",
      "    Batch 96 / 98\n",
      "    Batch 97 / 98\n",
      "    Batch 98 / 98\n",
      "Threshold: 0.9491, accuracy: 0.9706\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97      1562\n",
      "         1.0       0.97      0.97      0.97      1562\n",
      "\n",
      "    accuracy                           0.97      3124\n",
      "   macro avg       0.97      0.97      0.97      3124\n",
      "weighted avg       0.97      0.97      0.97      3124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: val\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2112\n",
      "Number of temporal edges: 14122\n",
      "Number of examples/datapoints: 3408\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the validation dataset after training.\n",
      "    Batch 3 / 107: loss 0.4934, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 6 / 107: loss 0.4467, accuracy 0.9062\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 107: loss 0.5205, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 12 / 107: loss 0.5721, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 15 / 107: loss 0.4199, accuracy 0.9062\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 107: loss 0.5719, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 21 / 107: loss 0.4298, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 24 / 107: loss 0.5063, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 27 / 107: loss 0.4012, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9292\n",
      "    Batch 30 / 107: loss 0.4781, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 33 / 107: loss 0.5158, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 36 / 107: loss 0.4228, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 39 / 107: loss 0.5117, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 42 / 107: loss 0.3657, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9500\n",
      "    Batch 45 / 107: loss 0.5706, accuracy 0.8021\n",
      "    ROC-AUC score: 0.7216\n",
      "    Batch 48 / 107: loss 0.5052, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 51 / 107: loss 0.4005, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 54 / 107: loss 0.5526, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 57 / 107: loss 0.3491, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 60 / 107: loss 0.4716, accuracy 0.9062\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 63 / 107: loss 0.4857, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 66 / 107: loss 0.3860, accuracy 0.9375\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 69 / 107: loss 0.5205, accuracy 0.9062\n",
      "    ROC-AUC score: 0.7455\n",
      "    Batch 72 / 107: loss 0.4462, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 75 / 107: loss 0.5053, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 78 / 107: loss 0.4273, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 81 / 107: loss 0.3539, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 84 / 107: loss 0.4296, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9437\n",
      "    Batch 87 / 107: loss 0.4274, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 90 / 107: loss 0.4881, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8406\n",
      "    Batch 93 / 107: loss 0.3902, accuracy 0.9688\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 107: loss 0.4403, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 99 / 107: loss 0.4247, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 102 / 107: loss 0.4329, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 105 / 107: loss 0.4026, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8381\n",
      "Loss 0.4613, accuracy 0.9005\n",
      "ROC-AUC score: 0.9312\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.92      0.90      1704\n",
      "         1.0       0.92      0.88      0.90      1704\n",
      "\n",
      "    accuracy                           0.90      3408\n",
      "   macro avg       0.90      0.90      0.90      3408\n",
      "weighted avg       0.90      0.90      0.90      3408\n",
      "\n",
      "Finished validating.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'val',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the validation dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished validating.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 3696\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 116: loss 0.4487, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8909\n",
      "    Batch 6 / 116: loss 0.5086, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8874\n",
      "    Batch 9 / 116: loss 0.4267, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 12 / 116: loss 0.4714, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 15 / 116: loss 0.4950, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 18 / 116: loss 0.5848, accuracy 0.8542\n",
      "    ROC-AUC score: 0.7137\n",
      "    Batch 21 / 116: loss 0.4739, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 24 / 116: loss 0.5412, accuracy 0.9375\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 116: loss 0.4050, accuracy 0.9375\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 30 / 116: loss 0.5992, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 116: loss 0.5741, accuracy 0.8854\n",
      "    ROC-AUC score: 0.7540\n",
      "    Batch 36 / 116: loss 0.5493, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 39 / 116: loss 0.5205, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9083\n",
      "    Batch 42 / 116: loss 0.4381, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 45 / 116: loss 0.3614, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 48 / 116: loss 0.3199, accuracy 0.9479\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 116: loss 0.3235, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 54 / 116: loss 0.5546, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 57 / 116: loss 0.4111, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 60 / 116: loss 0.6246, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 63 / 116: loss 0.5648, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 66 / 116: loss 0.5395, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8583\n",
      "    Batch 69 / 116: loss 0.6948, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 72 / 116: loss 0.4937, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 75 / 116: loss 0.6409, accuracy 0.8021\n",
      "    ROC-AUC score: 0.7937\n",
      "    Batch 78 / 116: loss 0.5065, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 81 / 116: loss 0.4715, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 84 / 116: loss 0.5772, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 87 / 116: loss 0.4551, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 90 / 116: loss 0.4404, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 93 / 116: loss 0.5451, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9297\n",
      "    Batch 96 / 116: loss 0.5523, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9150\n",
      "    Batch 99 / 116: loss 0.5202, accuracy 0.8750\n",
      "    ROC-AUC score: 0.7292\n",
      "    Batch 102 / 116: loss 0.5043, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 105 / 116: loss 0.5432, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 108 / 116: loss 0.4431, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8452\n",
      "    Batch 111 / 116: loss 0.5286, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8711\n",
      "    Batch 114 / 116: loss 0.4935, accuracy 0.8646\n",
      "    ROC-AUC score: 0.7686\n",
      "Loss 0.5050, accuracy 0.8893\n",
      "ROC-AUC score: 0.9054\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89      1848\n",
      "         1.0       0.90      0.88      0.89      1848\n",
      "\n",
      "    accuracy                           0.89      3696\n",
      "   macro avg       0.89      0.89      0.89      3696\n",
      "weighted avg       0.89      0.89      0.89      3696\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
