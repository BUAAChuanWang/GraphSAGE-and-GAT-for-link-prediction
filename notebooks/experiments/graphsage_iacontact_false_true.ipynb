{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : False,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : False,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0.5,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 3,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 3124\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()\n",
    "config['input_dim'], config['output_dim'] = input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=274, out_features=274, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=548, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.get_model(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 98\n",
      "    Batch 2 / 98\n",
      "    Batch 3 / 98\n",
      "    Batch 4 / 98\n",
      "    Batch 5 / 98\n",
      "    Batch 6 / 98\n",
      "    Batch 7 / 98\n",
      "    Batch 8 / 98\n",
      "    Batch 9 / 98\n",
      "    Batch 10 / 98\n",
      "    Batch 11 / 98\n",
      "    Batch 12 / 98\n",
      "    Batch 13 / 98\n",
      "    Batch 14 / 98\n",
      "    Batch 15 / 98\n",
      "    Batch 16 / 98\n",
      "    Batch 17 / 98\n",
      "    Batch 18 / 98\n",
      "    Batch 19 / 98\n",
      "    Batch 20 / 98\n",
      "    Batch 21 / 98\n",
      "    Batch 22 / 98\n",
      "    Batch 23 / 98\n",
      "    Batch 24 / 98\n",
      "    Batch 25 / 98\n",
      "    Batch 26 / 98\n",
      "    Batch 27 / 98\n",
      "    Batch 28 / 98\n",
      "    Batch 29 / 98\n",
      "    Batch 30 / 98\n",
      "    Batch 31 / 98\n",
      "    Batch 32 / 98\n",
      "    Batch 33 / 98\n",
      "    Batch 34 / 98\n",
      "    Batch 35 / 98\n",
      "    Batch 36 / 98\n",
      "    Batch 37 / 98\n",
      "    Batch 38 / 98\n",
      "    Batch 39 / 98\n",
      "    Batch 40 / 98\n",
      "    Batch 41 / 98\n",
      "    Batch 42 / 98\n",
      "    Batch 43 / 98\n",
      "    Batch 44 / 98\n",
      "    Batch 45 / 98\n",
      "    Batch 46 / 98\n",
      "    Batch 47 / 98\n",
      "    Batch 48 / 98\n",
      "    Batch 49 / 98\n",
      "    Batch 50 / 98\n",
      "    Batch 51 / 98\n",
      "    Batch 52 / 98\n",
      "    Batch 53 / 98\n",
      "    Batch 54 / 98\n",
      "    Batch 55 / 98\n",
      "    Batch 56 / 98\n",
      "    Batch 57 / 98\n",
      "    Batch 58 / 98\n",
      "    Batch 59 / 98\n",
      "    Batch 60 / 98\n",
      "    Batch 61 / 98\n",
      "    Batch 62 / 98\n",
      "    Batch 63 / 98\n",
      "    Batch 64 / 98\n",
      "    Batch 65 / 98\n",
      "    Batch 66 / 98\n",
      "    Batch 67 / 98\n",
      "    Batch 68 / 98\n",
      "    Batch 69 / 98\n",
      "    Batch 70 / 98\n",
      "    Batch 71 / 98\n",
      "    Batch 72 / 98\n",
      "    Batch 73 / 98\n",
      "    Batch 74 / 98\n",
      "    Batch 75 / 98\n",
      "    Batch 76 / 98\n",
      "    Batch 77 / 98\n",
      "    Batch 78 / 98\n",
      "    Batch 79 / 98\n",
      "    Batch 80 / 98\n",
      "    Batch 81 / 98\n",
      "    Batch 82 / 98\n",
      "    Batch 83 / 98\n",
      "    Batch 84 / 98\n",
      "    Batch 85 / 98\n",
      "    Batch 86 / 98\n",
      "    Batch 87 / 98\n",
      "    Batch 88 / 98\n",
      "    Batch 89 / 98\n",
      "    Batch 90 / 98\n",
      "    Batch 91 / 98\n",
      "    Batch 92 / 98\n",
      "    Batch 93 / 98\n",
      "    Batch 94 / 98\n",
      "    Batch 95 / 98\n",
      "    Batch 96 / 98\n",
      "    Batch 97 / 98\n",
      "    Batch 98 / 98\n",
      "ROC-AUC score: 0.4168\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 3\n",
      "    Batch 3 / 98: loss 0.6933\n",
      "    ROC-AUC score: 0.3036\n",
      "    Batch 6 / 98: loss 0.6932\n",
      "    ROC-AUC score: 0.4667\n",
      "    Batch 9 / 98: loss 0.6931\n",
      "    ROC-AUC score: 0.6353\n",
      "    Batch 12 / 98: loss 0.6931\n",
      "    ROC-AUC score: 0.5749\n",
      "    Batch 15 / 98: loss 0.6926\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 18 / 98: loss 0.6925\n",
      "    ROC-AUC score: 0.6680\n",
      "    Batch 21 / 98: loss 0.6914\n",
      "    ROC-AUC score: 0.9833\n",
      "    Batch 24 / 98: loss 0.6907\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 27 / 98: loss 0.6892\n",
      "    ROC-AUC score: 0.8867\n",
      "    Batch 30 / 98: loss 0.6883\n",
      "    ROC-AUC score: 0.8417\n",
      "    Batch 33 / 98: loss 0.6863\n",
      "    ROC-AUC score: 0.9180\n",
      "    Batch 36 / 98: loss 0.6857\n",
      "    ROC-AUC score: 0.8701\n",
      "    Batch 39 / 98: loss 0.6822\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 42 / 98: loss 0.6813\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 45 / 98: loss 0.6791\n",
      "    ROC-AUC score: 0.8477\n",
      "    Batch 48 / 98: loss 0.6760\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 51 / 98: loss 0.6761\n",
      "    ROC-AUC score: 0.7222\n",
      "    Batch 54 / 98: loss 0.6764\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 57 / 98: loss 0.6733\n",
      "    ROC-AUC score: 0.7909\n",
      "    Batch 60 / 98: loss 0.6681\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 63 / 98: loss 0.6677\n",
      "    ROC-AUC score: 0.9292\n",
      "    Batch 66 / 98: loss 0.6613\n",
      "    ROC-AUC score: 0.8658\n",
      "    Batch 69 / 98: loss 0.6605\n",
      "    ROC-AUC score: 0.9275\n",
      "    Batch 72 / 98: loss 0.6558\n",
      "    ROC-AUC score: 0.8730\n",
      "    Batch 75 / 98: loss 0.6575\n",
      "    ROC-AUC score: 0.7930\n",
      "    Batch 78 / 98: loss 0.6579\n",
      "    ROC-AUC score: 0.8528\n",
      "    Batch 81 / 98: loss 0.6519\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 84 / 98: loss 0.6640\n",
      "    ROC-AUC score: 0.9955\n",
      "    Batch 87 / 98: loss 0.6459\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 98: loss 0.6450\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 93 / 98: loss 0.6477\n",
      "    ROC-AUC score: 0.7879\n",
      "    Batch 96 / 98: loss 0.6418\n",
      "    ROC-AUC score: 0.8968\n",
      "Epoch 2 / 3\n",
      "    Batch 3 / 98: loss 0.6211\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 6 / 98: loss 0.6408\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 9 / 98: loss 0.6430\n",
      "    ROC-AUC score: 0.8785\n",
      "    Batch 12 / 98: loss 0.6365\n",
      "    ROC-AUC score: 0.8359\n",
      "    Batch 15 / 98: loss 0.6294\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 18 / 98: loss 0.6198\n",
      "    ROC-AUC score: 0.9042\n",
      "    Batch 21 / 98: loss 0.6215\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 24 / 98: loss 0.6208\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 27 / 98: loss 0.6154\n",
      "    ROC-AUC score: 0.8664\n",
      "    Batch 30 / 98: loss 0.5944\n",
      "    ROC-AUC score: 0.8701\n",
      "    Batch 33 / 98: loss 0.6083\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 36 / 98: loss 0.6110\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 39 / 98: loss 0.5997\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 42 / 98: loss 0.6085\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 45 / 98: loss 0.5898\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 48 / 98: loss 0.5964\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 98: loss 0.5821\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 54 / 98: loss 0.6032\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 57 / 98: loss 0.5852\n",
      "    ROC-AUC score: 0.9083\n",
      "    Batch 60 / 98: loss 0.5944\n",
      "    ROC-AUC score: 0.8917\n",
      "    Batch 63 / 98: loss 0.5706\n",
      "    ROC-AUC score: 0.7875\n",
      "    Batch 66 / 98: loss 0.5670\n",
      "    ROC-AUC score: 0.9004\n",
      "    Batch 69 / 98: loss 0.5442\n",
      "    ROC-AUC score: 0.9625\n",
      "    Batch 72 / 98: loss 0.5759\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 75 / 98: loss 0.5520\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 78 / 98: loss 0.5765\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 81 / 98: loss 0.5567\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 84 / 98: loss 0.5754\n",
      "    ROC-AUC score: 0.9297\n",
      "    Batch 87 / 98: loss 0.5666\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 90 / 98: loss 0.5752\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 93 / 98: loss 0.5533\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 96 / 98: loss 0.5740\n",
      "    ROC-AUC score: 0.9373\n",
      "Epoch 3 / 3\n",
      "    Batch 3 / 98: loss 0.5471\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 6 / 98: loss 0.5828\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 9 / 98: loss 0.5188\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 12 / 98: loss 0.5385\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 15 / 98: loss 0.5180\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 18 / 98: loss 0.5512\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 21 / 98: loss 0.5449\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 98: loss 0.5223\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 27 / 98: loss 0.5150\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 30 / 98: loss 0.5222\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 33 / 98: loss 0.5185\n",
      "    ROC-AUC score: 0.9221\n",
      "    Batch 36 / 98: loss 0.5001\n",
      "    ROC-AUC score: 0.9393\n",
      "    Batch 39 / 98: loss 0.5109\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 42 / 98: loss 0.5142\n",
      "    ROC-AUC score: 0.9042\n",
      "    Batch 45 / 98: loss 0.5162\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 48 / 98: loss 0.5135\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 51 / 98: loss 0.4786\n",
      "    ROC-AUC score: 0.9648\n",
      "    Batch 54 / 98: loss 0.5346\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 57 / 98: loss 0.4758\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 60 / 98: loss 0.5200\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 63 / 98: loss 0.4623\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 66 / 98: loss 0.5341\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 69 / 98: loss 0.5832\n",
      "    ROC-AUC score: 0.6583\n",
      "    Batch 72 / 98: loss 0.4980\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 75 / 98: loss 0.4593\n",
      "    ROC-AUC score: 0.9667\n",
      "    Batch 78 / 98: loss 0.5147\n",
      "    ROC-AUC score: 0.8588\n",
      "    Batch 81 / 98: loss 0.5045\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 84 / 98: loss 0.4832\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 87 / 98: loss 0.4708\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 90 / 98: loss 0.4531\n",
      "    ROC-AUC score: 0.9307\n",
      "    Batch 93 / 98: loss 0.5589\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 96 / 98: loss 0.4874\n",
      "    ROC-AUC score: 0.8292\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 80], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 98\n",
      "    Batch 2 / 98\n",
      "    Batch 3 / 98\n",
      "    Batch 4 / 98\n",
      "    Batch 5 / 98\n",
      "    Batch 6 / 98\n",
      "    Batch 7 / 98\n",
      "    Batch 8 / 98\n",
      "    Batch 9 / 98\n",
      "    Batch 10 / 98\n",
      "    Batch 11 / 98\n",
      "    Batch 12 / 98\n",
      "    Batch 13 / 98\n",
      "    Batch 14 / 98\n",
      "    Batch 15 / 98\n",
      "    Batch 16 / 98\n",
      "    Batch 17 / 98\n",
      "    Batch 18 / 98\n",
      "    Batch 19 / 98\n",
      "    Batch 20 / 98\n",
      "    Batch 21 / 98\n",
      "    Batch 22 / 98\n",
      "    Batch 23 / 98\n",
      "    Batch 24 / 98\n",
      "    Batch 25 / 98\n",
      "    Batch 26 / 98\n",
      "    Batch 27 / 98\n",
      "    Batch 28 / 98\n",
      "    Batch 29 / 98\n",
      "    Batch 30 / 98\n",
      "    Batch 31 / 98\n",
      "    Batch 32 / 98\n",
      "    Batch 33 / 98\n",
      "    Batch 34 / 98\n",
      "    Batch 35 / 98\n",
      "    Batch 36 / 98\n",
      "    Batch 37 / 98\n",
      "    Batch 38 / 98\n",
      "    Batch 39 / 98\n",
      "    Batch 40 / 98\n",
      "    Batch 41 / 98\n",
      "    Batch 42 / 98\n",
      "    Batch 43 / 98\n",
      "    Batch 44 / 98\n",
      "    Batch 45 / 98\n",
      "    Batch 46 / 98\n",
      "    Batch 47 / 98\n",
      "    Batch 48 / 98\n",
      "    Batch 49 / 98\n",
      "    Batch 50 / 98\n",
      "    Batch 51 / 98\n",
      "    Batch 52 / 98\n",
      "    Batch 53 / 98\n",
      "    Batch 54 / 98\n",
      "    Batch 55 / 98\n",
      "    Batch 56 / 98\n",
      "    Batch 57 / 98\n",
      "    Batch 58 / 98\n",
      "    Batch 59 / 98\n",
      "    Batch 60 / 98\n",
      "    Batch 61 / 98\n",
      "    Batch 62 / 98\n",
      "    Batch 63 / 98\n",
      "    Batch 64 / 98\n",
      "    Batch 65 / 98\n",
      "    Batch 66 / 98\n",
      "    Batch 67 / 98\n",
      "    Batch 68 / 98\n",
      "    Batch 69 / 98\n",
      "    Batch 70 / 98\n",
      "    Batch 71 / 98\n",
      "    Batch 72 / 98\n",
      "    Batch 73 / 98\n",
      "    Batch 74 / 98\n",
      "    Batch 75 / 98\n",
      "    Batch 76 / 98\n",
      "    Batch 77 / 98\n",
      "    Batch 78 / 98\n",
      "    Batch 79 / 98\n",
      "    Batch 80 / 98\n",
      "    Batch 81 / 98\n",
      "    Batch 82 / 98\n",
      "    Batch 83 / 98\n",
      "    Batch 84 / 98\n",
      "    Batch 85 / 98\n",
      "    Batch 86 / 98\n",
      "    Batch 87 / 98\n",
      "    Batch 88 / 98\n",
      "    Batch 89 / 98\n",
      "    Batch 90 / 98\n",
      "    Batch 91 / 98\n",
      "    Batch 92 / 98\n",
      "    Batch 93 / 98\n",
      "    Batch 94 / 98\n",
      "    Batch 95 / 98\n",
      "    Batch 96 / 98\n",
      "    Batch 97 / 98\n",
      "    Batch 98 / 98\n",
      "ROC-AUC score: 0.9354\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 98\n",
      "    Batch 2 / 98\n",
      "    Batch 3 / 98\n",
      "    Batch 4 / 98\n",
      "    Batch 5 / 98\n",
      "    Batch 6 / 98\n",
      "    Batch 7 / 98\n",
      "    Batch 8 / 98\n",
      "    Batch 9 / 98\n",
      "    Batch 10 / 98\n",
      "    Batch 11 / 98\n",
      "    Batch 12 / 98\n",
      "    Batch 13 / 98\n",
      "    Batch 14 / 98\n",
      "    Batch 15 / 98\n",
      "    Batch 16 / 98\n",
      "    Batch 17 / 98\n",
      "    Batch 18 / 98\n",
      "    Batch 19 / 98\n",
      "    Batch 20 / 98\n",
      "    Batch 21 / 98\n",
      "    Batch 22 / 98\n",
      "    Batch 23 / 98\n",
      "    Batch 24 / 98\n",
      "    Batch 25 / 98\n",
      "    Batch 26 / 98\n",
      "    Batch 27 / 98\n",
      "    Batch 28 / 98\n",
      "    Batch 29 / 98\n",
      "    Batch 30 / 98\n",
      "    Batch 31 / 98\n",
      "    Batch 32 / 98\n",
      "    Batch 33 / 98\n",
      "    Batch 34 / 98\n",
      "    Batch 35 / 98\n",
      "    Batch 36 / 98\n",
      "    Batch 37 / 98\n",
      "    Batch 38 / 98\n",
      "    Batch 39 / 98\n",
      "    Batch 40 / 98\n",
      "    Batch 41 / 98\n",
      "    Batch 42 / 98\n",
      "    Batch 43 / 98\n",
      "    Batch 44 / 98\n",
      "    Batch 45 / 98\n",
      "    Batch 46 / 98\n",
      "    Batch 47 / 98\n",
      "    Batch 48 / 98\n",
      "    Batch 49 / 98\n",
      "    Batch 50 / 98\n",
      "    Batch 51 / 98\n",
      "    Batch 52 / 98\n",
      "    Batch 53 / 98\n",
      "    Batch 54 / 98\n",
      "    Batch 55 / 98\n",
      "    Batch 56 / 98\n",
      "    Batch 57 / 98\n",
      "    Batch 58 / 98\n",
      "    Batch 59 / 98\n",
      "    Batch 60 / 98\n",
      "    Batch 61 / 98\n",
      "    Batch 62 / 98\n",
      "    Batch 63 / 98\n",
      "    Batch 64 / 98\n",
      "    Batch 65 / 98\n",
      "    Batch 66 / 98\n",
      "    Batch 67 / 98\n",
      "    Batch 68 / 98\n",
      "    Batch 69 / 98\n",
      "    Batch 70 / 98\n",
      "    Batch 71 / 98\n",
      "    Batch 72 / 98\n",
      "    Batch 73 / 98\n",
      "    Batch 74 / 98\n",
      "    Batch 75 / 98\n",
      "    Batch 76 / 98\n",
      "    Batch 77 / 98\n",
      "    Batch 78 / 98\n",
      "    Batch 79 / 98\n",
      "    Batch 80 / 98\n",
      "    Batch 81 / 98\n",
      "    Batch 82 / 98\n",
      "    Batch 83 / 98\n",
      "    Batch 84 / 98\n",
      "    Batch 85 / 98\n",
      "    Batch 86 / 98\n",
      "    Batch 87 / 98\n",
      "    Batch 88 / 98\n",
      "    Batch 89 / 98\n",
      "    Batch 90 / 98\n",
      "    Batch 91 / 98\n",
      "    Batch 92 / 98\n",
      "    Batch 93 / 98\n",
      "    Batch 94 / 98\n",
      "    Batch 95 / 98\n",
      "    Batch 96 / 98\n",
      "    Batch 97 / 98\n",
      "    Batch 98 / 98\n",
      "Threshold: 0.1626, accuracy: 0.8803\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88      1562\n",
      "         1.0       0.89      0.87      0.88      1562\n",
      "\n",
      "    accuracy                           0.88      3124\n",
      "   macro avg       0.88      0.88      0.88      3124\n",
      "weighted avg       0.88      0.88      0.88      3124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 3696\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 116: loss 0.5519, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8615\n",
      "    Batch 6 / 116: loss 0.5556, accuracy 0.7188\n",
      "    ROC-AUC score: 0.7578\n",
      "    Batch 9 / 116: loss 0.5095, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 12 / 116: loss 0.5596, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 15 / 116: loss 0.5587, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8627\n",
      "    Batch 18 / 116: loss 0.4771, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 21 / 116: loss 0.5134, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 24 / 116: loss 0.5482, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 27 / 116: loss 0.5206, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 30 / 116: loss 0.5646, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 33 / 116: loss 0.5252, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 36 / 116: loss 0.5179, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 39 / 116: loss 0.5119, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 42 / 116: loss 0.4773, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8828\n",
      "    Batch 45 / 116: loss 0.5755, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 48 / 116: loss 0.5293, accuracy 0.7292\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 116: loss 0.4724, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 54 / 116: loss 0.5108, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8785\n",
      "    Batch 57 / 116: loss 0.5186, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 60 / 116: loss 0.5345, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 63 / 116: loss 0.4528, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8708\n",
      "    Batch 66 / 116: loss 0.5279, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 69 / 116: loss 0.5309, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 72 / 116: loss 0.5280, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 75 / 116: loss 0.5131, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 78 / 116: loss 0.5831, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 81 / 116: loss 0.6247, accuracy 0.6979\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 84 / 116: loss 0.5213, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 87 / 116: loss 0.5810, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 90 / 116: loss 0.5074, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 93 / 116: loss 0.5494, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 96 / 116: loss 0.4773, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 99 / 116: loss 0.5554, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 102 / 116: loss 0.4957, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 105 / 116: loss 0.5436, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 108 / 116: loss 0.6005, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8438\n",
      "    Batch 111 / 116: loss 0.4549, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 114 / 116: loss 0.4867, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9484\n",
      "Loss 0.5278, accuracy 0.7716\n",
      "ROC-AUC score: 0.8997\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.64      0.74      1848\n",
      "         1.0       0.71      0.90      0.80      1848\n",
      "\n",
      "    accuracy                           0.77      3696\n",
      "   macro avg       0.79      0.77      0.77      3696\n",
      "weighted avg       0.79      0.77      0.77      3696\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
