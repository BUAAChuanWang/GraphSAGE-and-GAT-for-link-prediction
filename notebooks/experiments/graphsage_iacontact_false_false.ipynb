{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : False,\n",
    "    \"repeat_examples\" : False,\n",
    "    \n",
    "    \"self_loop\" : False,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0.5,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 3,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 1290\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()\n",
    "config['input_dim'], config['output_dim'] = input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=274, out_features=274, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=548, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.get_model(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 41\n",
      "    Batch 2 / 41\n",
      "    Batch 3 / 41\n",
      "    Batch 4 / 41\n",
      "    Batch 5 / 41\n",
      "    Batch 6 / 41\n",
      "    Batch 7 / 41\n",
      "    Batch 8 / 41\n",
      "    Batch 9 / 41\n",
      "    Batch 10 / 41\n",
      "    Batch 11 / 41\n",
      "    Batch 12 / 41\n",
      "    Batch 13 / 41\n",
      "    Batch 14 / 41\n",
      "    Batch 15 / 41\n",
      "    Batch 16 / 41\n",
      "    Batch 17 / 41\n",
      "    Batch 18 / 41\n",
      "    Batch 19 / 41\n",
      "    Batch 20 / 41\n",
      "    Batch 21 / 41\n",
      "    Batch 22 / 41\n",
      "    Batch 23 / 41\n",
      "    Batch 24 / 41\n",
      "    Batch 25 / 41\n",
      "    Batch 26 / 41\n",
      "    Batch 27 / 41\n",
      "    Batch 28 / 41\n",
      "    Batch 29 / 41\n",
      "    Batch 30 / 41\n",
      "    Batch 31 / 41\n",
      "    Batch 32 / 41\n",
      "    Batch 33 / 41\n",
      "    Batch 34 / 41\n",
      "    Batch 35 / 41\n",
      "    Batch 36 / 41\n",
      "    Batch 37 / 41\n",
      "    Batch 38 / 41\n",
      "    Batch 39 / 41\n",
      "    Batch 40 / 41\n",
      "    Batch 41 / 41\n",
      "ROC-AUC score: 0.3753\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 3\n",
      "    Batch 3 / 41: loss 0.6932\n",
      "    ROC-AUC score: 0.6190\n",
      "    Batch 6 / 41: loss 0.6931\n",
      "    ROC-AUC score: 0.5742\n",
      "    Batch 9 / 41: loss 0.6917\n",
      "    ROC-AUC score: 0.7659\n",
      "    Batch 12 / 41: loss 0.6911\n",
      "    ROC-AUC score: 0.8392\n",
      "    Batch 15 / 41: loss 0.6912\n",
      "    ROC-AUC score: 0.7137\n",
      "    Batch 18 / 41: loss 0.6900\n",
      "    ROC-AUC score: 0.6320\n",
      "    Batch 21 / 41: loss 0.6898\n",
      "    ROC-AUC score: 0.6863\n",
      "    Batch 24 / 41: loss 0.6879\n",
      "    ROC-AUC score: 0.7804\n",
      "    Batch 27 / 41: loss 0.6884\n",
      "    ROC-AUC score: 0.7965\n",
      "    Batch 30 / 41: loss 0.6852\n",
      "    ROC-AUC score: 0.8219\n",
      "    Batch 33 / 41: loss 0.6844\n",
      "    ROC-AUC score: 0.7895\n",
      "    Batch 36 / 41: loss 0.6854\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 39 / 41: loss 0.6853\n",
      "    ROC-AUC score: 0.7024\n",
      "Epoch 2 / 3\n",
      "    Batch 3 / 41: loss 0.6799\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 6 / 41: loss 0.6787\n",
      "    ROC-AUC score: 0.8353\n",
      "    Batch 9 / 41: loss 0.6752\n",
      "    ROC-AUC score: 0.7792\n",
      "    Batch 12 / 41: loss 0.6779\n",
      "    ROC-AUC score: 0.7937\n",
      "    Batch 15 / 41: loss 0.6785\n",
      "    ROC-AUC score: 0.7045\n",
      "    Batch 18 / 41: loss 0.6733\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 21 / 41: loss 0.6744\n",
      "    ROC-AUC score: 0.8651\n",
      "    Batch 24 / 41: loss 0.6781\n",
      "    ROC-AUC score: 0.8651\n",
      "    Batch 27 / 41: loss 0.6716\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 30 / 41: loss 0.6713\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 33 / 41: loss 0.6667\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 36 / 41: loss 0.6716\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 39 / 41: loss 0.6600\n",
      "    ROC-AUC score: 0.8667\n",
      "Epoch 3 / 3\n",
      "    Batch 3 / 41: loss 0.6546\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 6 / 41: loss 0.6648\n",
      "    ROC-AUC score: 0.8866\n",
      "    Batch 9 / 41: loss 0.6628\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 12 / 41: loss 0.6595\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 15 / 41: loss 0.6584\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 18 / 41: loss 0.6593\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 21 / 41: loss 0.6525\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 24 / 41: loss 0.6551\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 27 / 41: loss 0.6523\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 30 / 41: loss 0.6459\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 33 / 41: loss 0.6455\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 36 / 41: loss 0.6239\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 39 / 41: loss 0.6402\n",
      "    ROC-AUC score: 0.9352\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 80], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 41\n",
      "    Batch 2 / 41\n",
      "    Batch 3 / 41\n",
      "    Batch 4 / 41\n",
      "    Batch 5 / 41\n",
      "    Batch 6 / 41\n",
      "    Batch 7 / 41\n",
      "    Batch 8 / 41\n",
      "    Batch 9 / 41\n",
      "    Batch 10 / 41\n",
      "    Batch 11 / 41\n",
      "    Batch 12 / 41\n",
      "    Batch 13 / 41\n",
      "    Batch 14 / 41\n",
      "    Batch 15 / 41\n",
      "    Batch 16 / 41\n",
      "    Batch 17 / 41\n",
      "    Batch 18 / 41\n",
      "    Batch 19 / 41\n",
      "    Batch 20 / 41\n",
      "    Batch 21 / 41\n",
      "    Batch 22 / 41\n",
      "    Batch 23 / 41\n",
      "    Batch 24 / 41\n",
      "    Batch 25 / 41\n",
      "    Batch 26 / 41\n",
      "    Batch 27 / 41\n",
      "    Batch 28 / 41\n",
      "    Batch 29 / 41\n",
      "    Batch 30 / 41\n",
      "    Batch 31 / 41\n",
      "    Batch 32 / 41\n",
      "    Batch 33 / 41\n",
      "    Batch 34 / 41\n",
      "    Batch 35 / 41\n",
      "    Batch 36 / 41\n",
      "    Batch 37 / 41\n",
      "    Batch 38 / 41\n",
      "    Batch 39 / 41\n",
      "    Batch 40 / 41\n",
      "    Batch 41 / 41\n",
      "ROC-AUC score: 0.9210\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 41\n",
      "    Batch 2 / 41\n",
      "    Batch 3 / 41\n",
      "    Batch 4 / 41\n",
      "    Batch 5 / 41\n",
      "    Batch 6 / 41\n",
      "    Batch 7 / 41\n",
      "    Batch 8 / 41\n",
      "    Batch 9 / 41\n",
      "    Batch 10 / 41\n",
      "    Batch 11 / 41\n",
      "    Batch 12 / 41\n",
      "    Batch 13 / 41\n",
      "    Batch 14 / 41\n",
      "    Batch 15 / 41\n",
      "    Batch 16 / 41\n",
      "    Batch 17 / 41\n",
      "    Batch 18 / 41\n",
      "    Batch 19 / 41\n",
      "    Batch 20 / 41\n",
      "    Batch 21 / 41\n",
      "    Batch 22 / 41\n",
      "    Batch 23 / 41\n",
      "    Batch 24 / 41\n",
      "    Batch 25 / 41\n",
      "    Batch 26 / 41\n",
      "    Batch 27 / 41\n",
      "    Batch 28 / 41\n",
      "    Batch 29 / 41\n",
      "    Batch 30 / 41\n",
      "    Batch 31 / 41\n",
      "    Batch 32 / 41\n",
      "    Batch 33 / 41\n",
      "    Batch 34 / 41\n",
      "    Batch 35 / 41\n",
      "    Batch 36 / 41\n",
      "    Batch 37 / 41\n",
      "    Batch 38 / 41\n",
      "    Batch 39 / 41\n",
      "    Batch 40 / 41\n",
      "    Batch 41 / 41\n",
      "Threshold: 0.0419, accuracy: 0.8419\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.85      0.84       645\n",
      "         1.0       0.85      0.84      0.84       645\n",
      "\n",
      "    accuracy                           0.84      1290\n",
      "   macro avg       0.84      0.84      0.84      1290\n",
      "weighted avg       0.84      0.84      0.84      1290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 1348\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 43: loss 0.6435, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8421\n",
      "    Batch 6 / 43: loss 0.6586, accuracy 0.6979\n",
      "    ROC-AUC score: 0.6758\n",
      "    Batch 9 / 43: loss 0.6667, accuracy 0.6667\n",
      "    ROC-AUC score: 0.7344\n",
      "    Batch 12 / 43: loss 0.6484, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 15 / 43: loss 0.6700, accuracy 0.6562\n",
      "    ROC-AUC score: 0.6636\n",
      "    Batch 18 / 43: loss 0.6490, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8532\n",
      "    Batch 21 / 43: loss 0.6608, accuracy 0.7083\n",
      "    ROC-AUC score: 0.7383\n",
      "    Batch 24 / 43: loss 0.6622, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 27 / 43: loss 0.6541, accuracy 0.7083\n",
      "    ROC-AUC score: 0.7804\n",
      "    Batch 30 / 43: loss 0.6551, accuracy 0.6875\n",
      "    ROC-AUC score: 0.7206\n",
      "    Batch 33 / 43: loss 0.6549, accuracy 0.6771\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 36 / 43: loss 0.6495, accuracy 0.6146\n",
      "    ROC-AUC score: 0.6232\n",
      "    Batch 39 / 43: loss 0.6434, accuracy 0.7083\n",
      "    ROC-AUC score: 0.7167\n",
      "    Batch 42 / 43: loss 0.6464, accuracy 0.7292\n",
      "    ROC-AUC score: 0.6958\n",
      "Loss 0.6528, accuracy 0.6892\n",
      "ROC-AUC score: 0.7640\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.61      0.66       674\n",
      "         1.0       0.66      0.77      0.71       674\n",
      "\n",
      "    accuracy                           0.69      1348\n",
      "   macro avg       0.69      0.69      0.69      1348\n",
      "weighted avg       0.69      0.69      0.69      1348\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
