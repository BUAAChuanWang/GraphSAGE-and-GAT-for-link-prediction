{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : False,\n",
    "    \n",
    "    \"duplicate_examples\" : True,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : True,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GAT\",\n",
    "    \"num_heads\" : [1, 1],\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0,\n",
    "    \n",
    "    \"epochs\" : 4,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 5e-4,\n",
    "    \"weight_decay\" : 1e-3,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 11298\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAT(\n",
      "  (attn): ModuleList(\n",
      "    (0): GraphAttention(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Linear(in_features=274, out_features=64, bias=True)\n",
      "      )\n",
      "      (a): ModuleList(\n",
      "        (0): Linear(in_features=128, out_features=1, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0)\n",
      "      (softmax): Softmax()\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): GraphAttention(\n",
      "      (fcs): ModuleList(\n",
      "        (0): Linear(in_features=64, out_features=1, bias=True)\n",
      "      )\n",
      "      (a): ModuleList(\n",
      "        (0): Linear(in_features=2, out_features=1, bias=True)\n",
      "      )\n",
      "      (dropout): Dropout(p=0)\n",
      "      (softmax): Softmax()\n",
      "      (leakyrelu): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0)\n",
      "  (elu): ELU(alpha=1.0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.GAT(input_dim, config['hidden_dims'],\n",
    "                   output_dim, config['num_heads'],\n",
    "                   config['dropout'], config['device'])\n",
    "model.apply(models.init_weights)\n",
    "model.to(config['device'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "ROC-AUC score: 0.5258\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 4\n",
      "    Batch 3 / 354: loss 1.0855\n",
      "    ROC-AUC score: 0.4494\n",
      "    Batch 6 / 354: loss 0.8137\n",
      "    ROC-AUC score: 0.6542\n",
      "    Batch 9 / 354: loss 0.6702\n",
      "    ROC-AUC score: 0.5675\n",
      "    Batch 12 / 354: loss 0.7519\n",
      "    ROC-AUC score: 0.5870\n",
      "    Batch 15 / 354: loss 0.7185\n",
      "    ROC-AUC score: 0.6508\n",
      "    Batch 18 / 354: loss 0.7897\n",
      "    ROC-AUC score: 0.6353\n",
      "    Batch 21 / 354: loss 0.7276\n",
      "    ROC-AUC score: 0.5958\n",
      "    Batch 24 / 354: loss 0.7327\n",
      "    ROC-AUC score: 0.5725\n",
      "    Batch 27 / 354: loss 0.7753\n",
      "    ROC-AUC score: 0.5913\n",
      "    Batch 30 / 354: loss 0.7458\n",
      "    ROC-AUC score: 0.5156\n",
      "    Batch 33 / 354: loss 0.8337\n",
      "    ROC-AUC score: 0.5078\n",
      "    Batch 36 / 354: loss 0.9956\n",
      "    ROC-AUC score: 0.4286\n",
      "    Batch 39 / 354: loss 0.7098\n",
      "    ROC-AUC score: 0.7583\n",
      "    Batch 42 / 354: loss 0.8295\n",
      "    ROC-AUC score: 0.5476\n",
      "    Batch 45 / 354: loss 0.8558\n",
      "    ROC-AUC score: 0.6875\n",
      "    Batch 48 / 354: loss 0.7264\n",
      "    ROC-AUC score: 0.6000\n",
      "    Batch 51 / 354: loss 0.8923\n",
      "    ROC-AUC score: 0.5951\n",
      "    Batch 54 / 354: loss 0.7237\n",
      "    ROC-AUC score: 0.6471\n",
      "    Batch 57 / 354: loss 0.6546\n",
      "    ROC-AUC score: 0.7571\n",
      "    Batch 60 / 354: loss 0.6713\n",
      "    ROC-AUC score: 0.7619\n",
      "    Batch 63 / 354: loss 0.6031\n",
      "    ROC-AUC score: 0.7958\n",
      "    Batch 66 / 354: loss 0.7577\n",
      "    ROC-AUC score: 0.7778\n",
      "    Batch 69 / 354: loss 0.7714\n",
      "    ROC-AUC score: 0.5938\n",
      "    Batch 72 / 354: loss 0.6834\n",
      "    ROC-AUC score: 0.6061\n",
      "    Batch 75 / 354: loss 0.5570\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 78 / 354: loss 0.5629\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 81 / 354: loss 0.6988\n",
      "    ROC-AUC score: 0.7652\n",
      "    Batch 84 / 354: loss 0.7504\n",
      "    ROC-AUC score: 0.9246\n",
      "    Batch 87 / 354: loss 0.6371\n",
      "    ROC-AUC score: 0.8788\n",
      "    Batch 90 / 354: loss 0.7506\n",
      "    ROC-AUC score: 0.7020\n",
      "    Batch 93 / 354: loss 0.7000\n",
      "    ROC-AUC score: 0.7045\n",
      "    Batch 96 / 354: loss 0.6510\n",
      "    ROC-AUC score: 0.7875\n",
      "    Batch 99 / 354: loss 0.4723\n",
      "    ROC-AUC score: 0.8086\n",
      "    Batch 102 / 354: loss 0.5033\n",
      "    ROC-AUC score: 0.7961\n",
      "    Batch 105 / 354: loss 0.6147\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 108 / 354: loss 0.5616\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 111 / 354: loss 0.6916\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 114 / 354: loss 0.5091\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 117 / 354: loss 0.4310\n",
      "    ROC-AUC score: 0.9087\n",
      "    Batch 120 / 354: loss 0.6547\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 123 / 354: loss 0.4828\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 126 / 354: loss 0.5539\n",
      "    ROC-AUC score: 0.8175\n",
      "    Batch 129 / 354: loss 0.4019\n",
      "    ROC-AUC score: 0.9625\n",
      "    Batch 132 / 354: loss 0.5938\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 135 / 354: loss 0.4606\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 138 / 354: loss 0.4777\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 141 / 354: loss 0.5405\n",
      "    ROC-AUC score: 0.8788\n",
      "    Batch 144 / 354: loss 0.3858\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 147 / 354: loss 0.5050\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 150 / 354: loss 0.4398\n",
      "    ROC-AUC score: 0.9686\n",
      "    Batch 153 / 354: loss 0.4780\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 156 / 354: loss 0.6148\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 159 / 354: loss 0.4606\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 162 / 354: loss 0.5099\n",
      "    ROC-AUC score: 0.9648\n",
      "    Batch 165 / 354: loss 0.5117\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 168 / 354: loss 0.4645\n",
      "    ROC-AUC score: 0.9570\n",
      "    Batch 171 / 354: loss 0.4575\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 174 / 354: loss 0.4678\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 177 / 354: loss 0.4806\n",
      "    ROC-AUC score: 0.8866\n",
      "    Batch 180 / 354: loss 0.4424\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 183 / 354: loss 0.4506\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 186 / 354: loss 0.5601\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 189 / 354: loss 0.5271\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 192 / 354: loss 0.5390\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 195 / 354: loss 0.5329\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 198 / 354: loss 0.4342\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 201 / 354: loss 0.4555\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 204 / 354: loss 0.6149\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 207 / 354: loss 0.3958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 210 / 354: loss 0.4924\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 213 / 354: loss 0.5345\n",
      "    ROC-AUC score: 0.9838\n",
      "    Batch 216 / 354: loss 0.5132\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 219 / 354: loss 0.4340\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 222 / 354: loss 0.3760\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 225 / 354: loss 0.4187\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 228 / 354: loss 0.4602\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 231 / 354: loss 0.5533\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 234 / 354: loss 0.5286\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 237 / 354: loss 0.4565\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 240 / 354: loss 0.4631\n",
      "    ROC-AUC score: 0.9570\n",
      "    Batch 243 / 354: loss 0.4860\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 246 / 354: loss 0.5410\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 249 / 354: loss 0.4127\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 252 / 354: loss 0.4824\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 255 / 354: loss 0.5694\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 258 / 354: loss 0.5035\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 261 / 354: loss 0.4688\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 264 / 354: loss 0.4997\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 267 / 354: loss 0.4268\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 270 / 354: loss 0.5231\n",
      "    ROC-AUC score: 0.8462\n",
      "    Batch 273 / 354: loss 0.3986\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 276 / 354: loss 0.5401\n",
      "    ROC-AUC score: 0.7961\n",
      "    Batch 279 / 354: loss 0.4747\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 282 / 354: loss 0.5839\n",
      "    ROC-AUC score: 0.8452\n",
      "    Batch 285 / 354: loss 0.5621\n",
      "    ROC-AUC score: 0.9136\n",
      "    Batch 288 / 354: loss 0.4204\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 291 / 354: loss 0.4424\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 294 / 354: loss 0.4636\n",
      "    ROC-AUC score: 0.9570\n",
      "    Batch 297 / 354: loss 0.5762\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 300 / 354: loss 0.5070\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 303 / 354: loss 0.5077\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 306 / 354: loss 0.5098\n",
      "    ROC-AUC score: 0.9883\n",
      "    Batch 309 / 354: loss 0.4077\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 312 / 354: loss 0.4177\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 315 / 354: loss 0.4832\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 318 / 354: loss 0.4511\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 321 / 354: loss 0.4489\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 324 / 354: loss 0.4221\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 327 / 354: loss 0.4993\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 330 / 354: loss 0.3613\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 333 / 354: loss 0.4855\n",
      "    ROC-AUC score: 0.9625\n",
      "    Batch 336 / 354: loss 0.3966\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 339 / 354: loss 0.5236\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 342 / 354: loss 0.3981\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 345 / 354: loss 0.3145\n",
      "    ROC-AUC score: 0.9818\n",
      "    Batch 348 / 354: loss 0.5136\n",
      "    ROC-AUC score: 0.9318\n",
      "    Batch 351 / 354: loss 0.4890\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 354 / 354: loss 0.3157\n",
      "    ROC-AUC score: 1.0000\n",
      "Epoch 2 / 4\n",
      "    Batch 3 / 354: loss 0.4714\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 6 / 354: loss 0.4926\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 9 / 354: loss 0.5189\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 12 / 354: loss 0.4424\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 15 / 354: loss 0.4332\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 18 / 354: loss 0.4601\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 21 / 354: loss 0.5444\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 24 / 354: loss 0.4307\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 27 / 354: loss 0.3928\n",
      "    ROC-AUC score: 0.9136\n",
      "    Batch 30 / 354: loss 0.4628\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 33 / 354: loss 0.4234\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 354: loss 0.4540\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 39 / 354: loss 0.4328\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 42 / 354: loss 0.4663\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 45 / 354: loss 0.5070\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 48 / 354: loss 0.4532\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 51 / 354: loss 0.4547\n",
      "    ROC-AUC score: 0.8988\n",
      "    Batch 54 / 354: loss 0.3564\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 57 / 354: loss 0.4680\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 60 / 354: loss 0.4615\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 63 / 354: loss 0.5225\n",
      "    ROC-AUC score: 0.9841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 66 / 354: loss 0.3743\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 69 / 354: loss 0.4394\n",
      "    ROC-AUC score: 0.9697\n",
      "    Batch 72 / 354: loss 0.3849\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 75 / 354: loss 0.4922\n",
      "    ROC-AUC score: 0.9591\n",
      "    Batch 78 / 354: loss 0.4193\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 81 / 354: loss 0.3824\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 84 / 354: loss 0.3982\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 87 / 354: loss 0.4506\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 354: loss 0.4195\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 93 / 354: loss 0.4663\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 96 / 354: loss 0.4221\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 99 / 354: loss 0.4155\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 102 / 354: loss 0.5040\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 105 / 354: loss 0.4890\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 108 / 354: loss 0.3515\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 111 / 354: loss 0.4840\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 114 / 354: loss 0.4638\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 117 / 354: loss 0.3068\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 120 / 354: loss 0.3573\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 123 / 354: loss 0.3979\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 126 / 354: loss 0.5002\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 129 / 354: loss 0.5192\n",
      "    ROC-AUC score: 0.9610\n",
      "    Batch 132 / 354: loss 0.3989\n",
      "    ROC-AUC score: 0.9086\n",
      "    Batch 135 / 354: loss 0.3680\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 138 / 354: loss 0.3492\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 141 / 354: loss 0.4971\n",
      "    ROC-AUC score: 0.9827\n",
      "    Batch 144 / 354: loss 0.4178\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 147 / 354: loss 0.3633\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 150 / 354: loss 0.5464\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 153 / 354: loss 0.5202\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 156 / 354: loss 0.5288\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 159 / 354: loss 0.5094\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 162 / 354: loss 0.3513\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 165 / 354: loss 0.3941\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 168 / 354: loss 0.3714\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 171 / 354: loss 0.4055\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 174 / 354: loss 0.4029\n",
      "    ROC-AUC score: 0.9595\n",
      "    Batch 177 / 354: loss 0.4145\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 180 / 354: loss 0.5047\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 183 / 354: loss 0.4399\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 186 / 354: loss 0.4217\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 189 / 354: loss 0.3193\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 192 / 354: loss 0.3657\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 195 / 354: loss 0.3482\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 198 / 354: loss 0.3757\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 201 / 354: loss 0.3782\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 204 / 354: loss 0.4638\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 207 / 354: loss 0.3798\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 210 / 354: loss 0.5314\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 213 / 354: loss 0.3560\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 216 / 354: loss 0.4137\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 219 / 354: loss 0.4544\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 222 / 354: loss 0.4200\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 225 / 354: loss 0.3631\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 228 / 354: loss 0.4421\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 231 / 354: loss 0.3995\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 234 / 354: loss 0.3849\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 237 / 354: loss 0.3887\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 240 / 354: loss 0.3825\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 243 / 354: loss 0.5389\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 246 / 354: loss 0.4289\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 249 / 354: loss 0.4014\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 252 / 354: loss 0.3858\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 255 / 354: loss 0.3508\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 258 / 354: loss 0.2484\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 261 / 354: loss 0.2854\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 264 / 354: loss 0.3254\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 267 / 354: loss 0.3553\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 270 / 354: loss 0.4052\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 273 / 354: loss 0.4492\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 276 / 354: loss 0.5318\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 279 / 354: loss 0.4338\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 282 / 354: loss 0.3931\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 285 / 354: loss 0.4197\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 288 / 354: loss 0.4012\n",
      "    ROC-AUC score: 0.9610\n",
      "    Batch 291 / 354: loss 0.4540\n",
      "    ROC-AUC score: 0.9717\n",
      "    Batch 294 / 354: loss 0.4757\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 297 / 354: loss 0.4022\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 300 / 354: loss 0.4250\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 303 / 354: loss 0.5139\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 306 / 354: loss 0.3695\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 309 / 354: loss 0.4479\n",
      "    ROC-AUC score: 0.8874\n",
      "    Batch 312 / 354: loss 0.4568\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 315 / 354: loss 0.4774\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 318 / 354: loss 0.3812\n",
      "    ROC-AUC score: 0.9740\n",
      "    Batch 321 / 354: loss 0.3724\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 324 / 354: loss 0.4543\n",
      "    ROC-AUC score: 0.9246\n",
      "    Batch 327 / 354: loss 0.4493\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 330 / 354: loss 0.3544\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 333 / 354: loss 0.3792\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 336 / 354: loss 0.4351\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 339 / 354: loss 0.3758\n",
      "    ROC-AUC score: 0.9913\n",
      "    Batch 342 / 354: loss 0.3479\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 345 / 354: loss 0.3687\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 348 / 354: loss 0.3241\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 351 / 354: loss 0.3745\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 354 / 354: loss 0.6224\n",
      "Epoch 3 / 4\n",
      "    Batch 3 / 354: loss 0.4369\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 6 / 354: loss 0.3898\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 9 / 354: loss 0.4102\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 354: loss 0.4234\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 15 / 354: loss 0.3647\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 18 / 354: loss 0.3721\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 354: loss 0.4351\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 24 / 354: loss 0.4136\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 27 / 354: loss 0.4053\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 30 / 354: loss 0.3736\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 354: loss 0.4168\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 36 / 354: loss 0.3902\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 39 / 354: loss 0.3941\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 42 / 354: loss 0.4386\n",
      "    ROC-AUC score: 0.9750\n",
      "    Batch 45 / 354: loss 0.4839\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 48 / 354: loss 0.3434\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 354: loss 0.3265\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 54 / 354: loss 0.2759\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 57 / 354: loss 0.3906\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 60 / 354: loss 0.4323\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 63 / 354: loss 0.3322\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 66 / 354: loss 0.3739\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 69 / 354: loss 0.4214\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 354: loss 0.3873\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 354: loss 0.4072\n",
      "    ROC-AUC score: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-ec942c39a864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.8)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200], gamma=0.5)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "ROC-AUC score: 0.9824\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "Threshold: 1.6465, accuracy: 0.9616\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96      5649\n",
      "         1.0       0.96      0.96      0.96      5649\n",
      "\n",
      "    accuracy                           0.96     11298\n",
      "   macro avg       0.96      0.96      0.96     11298\n",
      "weighted avg       0.96      0.96      0.96     11298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: val\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2112\n",
      "Number of temporal edges: 14122\n",
      "Number of examples/datapoints: 14122\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the validation dataset after training.\n",
      "    Batch 3 / 442: loss 0.4945, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8704\n",
      "    Batch 6 / 442: loss 0.4629, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 9 / 442: loss 0.4449, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 12 / 442: loss 0.4805, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 15 / 442: loss 0.5184, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8961\n",
      "    Batch 18 / 442: loss 0.5248, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 21 / 442: loss 0.4834, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9805\n",
      "    Batch 24 / 442: loss 0.4818, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 27 / 442: loss 0.4568, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9219\n",
      "    Batch 30 / 442: loss 0.4524, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9708\n",
      "    Batch 33 / 442: loss 0.4704, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 36 / 442: loss 0.5540, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 39 / 442: loss 0.4680, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 42 / 442: loss 0.4378, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 45 / 442: loss 0.5356, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8792\n",
      "    Batch 48 / 442: loss 0.3635, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 51 / 442: loss 0.4897, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 54 / 442: loss 0.5294, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9838\n",
      "    Batch 57 / 442: loss 0.4638, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 60 / 442: loss 0.5063, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9750\n",
      "    Batch 63 / 442: loss 0.4912, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9087\n",
      "    Batch 66 / 442: loss 0.4504, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 69 / 442: loss 0.5400, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 72 / 442: loss 0.4190, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 75 / 442: loss 0.4512, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9610\n",
      "    Batch 78 / 442: loss 0.4889, accuracy 0.8438\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 81 / 442: loss 0.4885, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 84 / 442: loss 0.3799, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 87 / 442: loss 0.4498, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 90 / 442: loss 0.4809, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 93 / 442: loss 0.4281, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 96 / 442: loss 0.5256, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8421\n",
      "    Batch 99 / 442: loss 0.3945, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9688\n",
      "    Batch 102 / 442: loss 0.4407, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9667\n",
      "    Batch 105 / 442: loss 0.4819, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 108 / 442: loss 0.4842, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 111 / 442: loss 0.4819, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 114 / 442: loss 0.4874, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 117 / 442: loss 0.4175, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 120 / 442: loss 0.4884, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 123 / 442: loss 0.4271, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 126 / 442: loss 0.4038, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9610\n",
      "    Batch 129 / 442: loss 0.4482, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 132 / 442: loss 0.4087, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 135 / 442: loss 0.4034, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 138 / 442: loss 0.3852, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 141 / 442: loss 0.4569, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 144 / 442: loss 0.4916, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 147 / 442: loss 0.4208, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 150 / 442: loss 0.5077, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9952\n",
      "    Batch 153 / 442: loss 0.5140, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 156 / 442: loss 0.5350, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 159 / 442: loss 0.4849, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 162 / 442: loss 0.3836, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 165 / 442: loss 0.4903, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 168 / 442: loss 0.5317, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 171 / 442: loss 0.4861, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 174 / 442: loss 0.4762, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 177 / 442: loss 0.4821, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 180 / 442: loss 0.4646, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 183 / 442: loss 0.4983, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 186 / 442: loss 0.4881, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 189 / 442: loss 0.4930, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9179\n",
      "    Batch 192 / 442: loss 0.4207, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9458\n",
      "    Batch 195 / 442: loss 0.3932, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 198 / 442: loss 0.4796, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 201 / 442: loss 0.5370, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 204 / 442: loss 0.4848, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8727\n",
      "    Batch 207 / 442: loss 0.3921, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 210 / 442: loss 0.4670, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9740\n",
      "    Batch 213 / 442: loss 0.4966, accuracy 0.9062\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 216 / 442: loss 0.5105, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9654\n",
      "    Batch 219 / 442: loss 0.4363, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 222 / 442: loss 0.4925, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 225 / 442: loss 0.4005, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 228 / 442: loss 0.4828, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 231 / 442: loss 0.4561, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 234 / 442: loss 0.4836, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 237 / 442: loss 0.4859, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 240 / 442: loss 0.4865, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 243 / 442: loss 0.4311, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9827\n",
      "    Batch 246 / 442: loss 0.5020, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 249 / 442: loss 0.4415, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9136\n",
      "    Batch 252 / 442: loss 0.4379, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 255 / 442: loss 0.4206, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 258 / 442: loss 0.4520, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9838\n",
      "    Batch 261 / 442: loss 0.4155, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 264 / 442: loss 0.4912, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 267 / 442: loss 0.4573, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 270 / 442: loss 0.5001, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 273 / 442: loss 0.4868, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 276 / 442: loss 0.5076, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 279 / 442: loss 0.3928, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 282 / 442: loss 0.4380, accuracy 0.8021\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 285 / 442: loss 0.4448, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9948\n",
      "    Batch 288 / 442: loss 0.5057, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 291 / 442: loss 0.4357, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9083\n",
      "    Batch 294 / 442: loss 0.5092, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 297 / 442: loss 0.3971, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 300 / 442: loss 0.4792, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9614\n",
      "    Batch 303 / 442: loss 0.4264, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 306 / 442: loss 0.4735, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 309 / 442: loss 0.4724, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9792\n",
      "    Batch 312 / 442: loss 0.5368, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 315 / 442: loss 0.3988, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 318 / 442: loss 0.4887, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9190\n",
      "    Batch 321 / 442: loss 0.4141, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 324 / 442: loss 0.4781, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9545\n",
      "    Batch 327 / 442: loss 0.4109, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 330 / 442: loss 0.4553, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 333 / 442: loss 0.4791, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9531\n",
      "    Batch 336 / 442: loss 0.4156, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 339 / 442: loss 0.5648, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 342 / 442: loss 0.4579, accuracy 0.8333\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 345 / 442: loss 0.5162, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 348 / 442: loss 0.4922, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9083\n",
      "    Batch 351 / 442: loss 0.4918, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 354 / 442: loss 0.3910, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 357 / 442: loss 0.4763, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 360 / 442: loss 0.5874, accuracy 0.7708\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 363 / 442: loss 0.4481, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 366 / 442: loss 0.4282, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 369 / 442: loss 0.4091, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 372 / 442: loss 0.4765, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9125\n",
      "    Batch 375 / 442: loss 0.4553, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9542\n",
      "    Batch 378 / 442: loss 0.4502, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8417\n",
      "    Batch 381 / 442: loss 0.4560, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 384 / 442: loss 0.4182, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 387 / 442: loss 0.4692, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 390 / 442: loss 0.4062, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 393 / 442: loss 0.4444, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 396 / 442: loss 0.5292, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 399 / 442: loss 0.3689, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 402 / 442: loss 0.4833, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9875\n",
      "    Batch 405 / 442: loss 0.4654, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 408 / 442: loss 0.4871, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 411 / 442: loss 0.4662, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 414 / 442: loss 0.4629, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 417 / 442: loss 0.4346, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 420 / 442: loss 0.5010, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 423 / 442: loss 0.3971, accuracy 0.8646\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 426 / 442: loss 0.5129, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8958\n",
      "    Batch 429 / 442: loss 0.4094, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 432 / 442: loss 0.4771, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 435 / 442: loss 0.4246, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 438 / 442: loss 0.4594, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 441 / 442: loss 0.4449, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8364\n",
      "Loss 0.4640, accuracy 0.8638\n",
      "ROC-AUC score: 0.9432\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.97      0.88      7061\n",
      "         1.0       0.96      0.76      0.85      7061\n",
      "\n",
      "    accuracy                           0.86     14122\n",
      "   macro avg       0.88      0.86      0.86     14122\n",
      "weighted avg       0.88      0.86      0.86     14122\n",
      "\n",
      "Finished validating.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'val',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the validation dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished validating.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 14100\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 441: loss 0.5957, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8300\n",
      "    Batch 6 / 441: loss 0.5223, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 9 / 441: loss 0.5158, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 12 / 441: loss 0.4754, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 15 / 441: loss 0.5603, accuracy 0.7083\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 18 / 441: loss 0.4944, accuracy 0.7708\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 441: loss 0.4986, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 24 / 441: loss 0.6245, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 27 / 441: loss 0.5192, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9531\n",
      "    Batch 30 / 441: loss 0.4436, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9134\n",
      "    Batch 33 / 441: loss 0.5688, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 36 / 441: loss 0.4705, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9393\n",
      "    Batch 39 / 441: loss 0.4968, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 42 / 441: loss 0.4590, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9125\n",
      "    Batch 45 / 441: loss 0.4732, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 48 / 441: loss 0.4643, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 51 / 441: loss 0.4752, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 54 / 441: loss 0.5290, accuracy 0.8229\n",
      "    ROC-AUC score: 0.6914\n",
      "    Batch 57 / 441: loss 0.6014, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 60 / 441: loss 0.4959, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 63 / 441: loss 0.4813, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 66 / 441: loss 0.4452, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 69 / 441: loss 0.5353, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9686\n",
      "    Batch 72 / 441: loss 0.5022, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9069\n",
      "    Batch 75 / 441: loss 0.5666, accuracy 0.7812\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 78 / 441: loss 0.5651, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 81 / 441: loss 0.4521, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 84 / 441: loss 0.5305, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 87 / 441: loss 0.5224, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 90 / 441: loss 0.5252, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8588\n",
      "    Batch 93 / 441: loss 0.5442, accuracy 0.7604\n",
      "    ROC-AUC score: 0.7460\n",
      "    Batch 96 / 441: loss 0.4932, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 99 / 441: loss 0.4518, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 102 / 441: loss 0.4687, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 105 / 441: loss 0.4911, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 108 / 441: loss 0.4859, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 111 / 441: loss 0.4646, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 114 / 441: loss 0.4685, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 117 / 441: loss 0.5133, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 120 / 441: loss 0.4995, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 123 / 441: loss 0.4577, accuracy 0.7500\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 126 / 441: loss 0.4885, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8918\n",
      "    Batch 129 / 441: loss 0.5124, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 132 / 441: loss 0.4943, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 135 / 441: loss 0.4618, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9292\n",
      "    Batch 138 / 441: loss 0.4431, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8907\n",
      "    Batch 141 / 441: loss 0.5520, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 144 / 441: loss 0.4908, accuracy 0.6979\n",
      "    ROC-AUC score: 0.8833\n",
      "    Batch 147 / 441: loss 0.4453, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 150 / 441: loss 0.5783, accuracy 0.6979\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 153 / 441: loss 0.6219, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 156 / 441: loss 0.5803, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 159 / 441: loss 0.5463, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 162 / 441: loss 0.5008, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 165 / 441: loss 0.4694, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 168 / 441: loss 0.5205, accuracy 0.6771\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 171 / 441: loss 0.5149, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8594\n",
      "    Batch 174 / 441: loss 0.5551, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 177 / 441: loss 0.5412, accuracy 0.8125\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 180 / 441: loss 0.4897, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8833\n",
      "    Batch 183 / 441: loss 0.4804, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8864\n",
      "    Batch 186 / 441: loss 0.5614, accuracy 0.7812\n",
      "    ROC-AUC score: 0.7891\n",
      "    Batch 189 / 441: loss 0.5798, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8664\n",
      "    Batch 192 / 441: loss 0.5309, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 195 / 441: loss 0.5479, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 198 / 441: loss 0.5520, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 201 / 441: loss 0.4756, accuracy 0.7812\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 204 / 441: loss 0.4768, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9531\n",
      "    Batch 207 / 441: loss 0.5668, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 210 / 441: loss 0.5166, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 213 / 441: loss 0.5414, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 216 / 441: loss 0.5462, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 219 / 441: loss 0.5370, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 222 / 441: loss 0.5371, accuracy 0.6562\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 225 / 441: loss 0.5345, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8826\n",
      "    Batch 228 / 441: loss 0.5039, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 231 / 441: loss 0.4379, accuracy 0.7812\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 234 / 441: loss 0.5860, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 237 / 441: loss 0.5780, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 240 / 441: loss 0.4163, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 243 / 441: loss 0.5451, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 246 / 441: loss 0.5310, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 249 / 441: loss 0.4872, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 252 / 441: loss 0.4638, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 255 / 441: loss 0.5763, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 258 / 441: loss 0.5200, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8833\n",
      "    Batch 261 / 441: loss 0.4631, accuracy 0.8125\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 264 / 441: loss 0.6215, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 267 / 441: loss 0.5685, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9125\n",
      "    Batch 270 / 441: loss 0.6065, accuracy 0.7396\n",
      "    ROC-AUC score: 0.7937\n",
      "    Batch 273 / 441: loss 0.5492, accuracy 0.7708\n",
      "    ROC-AUC score: 0.7583\n",
      "    Batch 276 / 441: loss 0.4357, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 279 / 441: loss 0.4708, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 282 / 441: loss 0.5402, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 285 / 441: loss 0.4877, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 288 / 441: loss 0.4580, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 291 / 441: loss 0.4499, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 294 / 441: loss 0.5325, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 297 / 441: loss 0.5178, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 300 / 441: loss 0.5722, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 303 / 441: loss 0.4761, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9688\n",
      "    Batch 306 / 441: loss 0.4722, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 309 / 441: loss 0.5034, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 312 / 441: loss 0.5663, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 315 / 441: loss 0.4934, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 318 / 441: loss 0.5085, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 321 / 441: loss 0.4864, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 324 / 441: loss 0.4770, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 327 / 441: loss 0.5097, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9246\n",
      "    Batch 330 / 441: loss 0.4947, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 333 / 441: loss 0.5390, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 336 / 441: loss 0.4386, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 339 / 441: loss 0.4727, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 342 / 441: loss 0.4313, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9625\n",
      "    Batch 345 / 441: loss 0.4946, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 348 / 441: loss 0.6082, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 351 / 441: loss 0.4768, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 354 / 441: loss 0.5971, accuracy 0.7292\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 357 / 441: loss 0.4172, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 360 / 441: loss 0.4745, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 363 / 441: loss 0.5305, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9004\n",
      "    Batch 366 / 441: loss 0.5215, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 369 / 441: loss 0.4532, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 372 / 441: loss 0.5416, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 375 / 441: loss 0.4691, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 378 / 441: loss 0.5097, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9227\n",
      "    Batch 381 / 441: loss 0.4800, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9838\n",
      "    Batch 384 / 441: loss 0.4660, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9042\n",
      "    Batch 387 / 441: loss 0.5589, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9297\n",
      "    Batch 390 / 441: loss 0.4519, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 393 / 441: loss 0.4954, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 396 / 441: loss 0.5040, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 399 / 441: loss 0.4515, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 402 / 441: loss 0.5476, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 405 / 441: loss 0.5163, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9219\n",
      "    Batch 408 / 441: loss 0.5547, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9134\n",
      "    Batch 411 / 441: loss 0.4965, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 414 / 441: loss 0.4750, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 417 / 441: loss 0.4653, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 420 / 441: loss 0.4384, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 423 / 441: loss 0.4889, accuracy 0.7188\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 426 / 441: loss 0.4575, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 429 / 441: loss 0.5266, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 432 / 441: loss 0.5299, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 435 / 441: loss 0.5372, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9717\n",
      "    Batch 438 / 441: loss 0.6434, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 441 / 441: loss 0.5281, accuracy 0.7976\n",
      "    ROC-AUC score: 0.9167\n",
      "Loss 0.5104, accuracy 0.7778\n",
      "ROC-AUC score: 0.9118\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.96      0.81      7050\n",
      "         1.0       0.94      0.60      0.73      7050\n",
      "\n",
      "    accuracy                           0.78     14100\n",
      "   macro avg       0.82      0.78      0.77     14100\n",
      "weighted avg       0.82      0.78      0.77     14100\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
