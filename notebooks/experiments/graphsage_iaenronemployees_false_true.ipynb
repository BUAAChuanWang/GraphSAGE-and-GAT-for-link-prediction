{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAEnronEmployees\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : False,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : False,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0.5,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 3,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 151\n",
      "Number of static edges: 759\n",
      "Number of temporal edges: 15171\n",
      "Number of examples/datapoints: 2184\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()\n",
    "config['input_dim'], config['output_dim'] = input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=151, out_features=151, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=302, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.get_model(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 69\n",
      "    Batch 2 / 69\n",
      "    Batch 3 / 69\n",
      "    Batch 4 / 69\n",
      "    Batch 5 / 69\n",
      "    Batch 6 / 69\n",
      "    Batch 7 / 69\n",
      "    Batch 8 / 69\n",
      "    Batch 9 / 69\n",
      "    Batch 10 / 69\n",
      "    Batch 11 / 69\n",
      "    Batch 12 / 69\n",
      "    Batch 13 / 69\n",
      "    Batch 14 / 69\n",
      "    Batch 15 / 69\n",
      "    Batch 16 / 69\n",
      "    Batch 17 / 69\n",
      "    Batch 18 / 69\n",
      "    Batch 19 / 69\n",
      "    Batch 20 / 69\n",
      "    Batch 21 / 69\n",
      "    Batch 22 / 69\n",
      "    Batch 23 / 69\n",
      "    Batch 24 / 69\n",
      "    Batch 25 / 69\n",
      "    Batch 26 / 69\n",
      "    Batch 27 / 69\n",
      "    Batch 28 / 69\n",
      "    Batch 29 / 69\n",
      "    Batch 30 / 69\n",
      "    Batch 31 / 69\n",
      "    Batch 32 / 69\n",
      "    Batch 33 / 69\n",
      "    Batch 34 / 69\n",
      "    Batch 35 / 69\n",
      "    Batch 36 / 69\n",
      "    Batch 37 / 69\n",
      "    Batch 38 / 69\n",
      "    Batch 39 / 69\n",
      "    Batch 40 / 69\n",
      "    Batch 41 / 69\n",
      "    Batch 42 / 69\n",
      "    Batch 43 / 69\n",
      "    Batch 44 / 69\n",
      "    Batch 45 / 69\n",
      "    Batch 46 / 69\n",
      "    Batch 47 / 69\n",
      "    Batch 48 / 69\n",
      "    Batch 49 / 69\n",
      "    Batch 50 / 69\n",
      "    Batch 51 / 69\n",
      "    Batch 52 / 69\n",
      "    Batch 53 / 69\n",
      "    Batch 54 / 69\n",
      "    Batch 55 / 69\n",
      "    Batch 56 / 69\n",
      "    Batch 57 / 69\n",
      "    Batch 58 / 69\n",
      "    Batch 59 / 69\n",
      "    Batch 60 / 69\n",
      "    Batch 61 / 69\n",
      "    Batch 62 / 69\n",
      "    Batch 63 / 69\n",
      "    Batch 64 / 69\n",
      "    Batch 65 / 69\n",
      "    Batch 66 / 69\n",
      "    Batch 67 / 69\n",
      "    Batch 68 / 69\n",
      "    Batch 69 / 69\n",
      "ROC-AUC score: 0.4970\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 3\n",
      "    Batch 3 / 69: loss 0.6932\n",
      "    ROC-AUC score: 0.3492\n",
      "    Batch 6 / 69: loss 0.6932\n",
      "    ROC-AUC score: 0.3810\n",
      "    Batch 9 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.6587\n",
      "    Batch 12 / 69: loss 0.6932\n",
      "    ROC-AUC score: 0.4156\n",
      "    Batch 15 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.4023\n",
      "    Batch 18 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.6000\n",
      "    Batch 21 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.4196\n",
      "    Batch 24 / 69: loss 0.6932\n",
      "    ROC-AUC score: 0.5156\n",
      "    Batch 27 / 69: loss 0.6929\n",
      "    ROC-AUC score: 0.6721\n",
      "    Batch 30 / 69: loss 0.6933\n",
      "    ROC-AUC score: 0.5125\n",
      "    Batch 33 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.5079\n",
      "    Batch 36 / 69: loss 0.6930\n",
      "    ROC-AUC score: 0.5498\n",
      "    Batch 39 / 69: loss 0.6929\n",
      "    ROC-AUC score: 0.5547\n",
      "    Batch 42 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.5922\n",
      "    Batch 45 / 69: loss 0.6928\n",
      "    ROC-AUC score: 0.5476\n",
      "    Batch 48 / 69: loss 0.6929\n",
      "    ROC-AUC score: 0.5708\n",
      "    Batch 51 / 69: loss 0.6928\n",
      "    ROC-AUC score: 0.6333\n",
      "    Batch 54 / 69: loss 0.6925\n",
      "    ROC-AUC score: 0.7619\n",
      "    Batch 57 / 69: loss 0.6924\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 60 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.3961\n",
      "    Batch 63 / 69: loss 0.6930\n",
      "    ROC-AUC score: 0.5990\n",
      "    Batch 66 / 69: loss 0.6923\n",
      "    ROC-AUC score: 0.7608\n",
      "    Batch 69 / 69: loss 0.6929\n",
      "    ROC-AUC score: 0.2667\n",
      "Epoch 2 / 3\n",
      "    Batch 3 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.5875\n",
      "    Batch 6 / 69: loss 0.6923\n",
      "    ROC-AUC score: 0.6784\n",
      "    Batch 9 / 69: loss 0.6932\n",
      "    ROC-AUC score: 0.4199\n",
      "    Batch 12 / 69: loss 0.6924\n",
      "    ROC-AUC score: 0.4484\n",
      "    Batch 15 / 69: loss 0.6911\n",
      "    ROC-AUC score: 0.6437\n",
      "    Batch 18 / 69: loss 0.6919\n",
      "    ROC-AUC score: 0.4325\n",
      "    Batch 21 / 69: loss 0.6917\n",
      "    ROC-AUC score: 0.6984\n",
      "    Batch 24 / 69: loss 0.6918\n",
      "    ROC-AUC score: 0.5887\n",
      "    Batch 27 / 69: loss 0.6910\n",
      "    ROC-AUC score: 0.5397\n",
      "    Batch 30 / 69: loss 0.6910\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 33 / 69: loss 0.6921\n",
      "    ROC-AUC score: 0.4902\n",
      "    Batch 36 / 69: loss 0.6932\n",
      "    ROC-AUC score: 0.4048\n",
      "    Batch 39 / 69: loss 0.6915\n",
      "    ROC-AUC score: 0.6353\n",
      "    Batch 42 / 69: loss 0.6904\n",
      "    ROC-AUC score: 0.6865\n",
      "    Batch 45 / 69: loss 0.6887\n",
      "    ROC-AUC score: 0.5794\n",
      "    Batch 48 / 69: loss 0.6902\n",
      "    ROC-AUC score: 0.5101\n",
      "    Batch 51 / 69: loss 0.6915\n",
      "    ROC-AUC score: 0.6953\n",
      "    Batch 54 / 69: loss 0.6876\n",
      "    ROC-AUC score: 0.7579\n",
      "    Batch 57 / 69: loss 0.6900\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 60 / 69: loss 0.6873\n",
      "    ROC-AUC score: 0.7765\n",
      "    Batch 63 / 69: loss 0.6909\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 66 / 69: loss 0.6908\n",
      "    ROC-AUC score: 0.5101\n",
      "    Batch 69 / 69: loss 0.6863\n",
      "    ROC-AUC score: 0.9333\n",
      "Epoch 3 / 3\n",
      "    Batch 3 / 69: loss 0.6923\n",
      "    ROC-AUC score: 0.6431\n",
      "    Batch 6 / 69: loss 0.6862\n",
      "    ROC-AUC score: 0.6667\n",
      "    Batch 9 / 69: loss 0.6902\n",
      "    ROC-AUC score: 0.5250\n",
      "    Batch 12 / 69: loss 0.6882\n",
      "    ROC-AUC score: 0.7451\n",
      "    Batch 15 / 69: loss 0.6835\n",
      "    ROC-AUC score: 0.7176\n",
      "    Batch 18 / 69: loss 0.6903\n",
      "    ROC-AUC score: 0.5870\n",
      "    Batch 21 / 69: loss 0.6855\n",
      "    ROC-AUC score: 0.6235\n",
      "    Batch 24 / 69: loss 0.6818\n",
      "    ROC-AUC score: 0.6235\n",
      "    Batch 27 / 69: loss 0.6892\n",
      "    ROC-AUC score: 0.5397\n",
      "    Batch 30 / 69: loss 0.6893\n",
      "    ROC-AUC score: 0.4980\n",
      "    Batch 33 / 69: loss 0.6875\n",
      "    ROC-AUC score: 0.6824\n",
      "    Batch 36 / 69: loss 0.6842\n",
      "    ROC-AUC score: 0.6118\n",
      "    Batch 39 / 69: loss 0.6797\n",
      "    ROC-AUC score: 0.7103\n",
      "    Batch 42 / 69: loss 0.6865\n",
      "    ROC-AUC score: 0.5412\n",
      "    Batch 45 / 69: loss 0.6848\n",
      "    ROC-AUC score: 0.6000\n",
      "    Batch 48 / 69: loss 0.6878\n",
      "    ROC-AUC score: 0.6032\n",
      "    Batch 51 / 69: loss 0.6812\n",
      "    ROC-AUC score: 0.6500\n",
      "    Batch 54 / 69: loss 0.6875\n",
      "    ROC-AUC score: 0.5412\n",
      "    Batch 57 / 69: loss 0.6852\n",
      "    ROC-AUC score: 0.6078\n",
      "    Batch 60 / 69: loss 0.6815\n",
      "    ROC-AUC score: 0.6039\n",
      "    Batch 63 / 69: loss 0.6766\n",
      "    ROC-AUC score: 0.5675\n",
      "    Batch 66 / 69: loss 0.6923\n",
      "    ROC-AUC score: 0.5792\n",
      "    Batch 69 / 69: loss 0.6904\n",
      "    ROC-AUC score: 0.5000\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 600, 1000, 1400], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 69\n",
      "    Batch 2 / 69\n",
      "    Batch 3 / 69\n",
      "    Batch 4 / 69\n",
      "    Batch 5 / 69\n",
      "    Batch 6 / 69\n",
      "    Batch 7 / 69\n",
      "    Batch 8 / 69\n",
      "    Batch 9 / 69\n",
      "    Batch 10 / 69\n",
      "    Batch 11 / 69\n",
      "    Batch 12 / 69\n",
      "    Batch 13 / 69\n",
      "    Batch 14 / 69\n",
      "    Batch 15 / 69\n",
      "    Batch 16 / 69\n",
      "    Batch 17 / 69\n",
      "    Batch 18 / 69\n",
      "    Batch 19 / 69\n",
      "    Batch 20 / 69\n",
      "    Batch 21 / 69\n",
      "    Batch 22 / 69\n",
      "    Batch 23 / 69\n",
      "    Batch 24 / 69\n",
      "    Batch 25 / 69\n",
      "    Batch 26 / 69\n",
      "    Batch 27 / 69\n",
      "    Batch 28 / 69\n",
      "    Batch 29 / 69\n",
      "    Batch 30 / 69\n",
      "    Batch 31 / 69\n",
      "    Batch 32 / 69\n",
      "    Batch 33 / 69\n",
      "    Batch 34 / 69\n",
      "    Batch 35 / 69\n",
      "    Batch 36 / 69\n",
      "    Batch 37 / 69\n",
      "    Batch 38 / 69\n",
      "    Batch 39 / 69\n",
      "    Batch 40 / 69\n",
      "    Batch 41 / 69\n",
      "    Batch 42 / 69\n",
      "    Batch 43 / 69\n",
      "    Batch 44 / 69\n",
      "    Batch 45 / 69\n",
      "    Batch 46 / 69\n",
      "    Batch 47 / 69\n",
      "    Batch 48 / 69\n",
      "    Batch 49 / 69\n",
      "    Batch 50 / 69\n",
      "    Batch 51 / 69\n",
      "    Batch 52 / 69\n",
      "    Batch 53 / 69\n",
      "    Batch 54 / 69\n",
      "    Batch 55 / 69\n",
      "    Batch 56 / 69\n",
      "    Batch 57 / 69\n",
      "    Batch 58 / 69\n",
      "    Batch 59 / 69\n",
      "    Batch 60 / 69\n",
      "    Batch 61 / 69\n",
      "    Batch 62 / 69\n",
      "    Batch 63 / 69\n",
      "    Batch 64 / 69\n",
      "    Batch 65 / 69\n",
      "    Batch 66 / 69\n",
      "    Batch 67 / 69\n",
      "    Batch 68 / 69\n",
      "    Batch 69 / 69\n",
      "ROC-AUC score: 0.6460\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 69\n",
      "    Batch 2 / 69\n",
      "    Batch 3 / 69\n",
      "    Batch 4 / 69\n",
      "    Batch 5 / 69\n",
      "    Batch 6 / 69\n",
      "    Batch 7 / 69\n",
      "    Batch 8 / 69\n",
      "    Batch 9 / 69\n",
      "    Batch 10 / 69\n",
      "    Batch 11 / 69\n",
      "    Batch 12 / 69\n",
      "    Batch 13 / 69\n",
      "    Batch 14 / 69\n",
      "    Batch 15 / 69\n",
      "    Batch 16 / 69\n",
      "    Batch 17 / 69\n",
      "    Batch 18 / 69\n",
      "    Batch 19 / 69\n",
      "    Batch 20 / 69\n",
      "    Batch 21 / 69\n",
      "    Batch 22 / 69\n",
      "    Batch 23 / 69\n",
      "    Batch 24 / 69\n",
      "    Batch 25 / 69\n",
      "    Batch 26 / 69\n",
      "    Batch 27 / 69\n",
      "    Batch 28 / 69\n",
      "    Batch 29 / 69\n",
      "    Batch 30 / 69\n",
      "    Batch 31 / 69\n",
      "    Batch 32 / 69\n",
      "    Batch 33 / 69\n",
      "    Batch 34 / 69\n",
      "    Batch 35 / 69\n",
      "    Batch 36 / 69\n",
      "    Batch 37 / 69\n",
      "    Batch 38 / 69\n",
      "    Batch 39 / 69\n",
      "    Batch 40 / 69\n",
      "    Batch 41 / 69\n",
      "    Batch 42 / 69\n",
      "    Batch 43 / 69\n",
      "    Batch 44 / 69\n",
      "    Batch 45 / 69\n",
      "    Batch 46 / 69\n",
      "    Batch 47 / 69\n",
      "    Batch 48 / 69\n",
      "    Batch 49 / 69\n",
      "    Batch 50 / 69\n",
      "    Batch 51 / 69\n",
      "    Batch 52 / 69\n",
      "    Batch 53 / 69\n",
      "    Batch 54 / 69\n",
      "    Batch 55 / 69\n",
      "    Batch 56 / 69\n",
      "    Batch 57 / 69\n",
      "    Batch 58 / 69\n",
      "    Batch 59 / 69\n",
      "    Batch 60 / 69\n",
      "    Batch 61 / 69\n",
      "    Batch 62 / 69\n",
      "    Batch 63 / 69\n",
      "    Batch 64 / 69\n",
      "    Batch 65 / 69\n",
      "    Batch 66 / 69\n",
      "    Batch 67 / 69\n",
      "    Batch 68 / 69\n",
      "    Batch 69 / 69\n",
      "Threshold: 0.0554, accuracy: 0.5902\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.59      0.59      1092\n",
      "         1.0       0.59      0.59      0.59      1092\n",
      "\n",
      "    accuracy                           0.59      2184\n",
      "   macro avg       0.59      0.59      0.59      2184\n",
      "weighted avg       0.59      0.59      0.59      2184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 151\n",
      "Number of static edges: 1888\n",
      "Number of temporal edges: 37929\n",
      "Number of examples/datapoints: 1932\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 61: loss 0.6919, accuracy 0.5208\n",
      "    ROC-AUC score: 0.6864\n",
      "    Batch 6 / 61: loss 0.6904, accuracy 0.5729\n",
      "    ROC-AUC score: 0.6548\n",
      "    Batch 9 / 61: loss 0.6815, accuracy 0.5938\n",
      "    ROC-AUC score: 0.6797\n",
      "    Batch 12 / 61: loss 0.6943, accuracy 0.4792\n",
      "    ROC-AUC score: 0.6270\n",
      "    Batch 15 / 61: loss 0.6770, accuracy 0.5729\n",
      "    ROC-AUC score: 0.6125\n",
      "    Batch 18 / 61: loss 0.6874, accuracy 0.5312\n",
      "    ROC-AUC score: 0.5469\n",
      "    Batch 21 / 61: loss 0.6770, accuracy 0.6146\n",
      "    ROC-AUC score: 0.4848\n",
      "    Batch 24 / 61: loss 0.6897, accuracy 0.4792\n",
      "    ROC-AUC score: 0.5059\n",
      "    Batch 27 / 61: loss 0.6905, accuracy 0.5417\n",
      "    ROC-AUC score: 0.3417\n",
      "    Batch 30 / 61: loss 0.6928, accuracy 0.5208\n",
      "    ROC-AUC score: 0.6599\n",
      "    Batch 33 / 61: loss 0.6901, accuracy 0.5312\n",
      "    ROC-AUC score: 0.5357\n",
      "    Batch 36 / 61: loss 0.6921, accuracy 0.5104\n",
      "    ROC-AUC score: 0.5344\n",
      "    Batch 39 / 61: loss 0.6890, accuracy 0.5208\n",
      "    ROC-AUC score: 0.6431\n",
      "    Batch 42 / 61: loss 0.7017, accuracy 0.4479\n",
      "    ROC-AUC score: 0.5992\n",
      "    Batch 45 / 61: loss 0.7002, accuracy 0.4375\n",
      "    ROC-AUC score: 0.6957\n",
      "    Batch 48 / 61: loss 0.6889, accuracy 0.5417\n",
      "    ROC-AUC score: 0.3438\n",
      "    Batch 51 / 61: loss 0.6956, accuracy 0.4896\n",
      "    ROC-AUC score: 0.5119\n",
      "    Batch 54 / 61: loss 0.6960, accuracy 0.4688\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 57 / 61: loss 0.6877, accuracy 0.5208\n",
      "    ROC-AUC score: 0.7451\n",
      "    Batch 60 / 61: loss 0.6891, accuracy 0.5208\n",
      "    ROC-AUC score: 0.7368\n",
      "Loss 0.6896, accuracy 0.5223\n",
      "ROC-AUC score: 0.6256\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.09      0.16       966\n",
      "         1.0       0.51      0.95      0.67       966\n",
      "\n",
      "    accuracy                           0.52      1932\n",
      "   macro avg       0.59      0.52      0.41      1932\n",
      "weighted avg       0.59      0.52      0.41      1932\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
