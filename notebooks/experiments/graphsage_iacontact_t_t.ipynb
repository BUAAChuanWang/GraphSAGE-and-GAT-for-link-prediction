{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : False,\n",
    "    \n",
    "    \"duplicate_examples\" : True,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : True,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 2,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 11298\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=274, out_features=274, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=548, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "agg_class = utils.get_agg_class(config['agg_class'])\n",
    "model = models.GraphSAGE(input_dim, config['hidden_dims'],\n",
    "                         output_dim, config['dropout'],\n",
    "                         agg_class, config['num_samples'],\n",
    "                         config['device'])\n",
    "model.to(config['device'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "ROC-AUC score: 0.5109\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 2\n",
      "    Batch 3 / 354: loss 0.6914\n",
      "    ROC-AUC score: 0.4155\n",
      "    Batch 6 / 354: loss 0.6914\n",
      "    ROC-AUC score: 0.6235\n",
      "    Batch 9 / 354: loss 0.6884\n",
      "    ROC-AUC score: 0.8588\n",
      "    Batch 12 / 354: loss 0.6852\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 15 / 354: loss 0.6819\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 18 / 354: loss 0.6785\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 21 / 354: loss 0.6758\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 24 / 354: loss 0.6669\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 27 / 354: loss 0.6669\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 30 / 354: loss 0.6658\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 354: loss 0.6628\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 36 / 354: loss 0.6519\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 39 / 354: loss 0.6549\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 42 / 354: loss 0.6467\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 45 / 354: loss 0.6408\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 48 / 354: loss 0.6559\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 51 / 354: loss 0.6487\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 54 / 354: loss 0.6342\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 57 / 354: loss 0.6233\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 60 / 354: loss 0.6381\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 63 / 354: loss 0.6305\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 66 / 354: loss 0.6077\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 69 / 354: loss 0.6238\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 354: loss 0.6187\n",
      "    ROC-AUC score: 0.9417\n",
      "    Batch 75 / 354: loss 0.6192\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 78 / 354: loss 0.6142\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 81 / 354: loss 0.5791\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 84 / 354: loss 0.6154\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 87 / 354: loss 0.5888\n",
      "    ROC-AUC score: 0.9662\n",
      "    Batch 90 / 354: loss 0.5615\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 93 / 354: loss 0.6087\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 96 / 354: loss 0.5719\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 99 / 354: loss 0.5592\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 102 / 354: loss 0.5664\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 105 / 354: loss 0.5624\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 108 / 354: loss 0.5868\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 111 / 354: loss 0.5828\n",
      "    ROC-AUC score: 0.9792\n",
      "    Batch 114 / 354: loss 0.5519\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 117 / 354: loss 0.5745\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 120 / 354: loss 0.5598\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 123 / 354: loss 0.5736\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 126 / 354: loss 0.5333\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 129 / 354: loss 0.5518\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 132 / 354: loss 0.5374\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 135 / 354: loss 0.4838\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 138 / 354: loss 0.4897\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 141 / 354: loss 0.5182\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 144 / 354: loss 0.5360\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 147 / 354: loss 0.5351\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 150 / 354: loss 0.5220\n",
      "    ROC-AUC score: 0.9740\n",
      "    Batch 153 / 354: loss 0.5114\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 156 / 354: loss 0.4944\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 159 / 354: loss 0.5099\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 162 / 354: loss 0.5302\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 165 / 354: loss 0.4746\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 168 / 354: loss 0.4910\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 171 / 354: loss 0.4779\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 174 / 354: loss 0.4982\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 177 / 354: loss 0.4861\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 180 / 354: loss 0.4676\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 183 / 354: loss 0.4848\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 186 / 354: loss 0.4559\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 189 / 354: loss 0.4812\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 192 / 354: loss 0.5108\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 195 / 354: loss 0.4514\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 198 / 354: loss 0.4380\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 201 / 354: loss 0.4615\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 204 / 354: loss 0.4858\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 207 / 354: loss 0.4583\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 210 / 354: loss 0.5033\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 213 / 354: loss 0.4554\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 216 / 354: loss 0.4451\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 219 / 354: loss 0.4579\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 222 / 354: loss 0.4550\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 225 / 354: loss 0.4846\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 228 / 354: loss 0.5015\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 231 / 354: loss 0.4601\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 234 / 354: loss 0.4720\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 237 / 354: loss 0.4090\n",
      "    ROC-AUC score: 0.9625\n",
      "    Batch 240 / 354: loss 0.3885\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 243 / 354: loss 0.4131\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 246 / 354: loss 0.4578\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 249 / 354: loss 0.4363\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 252 / 354: loss 0.4692\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 255 / 354: loss 0.4682\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 258 / 354: loss 0.4550\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 261 / 354: loss 0.4757\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 264 / 354: loss 0.4890\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 267 / 354: loss 0.4232\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 270 / 354: loss 0.3917\n",
      "    ROC-AUC score: 0.9827\n",
      "    Batch 273 / 354: loss 0.4313\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 276 / 354: loss 0.4554\n",
      "    ROC-AUC score: 0.9805\n",
      "    Batch 279 / 354: loss 0.4892\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 282 / 354: loss 0.4164\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 285 / 354: loss 0.4396\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 288 / 354: loss 0.4312\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 291 / 354: loss 0.4020\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 294 / 354: loss 0.4076\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 297 / 354: loss 0.3818\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 300 / 354: loss 0.4032\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 303 / 354: loss 0.4988\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 306 / 354: loss 0.4605\n",
      "    ROC-AUC score: 0.9676\n",
      "    Batch 309 / 354: loss 0.4598\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 312 / 354: loss 0.4640\n",
      "    ROC-AUC score: 0.9766\n",
      "    Batch 315 / 354: loss 0.4001\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 318 / 354: loss 0.4249\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 321 / 354: loss 0.3884\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 324 / 354: loss 0.3454\n",
      "    ROC-AUC score: 0.9500\n",
      "    Batch 327 / 354: loss 0.3903\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 330 / 354: loss 0.4186\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 333 / 354: loss 0.4362\n",
      "    ROC-AUC score: 0.9708\n",
      "    Batch 336 / 354: loss 0.3610\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 339 / 354: loss 0.4192\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 342 / 354: loss 0.3726\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 345 / 354: loss 0.3997\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 348 / 354: loss 0.4862\n",
      "    ROC-AUC score: 0.9838\n",
      "    Batch 351 / 354: loss 0.3840\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 354 / 354: loss 0.3892\n",
      "    ROC-AUC score: 1.0000\n",
      "Epoch 2 / 2\n",
      "    Batch 3 / 354: loss 0.4023\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 6 / 354: loss 0.4044\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 9 / 354: loss 0.4970\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 12 / 354: loss 0.4126\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 15 / 354: loss 0.4693\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 354: loss 0.3664\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 21 / 354: loss 0.4018\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 24 / 354: loss 0.3828\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 27 / 354: loss 0.4005\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 30 / 354: loss 0.3939\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 354: loss 0.3598\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 354: loss 0.4042\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 39 / 354: loss 0.3623\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 42 / 354: loss 0.3878\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 45 / 354: loss 0.4281\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 48 / 354: loss 0.4172\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 51 / 354: loss 0.3953\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 54 / 354: loss 0.3798\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 57 / 354: loss 0.4315\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 60 / 354: loss 0.3715\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 63 / 354: loss 0.3647\n",
      "    ROC-AUC score: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 66 / 354: loss 0.3450\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 69 / 354: loss 0.4097\n",
      "    ROC-AUC score: 0.9697\n",
      "    Batch 72 / 354: loss 0.3652\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 75 / 354: loss 0.4402\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 78 / 354: loss 0.3804\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 81 / 354: loss 0.4859\n",
      "    ROC-AUC score: 0.9881\n",
      "    Batch 84 / 354: loss 0.4062\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 87 / 354: loss 0.3274\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 354: loss 0.3967\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 93 / 354: loss 0.3735\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 96 / 354: loss 0.3938\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 99 / 354: loss 0.4648\n",
      "    ROC-AUC score: 0.9297\n",
      "    Batch 102 / 354: loss 0.3786\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 105 / 354: loss 0.3746\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 108 / 354: loss 0.3933\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 111 / 354: loss 0.4094\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 114 / 354: loss 0.4051\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 117 / 354: loss 0.3954\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 120 / 354: loss 0.4228\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 123 / 354: loss 0.3875\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 126 / 354: loss 0.3008\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 129 / 354: loss 0.3944\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 132 / 354: loss 0.4283\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 135 / 354: loss 0.3928\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 138 / 354: loss 0.3630\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 141 / 354: loss 0.3653\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 144 / 354: loss 0.3471\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 147 / 354: loss 0.4106\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 150 / 354: loss 0.3510\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 153 / 354: loss 0.3340\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 156 / 354: loss 0.4014\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 159 / 354: loss 0.3739\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 162 / 354: loss 0.3668\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 165 / 354: loss 0.4025\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 168 / 354: loss 0.3682\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 171 / 354: loss 0.4336\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 174 / 354: loss 0.3254\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 177 / 354: loss 0.4043\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 180 / 354: loss 0.3619\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 183 / 354: loss 0.4560\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 186 / 354: loss 0.3830\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 189 / 354: loss 0.3864\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 192 / 354: loss 0.3389\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 195 / 354: loss 0.3738\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 198 / 354: loss 0.3629\n",
      "    ROC-AUC score: 0.9654\n",
      "    Batch 201 / 354: loss 0.4595\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 204 / 354: loss 0.4084\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 207 / 354: loss 0.3631\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 210 / 354: loss 0.3895\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 213 / 354: loss 0.3644\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 216 / 354: loss 0.3969\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 219 / 354: loss 0.3856\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 222 / 354: loss 0.3763\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 225 / 354: loss 0.4397\n",
      "    ROC-AUC score: 0.9595\n",
      "    Batch 228 / 354: loss 0.4142\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 231 / 354: loss 0.3646\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 234 / 354: loss 0.3847\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 237 / 354: loss 0.4177\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 240 / 354: loss 0.4140\n",
      "    ROC-AUC score: 0.9654\n",
      "    Batch 243 / 354: loss 0.4081\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 246 / 354: loss 0.4132\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 249 / 354: loss 0.3430\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 252 / 354: loss 0.3852\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 255 / 354: loss 0.3944\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 258 / 354: loss 0.3817\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 261 / 354: loss 0.4227\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 264 / 354: loss 0.3865\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 267 / 354: loss 0.3845\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 270 / 354: loss 0.3486\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 273 / 354: loss 0.4019\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 276 / 354: loss 0.3512\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 279 / 354: loss 0.4047\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 282 / 354: loss 0.3157\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 285 / 354: loss 0.4336\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 288 / 354: loss 0.3507\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 291 / 354: loss 0.4167\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 294 / 354: loss 0.3570\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 297 / 354: loss 0.3489\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 300 / 354: loss 0.4181\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 303 / 354: loss 0.3397\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 306 / 354: loss 0.3643\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 309 / 354: loss 0.3766\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 312 / 354: loss 0.4192\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 315 / 354: loss 0.4797\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 318 / 354: loss 0.3468\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 321 / 354: loss 0.3808\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 324 / 354: loss 0.3506\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 327 / 354: loss 0.4460\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 330 / 354: loss 0.4112\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 333 / 354: loss 0.4033\n",
      "    ROC-AUC score: 0.9875\n",
      "    Batch 336 / 354: loss 0.3583\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 339 / 354: loss 0.3568\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 342 / 354: loss 0.3934\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 345 / 354: loss 0.3617\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 348 / 354: loss 0.3949\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 351 / 354: loss 0.3885\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 354 / 354: loss 0.3666\n",
      "    ROC-AUC score: 1.0000\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 80], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "ROC-AUC score: 0.9869\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 354\n",
      "    Batch 2 / 354\n",
      "    Batch 3 / 354\n",
      "    Batch 4 / 354\n",
      "    Batch 5 / 354\n",
      "    Batch 6 / 354\n",
      "    Batch 7 / 354\n",
      "    Batch 8 / 354\n",
      "    Batch 9 / 354\n",
      "    Batch 10 / 354\n",
      "    Batch 11 / 354\n",
      "    Batch 12 / 354\n",
      "    Batch 13 / 354\n",
      "    Batch 14 / 354\n",
      "    Batch 15 / 354\n",
      "    Batch 16 / 354\n",
      "    Batch 17 / 354\n",
      "    Batch 18 / 354\n",
      "    Batch 19 / 354\n",
      "    Batch 20 / 354\n",
      "    Batch 21 / 354\n",
      "    Batch 22 / 354\n",
      "    Batch 23 / 354\n",
      "    Batch 24 / 354\n",
      "    Batch 25 / 354\n",
      "    Batch 26 / 354\n",
      "    Batch 27 / 354\n",
      "    Batch 28 / 354\n",
      "    Batch 29 / 354\n",
      "    Batch 30 / 354\n",
      "    Batch 31 / 354\n",
      "    Batch 32 / 354\n",
      "    Batch 33 / 354\n",
      "    Batch 34 / 354\n",
      "    Batch 35 / 354\n",
      "    Batch 36 / 354\n",
      "    Batch 37 / 354\n",
      "    Batch 38 / 354\n",
      "    Batch 39 / 354\n",
      "    Batch 40 / 354\n",
      "    Batch 41 / 354\n",
      "    Batch 42 / 354\n",
      "    Batch 43 / 354\n",
      "    Batch 44 / 354\n",
      "    Batch 45 / 354\n",
      "    Batch 46 / 354\n",
      "    Batch 47 / 354\n",
      "    Batch 48 / 354\n",
      "    Batch 49 / 354\n",
      "    Batch 50 / 354\n",
      "    Batch 51 / 354\n",
      "    Batch 52 / 354\n",
      "    Batch 53 / 354\n",
      "    Batch 54 / 354\n",
      "    Batch 55 / 354\n",
      "    Batch 56 / 354\n",
      "    Batch 57 / 354\n",
      "    Batch 58 / 354\n",
      "    Batch 59 / 354\n",
      "    Batch 60 / 354\n",
      "    Batch 61 / 354\n",
      "    Batch 62 / 354\n",
      "    Batch 63 / 354\n",
      "    Batch 64 / 354\n",
      "    Batch 65 / 354\n",
      "    Batch 66 / 354\n",
      "    Batch 67 / 354\n",
      "    Batch 68 / 354\n",
      "    Batch 69 / 354\n",
      "    Batch 70 / 354\n",
      "    Batch 71 / 354\n",
      "    Batch 72 / 354\n",
      "    Batch 73 / 354\n",
      "    Batch 74 / 354\n",
      "    Batch 75 / 354\n",
      "    Batch 76 / 354\n",
      "    Batch 77 / 354\n",
      "    Batch 78 / 354\n",
      "    Batch 79 / 354\n",
      "    Batch 80 / 354\n",
      "    Batch 81 / 354\n",
      "    Batch 82 / 354\n",
      "    Batch 83 / 354\n",
      "    Batch 84 / 354\n",
      "    Batch 85 / 354\n",
      "    Batch 86 / 354\n",
      "    Batch 87 / 354\n",
      "    Batch 88 / 354\n",
      "    Batch 89 / 354\n",
      "    Batch 90 / 354\n",
      "    Batch 91 / 354\n",
      "    Batch 92 / 354\n",
      "    Batch 93 / 354\n",
      "    Batch 94 / 354\n",
      "    Batch 95 / 354\n",
      "    Batch 96 / 354\n",
      "    Batch 97 / 354\n",
      "    Batch 98 / 354\n",
      "    Batch 99 / 354\n",
      "    Batch 100 / 354\n",
      "    Batch 101 / 354\n",
      "    Batch 102 / 354\n",
      "    Batch 103 / 354\n",
      "    Batch 104 / 354\n",
      "    Batch 105 / 354\n",
      "    Batch 106 / 354\n",
      "    Batch 107 / 354\n",
      "    Batch 108 / 354\n",
      "    Batch 109 / 354\n",
      "    Batch 110 / 354\n",
      "    Batch 111 / 354\n",
      "    Batch 112 / 354\n",
      "    Batch 113 / 354\n",
      "    Batch 114 / 354\n",
      "    Batch 115 / 354\n",
      "    Batch 116 / 354\n",
      "    Batch 117 / 354\n",
      "    Batch 118 / 354\n",
      "    Batch 119 / 354\n",
      "    Batch 120 / 354\n",
      "    Batch 121 / 354\n",
      "    Batch 122 / 354\n",
      "    Batch 123 / 354\n",
      "    Batch 124 / 354\n",
      "    Batch 125 / 354\n",
      "    Batch 126 / 354\n",
      "    Batch 127 / 354\n",
      "    Batch 128 / 354\n",
      "    Batch 129 / 354\n",
      "    Batch 130 / 354\n",
      "    Batch 131 / 354\n",
      "    Batch 132 / 354\n",
      "    Batch 133 / 354\n",
      "    Batch 134 / 354\n",
      "    Batch 135 / 354\n",
      "    Batch 136 / 354\n",
      "    Batch 137 / 354\n",
      "    Batch 138 / 354\n",
      "    Batch 139 / 354\n",
      "    Batch 140 / 354\n",
      "    Batch 141 / 354\n",
      "    Batch 142 / 354\n",
      "    Batch 143 / 354\n",
      "    Batch 144 / 354\n",
      "    Batch 145 / 354\n",
      "    Batch 146 / 354\n",
      "    Batch 147 / 354\n",
      "    Batch 148 / 354\n",
      "    Batch 149 / 354\n",
      "    Batch 150 / 354\n",
      "    Batch 151 / 354\n",
      "    Batch 152 / 354\n",
      "    Batch 153 / 354\n",
      "    Batch 154 / 354\n",
      "    Batch 155 / 354\n",
      "    Batch 156 / 354\n",
      "    Batch 157 / 354\n",
      "    Batch 158 / 354\n",
      "    Batch 159 / 354\n",
      "    Batch 160 / 354\n",
      "    Batch 161 / 354\n",
      "    Batch 162 / 354\n",
      "    Batch 163 / 354\n",
      "    Batch 164 / 354\n",
      "    Batch 165 / 354\n",
      "    Batch 166 / 354\n",
      "    Batch 167 / 354\n",
      "    Batch 168 / 354\n",
      "    Batch 169 / 354\n",
      "    Batch 170 / 354\n",
      "    Batch 171 / 354\n",
      "    Batch 172 / 354\n",
      "    Batch 173 / 354\n",
      "    Batch 174 / 354\n",
      "    Batch 175 / 354\n",
      "    Batch 176 / 354\n",
      "    Batch 177 / 354\n",
      "    Batch 178 / 354\n",
      "    Batch 179 / 354\n",
      "    Batch 180 / 354\n",
      "    Batch 181 / 354\n",
      "    Batch 182 / 354\n",
      "    Batch 183 / 354\n",
      "    Batch 184 / 354\n",
      "    Batch 185 / 354\n",
      "    Batch 186 / 354\n",
      "    Batch 187 / 354\n",
      "    Batch 188 / 354\n",
      "    Batch 189 / 354\n",
      "    Batch 190 / 354\n",
      "    Batch 191 / 354\n",
      "    Batch 192 / 354\n",
      "    Batch 193 / 354\n",
      "    Batch 194 / 354\n",
      "    Batch 195 / 354\n",
      "    Batch 196 / 354\n",
      "    Batch 197 / 354\n",
      "    Batch 198 / 354\n",
      "    Batch 199 / 354\n",
      "    Batch 200 / 354\n",
      "    Batch 201 / 354\n",
      "    Batch 202 / 354\n",
      "    Batch 203 / 354\n",
      "    Batch 204 / 354\n",
      "    Batch 205 / 354\n",
      "    Batch 206 / 354\n",
      "    Batch 207 / 354\n",
      "    Batch 208 / 354\n",
      "    Batch 209 / 354\n",
      "    Batch 210 / 354\n",
      "    Batch 211 / 354\n",
      "    Batch 212 / 354\n",
      "    Batch 213 / 354\n",
      "    Batch 214 / 354\n",
      "    Batch 215 / 354\n",
      "    Batch 216 / 354\n",
      "    Batch 217 / 354\n",
      "    Batch 218 / 354\n",
      "    Batch 219 / 354\n",
      "    Batch 220 / 354\n",
      "    Batch 221 / 354\n",
      "    Batch 222 / 354\n",
      "    Batch 223 / 354\n",
      "    Batch 224 / 354\n",
      "    Batch 225 / 354\n",
      "    Batch 226 / 354\n",
      "    Batch 227 / 354\n",
      "    Batch 228 / 354\n",
      "    Batch 229 / 354\n",
      "    Batch 230 / 354\n",
      "    Batch 231 / 354\n",
      "    Batch 232 / 354\n",
      "    Batch 233 / 354\n",
      "    Batch 234 / 354\n",
      "    Batch 235 / 354\n",
      "    Batch 236 / 354\n",
      "    Batch 237 / 354\n",
      "    Batch 238 / 354\n",
      "    Batch 239 / 354\n",
      "    Batch 240 / 354\n",
      "    Batch 241 / 354\n",
      "    Batch 242 / 354\n",
      "    Batch 243 / 354\n",
      "    Batch 244 / 354\n",
      "    Batch 245 / 354\n",
      "    Batch 246 / 354\n",
      "    Batch 247 / 354\n",
      "    Batch 248 / 354\n",
      "    Batch 249 / 354\n",
      "    Batch 250 / 354\n",
      "    Batch 251 / 354\n",
      "    Batch 252 / 354\n",
      "    Batch 253 / 354\n",
      "    Batch 254 / 354\n",
      "    Batch 255 / 354\n",
      "    Batch 256 / 354\n",
      "    Batch 257 / 354\n",
      "    Batch 258 / 354\n",
      "    Batch 259 / 354\n",
      "    Batch 260 / 354\n",
      "    Batch 261 / 354\n",
      "    Batch 262 / 354\n",
      "    Batch 263 / 354\n",
      "    Batch 264 / 354\n",
      "    Batch 265 / 354\n",
      "    Batch 266 / 354\n",
      "    Batch 267 / 354\n",
      "    Batch 268 / 354\n",
      "    Batch 269 / 354\n",
      "    Batch 270 / 354\n",
      "    Batch 271 / 354\n",
      "    Batch 272 / 354\n",
      "    Batch 273 / 354\n",
      "    Batch 274 / 354\n",
      "    Batch 275 / 354\n",
      "    Batch 276 / 354\n",
      "    Batch 277 / 354\n",
      "    Batch 278 / 354\n",
      "    Batch 279 / 354\n",
      "    Batch 280 / 354\n",
      "    Batch 281 / 354\n",
      "    Batch 282 / 354\n",
      "    Batch 283 / 354\n",
      "    Batch 284 / 354\n",
      "    Batch 285 / 354\n",
      "    Batch 286 / 354\n",
      "    Batch 287 / 354\n",
      "    Batch 288 / 354\n",
      "    Batch 289 / 354\n",
      "    Batch 290 / 354\n",
      "    Batch 291 / 354\n",
      "    Batch 292 / 354\n",
      "    Batch 293 / 354\n",
      "    Batch 294 / 354\n",
      "    Batch 295 / 354\n",
      "    Batch 296 / 354\n",
      "    Batch 297 / 354\n",
      "    Batch 298 / 354\n",
      "    Batch 299 / 354\n",
      "    Batch 300 / 354\n",
      "    Batch 301 / 354\n",
      "    Batch 302 / 354\n",
      "    Batch 303 / 354\n",
      "    Batch 304 / 354\n",
      "    Batch 305 / 354\n",
      "    Batch 306 / 354\n",
      "    Batch 307 / 354\n",
      "    Batch 308 / 354\n",
      "    Batch 309 / 354\n",
      "    Batch 310 / 354\n",
      "    Batch 311 / 354\n",
      "    Batch 312 / 354\n",
      "    Batch 313 / 354\n",
      "    Batch 314 / 354\n",
      "    Batch 315 / 354\n",
      "    Batch 316 / 354\n",
      "    Batch 317 / 354\n",
      "    Batch 318 / 354\n",
      "    Batch 319 / 354\n",
      "    Batch 320 / 354\n",
      "    Batch 321 / 354\n",
      "    Batch 322 / 354\n",
      "    Batch 323 / 354\n",
      "    Batch 324 / 354\n",
      "    Batch 325 / 354\n",
      "    Batch 326 / 354\n",
      "    Batch 327 / 354\n",
      "    Batch 328 / 354\n",
      "    Batch 329 / 354\n",
      "    Batch 330 / 354\n",
      "    Batch 331 / 354\n",
      "    Batch 332 / 354\n",
      "    Batch 333 / 354\n",
      "    Batch 334 / 354\n",
      "    Batch 335 / 354\n",
      "    Batch 336 / 354\n",
      "    Batch 337 / 354\n",
      "    Batch 338 / 354\n",
      "    Batch 339 / 354\n",
      "    Batch 340 / 354\n",
      "    Batch 341 / 354\n",
      "    Batch 342 / 354\n",
      "    Batch 343 / 354\n",
      "    Batch 344 / 354\n",
      "    Batch 345 / 354\n",
      "    Batch 346 / 354\n",
      "    Batch 347 / 354\n",
      "    Batch 348 / 354\n",
      "    Batch 349 / 354\n",
      "    Batch 350 / 354\n",
      "    Batch 351 / 354\n",
      "    Batch 352 / 354\n",
      "    Batch 353 / 354\n",
      "    Batch 354 / 354\n",
      "Threshold: 0.8377, accuracy: 0.9586\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96      5649\n",
      "         1.0       0.96      0.96      0.96      5649\n",
      "\n",
      "    accuracy                           0.96     11298\n",
      "   macro avg       0.96      0.96      0.96     11298\n",
      "weighted avg       0.96      0.96      0.96     11298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: val\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2112\n",
      "Number of temporal edges: 14122\n",
      "Number of examples/datapoints: 14122\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the validation dataset after training.\n",
      "    Batch 3 / 442: loss 0.4078, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 6 / 442: loss 0.5307, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8259\n",
      "    Batch 9 / 442: loss 0.4669, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 12 / 442: loss 0.3984, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 15 / 442: loss 0.4046, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 18 / 442: loss 0.4260, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 21 / 442: loss 0.4513, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9555\n",
      "    Batch 24 / 442: loss 0.4312, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 27 / 442: loss 0.4413, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 30 / 442: loss 0.3772, accuracy 0.9375\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 442: loss 0.5113, accuracy 0.8646\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 442: loss 0.4725, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 39 / 442: loss 0.4308, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9219\n",
      "    Batch 42 / 442: loss 0.4459, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 45 / 442: loss 0.4495, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9208\n",
      "    Batch 48 / 442: loss 0.4167, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 51 / 442: loss 0.3942, accuracy 0.9271\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 442: loss 0.3805, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9190\n",
      "    Batch 57 / 442: loss 0.4013, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 60 / 442: loss 0.4089, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 63 / 442: loss 0.4287, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8828\n",
      "    Batch 66 / 442: loss 0.4058, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 69 / 442: loss 0.4610, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 72 / 442: loss 0.4405, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9883\n",
      "    Batch 75 / 442: loss 0.5092, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 78 / 442: loss 0.4560, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 81 / 442: loss 0.4210, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8867\n",
      "    Batch 84 / 442: loss 0.4473, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9125\n",
      "    Batch 87 / 442: loss 0.4533, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 90 / 442: loss 0.4439, accuracy 0.9375\n",
      "    ROC-AUC score: 0.8945\n",
      "    Batch 93 / 442: loss 0.4932, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8907\n",
      "    Batch 96 / 442: loss 0.4100, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9686\n",
      "    Batch 99 / 442: loss 0.3996, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 102 / 442: loss 0.4692, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 105 / 442: loss 0.4292, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 108 / 442: loss 0.4026, accuracy 0.9271\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 111 / 442: loss 0.4509, accuracy 0.9062\n",
      "    ROC-AUC score: 0.7937\n",
      "    Batch 114 / 442: loss 0.4130, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9567\n",
      "    Batch 117 / 442: loss 0.5621, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 120 / 442: loss 0.3999, accuracy 0.9688\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 123 / 442: loss 0.3793, accuracy 0.9375\n",
      "    ROC-AUC score: 0.8708\n",
      "    Batch 126 / 442: loss 0.3484, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9688\n",
      "    Batch 129 / 442: loss 0.4408, accuracy 0.9583\n",
      "    ROC-AUC score: 0.8937\n",
      "    Batch 132 / 442: loss 0.4516, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8866\n",
      "    Batch 135 / 442: loss 0.5309, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9307\n",
      "    Batch 138 / 442: loss 0.4944, accuracy 0.8438\n",
      "    ROC-AUC score: 0.7930\n",
      "    Batch 141 / 442: loss 0.3938, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 144 / 442: loss 0.4812, accuracy 0.8646\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 147 / 442: loss 0.4220, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9109\n",
      "    Batch 150 / 442: loss 0.5439, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9125\n",
      "    Batch 153 / 442: loss 0.3771, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 156 / 442: loss 0.5330, accuracy 0.8646\n",
      "    ROC-AUC score: 0.7965\n",
      "    Batch 159 / 442: loss 0.4500, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 162 / 442: loss 0.4221, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 165 / 442: loss 0.4800, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 168 / 442: loss 0.3521, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 171 / 442: loss 0.4420, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 174 / 442: loss 0.4224, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 177 / 442: loss 0.4954, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 180 / 442: loss 0.3351, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 183 / 442: loss 0.4456, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 186 / 442: loss 0.3735, accuracy 0.9688\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 189 / 442: loss 0.4590, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 192 / 442: loss 0.4429, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9364\n",
      "    Batch 195 / 442: loss 0.4503, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 198 / 442: loss 0.4726, accuracy 0.9271\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 201 / 442: loss 0.3911, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 204 / 442: loss 0.4782, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 207 / 442: loss 0.3714, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 210 / 442: loss 0.4079, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9409\n",
      "    Batch 213 / 442: loss 0.4352, accuracy 0.9375\n",
      "    ROC-AUC score: 0.8828\n",
      "    Batch 216 / 442: loss 0.5185, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8907\n",
      "    Batch 219 / 442: loss 0.4431, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 222 / 442: loss 0.3647, accuracy 0.9479\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 225 / 442: loss 0.3709, accuracy 0.9062\n",
      "    ROC-AUC score: 0.7930\n",
      "    Batch 228 / 442: loss 0.4727, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9417\n",
      "    Batch 231 / 442: loss 0.4001, accuracy 0.9583\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 234 / 442: loss 0.4126, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 237 / 442: loss 0.4697, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9481\n",
      "    Batch 240 / 442: loss 0.4230, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 243 / 442: loss 0.3973, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 246 / 442: loss 0.4384, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9219\n",
      "    Batch 249 / 442: loss 0.3813, accuracy 0.9792\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 252 / 442: loss 0.4310, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 255 / 442: loss 0.3630, accuracy 0.9583\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 258 / 442: loss 0.3689, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 261 / 442: loss 0.3978, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9625\n",
      "    Batch 264 / 442: loss 0.4549, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 267 / 442: loss 0.5078, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 270 / 442: loss 0.3898, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 273 / 442: loss 0.3533, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 276 / 442: loss 0.3830, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 279 / 442: loss 0.4438, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 282 / 442: loss 0.3420, accuracy 0.9792\n",
      "    ROC-AUC score: 0.9595\n",
      "    Batch 285 / 442: loss 0.4587, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 288 / 442: loss 0.4046, accuracy 0.9375\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 291 / 442: loss 0.4071, accuracy 0.9062\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 294 / 442: loss 0.4366, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 297 / 442: loss 0.4158, accuracy 0.9375\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 300 / 442: loss 0.3929, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 303 / 442: loss 0.4090, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 306 / 442: loss 0.5305, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9879\n",
      "    Batch 309 / 442: loss 0.3226, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 312 / 442: loss 0.4554, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 315 / 442: loss 0.4335, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 318 / 442: loss 0.3912, accuracy 0.9479\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 321 / 442: loss 0.4544, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 324 / 442: loss 0.3580, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9654\n",
      "    Batch 327 / 442: loss 0.4292, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 330 / 442: loss 0.4901, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9595\n",
      "    Batch 333 / 442: loss 0.4168, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8906\n",
      "    Batch 336 / 442: loss 0.5222, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 339 / 442: loss 0.4091, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 342 / 442: loss 0.3756, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 345 / 442: loss 0.4015, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9351\n",
      "    Batch 348 / 442: loss 0.4539, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 351 / 442: loss 0.4028, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 354 / 442: loss 0.4957, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 357 / 442: loss 0.4163, accuracy 0.9062\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 360 / 442: loss 0.3828, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 363 / 442: loss 0.4496, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 366 / 442: loss 0.3711, accuracy 0.9792\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 369 / 442: loss 0.4544, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 372 / 442: loss 0.3408, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 375 / 442: loss 0.3678, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9717\n",
      "    Batch 378 / 442: loss 0.4158, accuracy 0.9583\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 381 / 442: loss 0.3916, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 384 / 442: loss 0.3307, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9750\n",
      "    Batch 387 / 442: loss 0.4600, accuracy 0.8958\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 390 / 442: loss 0.4197, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 393 / 442: loss 0.4065, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 396 / 442: loss 0.4575, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 399 / 442: loss 0.4467, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 402 / 442: loss 0.3590, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9750\n",
      "    Batch 405 / 442: loss 0.4075, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 408 / 442: loss 0.4749, accuracy 0.8854\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 411 / 442: loss 0.3910, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 414 / 442: loss 0.3963, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 417 / 442: loss 0.4240, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 420 / 442: loss 0.4637, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 423 / 442: loss 0.4230, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9609\n",
      "    Batch 426 / 442: loss 0.3949, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 429 / 442: loss 0.4634, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 432 / 442: loss 0.4386, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 435 / 442: loss 0.5153, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 438 / 442: loss 0.4339, accuracy 0.9062\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 441 / 442: loss 0.3784, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9333\n",
      "Loss 0.4281, accuracy 0.9119\n",
      "ROC-AUC score: 0.9353\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.93      0.91      7061\n",
      "         1.0       0.92      0.90      0.91      7061\n",
      "\n",
      "    accuracy                           0.91     14122\n",
      "   macro avg       0.91      0.91      0.91     14122\n",
      "weighted avg       0.91      0.91      0.91     14122\n",
      "\n",
      "Finished validating.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'val',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the validation dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished validating.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 14100\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 441: loss 0.4760, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 6 / 441: loss 0.5127, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 9 / 441: loss 0.4557, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9246\n",
      "    Batch 12 / 441: loss 0.3957, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8937\n",
      "    Batch 15 / 441: loss 0.4509, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9555\n",
      "    Batch 18 / 441: loss 0.4528, accuracy 0.9062\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 21 / 441: loss 0.5125, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9150\n",
      "    Batch 24 / 441: loss 0.4199, accuracy 0.9271\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 441: loss 0.4235, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 30 / 441: loss 0.4899, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 33 / 441: loss 0.4841, accuracy 0.8646\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 441: loss 0.4504, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 39 / 441: loss 0.4448, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 42 / 441: loss 0.4715, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8458\n",
      "    Batch 45 / 441: loss 0.4793, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 48 / 441: loss 0.5558, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 51 / 441: loss 0.4223, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 54 / 441: loss 0.5144, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 57 / 441: loss 0.5147, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 60 / 441: loss 0.3966, accuracy 0.8854\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 63 / 441: loss 0.4082, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 66 / 441: loss 0.4309, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9219\n",
      "    Batch 69 / 441: loss 0.4634, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 441: loss 0.4493, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9805\n",
      "    Batch 75 / 441: loss 0.5635, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 78 / 441: loss 0.4171, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 81 / 441: loss 0.4176, accuracy 0.9375\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 84 / 441: loss 0.4089, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 87 / 441: loss 0.4324, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 441: loss 0.5703, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 93 / 441: loss 0.5552, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9109\n",
      "    Batch 96 / 441: loss 0.5132, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 99 / 441: loss 0.3683, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 102 / 441: loss 0.4957, accuracy 0.9062\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 105 / 441: loss 0.3940, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 108 / 441: loss 0.4582, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9087\n",
      "    Batch 111 / 441: loss 0.4485, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 114 / 441: loss 0.4825, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9351\n",
      "    Batch 117 / 441: loss 0.4910, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 120 / 441: loss 0.5247, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 123 / 441: loss 0.4239, accuracy 0.9479\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 126 / 441: loss 0.4120, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9190\n",
      "    Batch 129 / 441: loss 0.4245, accuracy 0.9583\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 132 / 441: loss 0.4799, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 135 / 441: loss 0.5111, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8359\n",
      "    Batch 138 / 441: loss 0.5626, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 141 / 441: loss 0.5072, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 144 / 441: loss 0.5809, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9765\n",
      "    Batch 147 / 441: loss 0.3789, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 150 / 441: loss 0.4265, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 153 / 441: loss 0.4844, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 156 / 441: loss 0.5228, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8651\n",
      "    Batch 159 / 441: loss 0.4050, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 162 / 441: loss 0.5017, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9134\n",
      "    Batch 165 / 441: loss 0.4739, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8633\n",
      "    Batch 168 / 441: loss 0.3812, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 171 / 441: loss 0.5002, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 174 / 441: loss 0.5101, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9567\n",
      "    Batch 177 / 441: loss 0.5492, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 180 / 441: loss 0.4709, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 183 / 441: loss 0.6111, accuracy 0.8021\n",
      "    ROC-AUC score: 0.7725\n",
      "    Batch 186 / 441: loss 0.4572, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9686\n",
      "    Batch 189 / 441: loss 0.4013, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 192 / 441: loss 0.4621, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 195 / 441: loss 0.4042, accuracy 0.9375\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 198 / 441: loss 0.3983, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 201 / 441: loss 0.4624, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 204 / 441: loss 0.5213, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 207 / 441: loss 0.4844, accuracy 0.9375\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 210 / 441: loss 0.4361, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 213 / 441: loss 0.4829, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8502\n",
      "    Batch 216 / 441: loss 0.5268, accuracy 0.8542\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 219 / 441: loss 0.3844, accuracy 0.9479\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 222 / 441: loss 0.4579, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9805\n",
      "    Batch 225 / 441: loss 0.3592, accuracy 0.9271\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 228 / 441: loss 0.3444, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 231 / 441: loss 0.4506, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9136\n",
      "    Batch 234 / 441: loss 0.3772, accuracy 0.9583\n",
      "    ROC-AUC score: 0.8988\n",
      "    Batch 237 / 441: loss 0.5743, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8651\n",
      "    Batch 240 / 441: loss 0.5324, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 243 / 441: loss 0.3798, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9955\n",
      "    Batch 246 / 441: loss 0.5259, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8588\n",
      "    Batch 249 / 441: loss 0.5438, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 252 / 441: loss 0.4366, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 255 / 441: loss 0.4478, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 258 / 441: loss 0.4135, accuracy 0.9583\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 261 / 441: loss 0.3809, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9545\n",
      "    Batch 264 / 441: loss 0.4855, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 267 / 441: loss 0.3778, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 270 / 441: loss 0.4246, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 273 / 441: loss 0.3622, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 276 / 441: loss 0.4421, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 279 / 441: loss 0.4759, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 282 / 441: loss 0.4621, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 285 / 441: loss 0.5159, accuracy 0.8542\n",
      "    ROC-AUC score: 0.7833\n",
      "    Batch 288 / 441: loss 0.4726, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9883\n",
      "    Batch 291 / 441: loss 0.4826, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8588\n",
      "    Batch 294 / 441: loss 0.4293, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 297 / 441: loss 0.4145, accuracy 0.9167\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 300 / 441: loss 0.4728, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 303 / 441: loss 0.4340, accuracy 0.9271\n",
      "    ROC-AUC score: 0.8672\n",
      "    Batch 306 / 441: loss 0.4800, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 309 / 441: loss 0.4433, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 312 / 441: loss 0.4949, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 315 / 441: loss 0.4871, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 318 / 441: loss 0.4756, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 321 / 441: loss 0.4869, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9773\n",
      "    Batch 324 / 441: loss 0.4373, accuracy 0.9062\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 327 / 441: loss 0.4444, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 330 / 441: loss 0.4681, accuracy 0.9583\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 333 / 441: loss 0.4421, accuracy 0.9062\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 336 / 441: loss 0.5388, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9784\n",
      "    Batch 339 / 441: loss 0.4484, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 342 / 441: loss 0.5246, accuracy 0.9062\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 345 / 441: loss 0.3882, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 348 / 441: loss 0.4290, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 351 / 441: loss 0.5377, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 354 / 441: loss 0.4423, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9393\n",
      "    Batch 357 / 441: loss 0.4536, accuracy 0.8958\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 360 / 441: loss 0.3936, accuracy 0.9583\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 363 / 441: loss 0.4160, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 366 / 441: loss 0.4324, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9648\n",
      "    Batch 369 / 441: loss 0.4517, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9762\n",
      "    Batch 372 / 441: loss 0.5307, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 375 / 441: loss 0.5061, accuracy 0.8854\n",
      "    ROC-AUC score: 0.7229\n",
      "    Batch 378 / 441: loss 0.4486, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 381 / 441: loss 0.4103, accuracy 0.9583\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 384 / 441: loss 0.4631, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 387 / 441: loss 0.5164, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8542\n",
      "    Batch 390 / 441: loss 0.4245, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 393 / 441: loss 0.4711, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9870\n",
      "    Batch 396 / 441: loss 0.5044, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9083\n",
      "    Batch 399 / 441: loss 0.4448, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 402 / 441: loss 0.4205, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 405 / 441: loss 0.4511, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 408 / 441: loss 0.5268, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8831\n",
      "    Batch 411 / 441: loss 0.5724, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 414 / 441: loss 0.4814, accuracy 0.9167\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 417 / 441: loss 0.4657, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 420 / 441: loss 0.4462, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8056\n",
      "    Batch 423 / 441: loss 0.5042, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9643\n",
      "    Batch 426 / 441: loss 0.4477, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 429 / 441: loss 0.4864, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9150\n",
      "    Batch 432 / 441: loss 0.4917, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 435 / 441: loss 0.5120, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 438 / 441: loss 0.4192, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9583\n",
      "    Batch 441 / 441: loss 0.4829, accuracy 0.9048\n",
      "    ROC-AUC score: 0.9643\n",
      "Loss 0.4638, accuracy 0.8970\n",
      "ROC-AUC score: 0.9383\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.89      0.90      7050\n",
      "         1.0       0.89      0.90      0.90      7050\n",
      "\n",
      "    accuracy                           0.90     14100\n",
      "   macro avg       0.90      0.90      0.90     14100\n",
      "weighted avg       0.90      0.90      0.90     14100\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
