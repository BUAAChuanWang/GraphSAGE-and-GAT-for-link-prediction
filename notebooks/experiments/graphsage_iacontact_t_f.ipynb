{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContact\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : False,\n",
    "    \n",
    "    \"duplicate_examples\" : True,\n",
    "    \"repeat_examples\" : False,\n",
    "    \n",
    "    \"self_loop\" : True,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 5,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 274\n",
      "Number of static edges: 1686\n",
      "Number of temporal edges: 8473\n",
      "Number of examples/datapoints: 4066\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=274, out_features=274, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=548, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "agg_class = utils.get_agg_class(config['agg_class'])\n",
    "model = models.GraphSAGE(input_dim, config['hidden_dims'],\n",
    "                         output_dim, config['dropout'],\n",
    "                         agg_class, config['num_samples'],\n",
    "                         config['device'])\n",
    "model.to(config['device'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 128\n",
      "    Batch 2 / 128\n",
      "    Batch 3 / 128\n",
      "    Batch 4 / 128\n",
      "    Batch 5 / 128\n",
      "    Batch 6 / 128\n",
      "    Batch 7 / 128\n",
      "    Batch 8 / 128\n",
      "    Batch 9 / 128\n",
      "    Batch 10 / 128\n",
      "    Batch 11 / 128\n",
      "    Batch 12 / 128\n",
      "    Batch 13 / 128\n",
      "    Batch 14 / 128\n",
      "    Batch 15 / 128\n",
      "    Batch 16 / 128\n",
      "    Batch 17 / 128\n",
      "    Batch 18 / 128\n",
      "    Batch 19 / 128\n",
      "    Batch 20 / 128\n",
      "    Batch 21 / 128\n",
      "    Batch 22 / 128\n",
      "    Batch 23 / 128\n",
      "    Batch 24 / 128\n",
      "    Batch 25 / 128\n",
      "    Batch 26 / 128\n",
      "    Batch 27 / 128\n",
      "    Batch 28 / 128\n",
      "    Batch 29 / 128\n",
      "    Batch 30 / 128\n",
      "    Batch 31 / 128\n",
      "    Batch 32 / 128\n",
      "    Batch 33 / 128\n",
      "    Batch 34 / 128\n",
      "    Batch 35 / 128\n",
      "    Batch 36 / 128\n",
      "    Batch 37 / 128\n",
      "    Batch 38 / 128\n",
      "    Batch 39 / 128\n",
      "    Batch 40 / 128\n",
      "    Batch 41 / 128\n",
      "    Batch 42 / 128\n",
      "    Batch 43 / 128\n",
      "    Batch 44 / 128\n",
      "    Batch 45 / 128\n",
      "    Batch 46 / 128\n",
      "    Batch 47 / 128\n",
      "    Batch 48 / 128\n",
      "    Batch 49 / 128\n",
      "    Batch 50 / 128\n",
      "    Batch 51 / 128\n",
      "    Batch 52 / 128\n",
      "    Batch 53 / 128\n",
      "    Batch 54 / 128\n",
      "    Batch 55 / 128\n",
      "    Batch 56 / 128\n",
      "    Batch 57 / 128\n",
      "    Batch 58 / 128\n",
      "    Batch 59 / 128\n",
      "    Batch 60 / 128\n",
      "    Batch 61 / 128\n",
      "    Batch 62 / 128\n",
      "    Batch 63 / 128\n",
      "    Batch 64 / 128\n",
      "    Batch 65 / 128\n",
      "    Batch 66 / 128\n",
      "    Batch 67 / 128\n",
      "    Batch 68 / 128\n",
      "    Batch 69 / 128\n",
      "    Batch 70 / 128\n",
      "    Batch 71 / 128\n",
      "    Batch 72 / 128\n",
      "    Batch 73 / 128\n",
      "    Batch 74 / 128\n",
      "    Batch 75 / 128\n",
      "    Batch 76 / 128\n",
      "    Batch 77 / 128\n",
      "    Batch 78 / 128\n",
      "    Batch 79 / 128\n",
      "    Batch 80 / 128\n",
      "    Batch 81 / 128\n",
      "    Batch 82 / 128\n",
      "    Batch 83 / 128\n",
      "    Batch 84 / 128\n",
      "    Batch 85 / 128\n",
      "    Batch 86 / 128\n",
      "    Batch 87 / 128\n",
      "    Batch 88 / 128\n",
      "    Batch 89 / 128\n",
      "    Batch 90 / 128\n",
      "    Batch 91 / 128\n",
      "    Batch 92 / 128\n",
      "    Batch 93 / 128\n",
      "    Batch 94 / 128\n",
      "    Batch 95 / 128\n",
      "    Batch 96 / 128\n",
      "    Batch 97 / 128\n",
      "    Batch 98 / 128\n",
      "    Batch 99 / 128\n",
      "    Batch 100 / 128\n",
      "    Batch 101 / 128\n",
      "    Batch 102 / 128\n",
      "    Batch 103 / 128\n",
      "    Batch 104 / 128\n",
      "    Batch 105 / 128\n",
      "    Batch 106 / 128\n",
      "    Batch 107 / 128\n",
      "    Batch 108 / 128\n",
      "    Batch 109 / 128\n",
      "    Batch 110 / 128\n",
      "    Batch 111 / 128\n",
      "    Batch 112 / 128\n",
      "    Batch 113 / 128\n",
      "    Batch 114 / 128\n",
      "    Batch 115 / 128\n",
      "    Batch 116 / 128\n",
      "    Batch 117 / 128\n",
      "    Batch 118 / 128\n",
      "    Batch 119 / 128\n",
      "    Batch 120 / 128\n",
      "    Batch 121 / 128\n",
      "    Batch 122 / 128\n",
      "    Batch 123 / 128\n",
      "    Batch 124 / 128\n",
      "    Batch 125 / 128\n",
      "    Batch 126 / 128\n",
      "    Batch 127 / 128\n",
      "    Batch 128 / 128\n",
      "ROC-AUC score: 0.4739\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 5\n",
      "    Batch 3 / 128: loss 0.6931\n",
      "    ROC-AUC score: 0.6157\n",
      "    Batch 6 / 128: loss 0.6927\n",
      "    ROC-AUC score: 0.6953\n",
      "    Batch 9 / 128: loss 0.6925\n",
      "    ROC-AUC score: 0.5843\n",
      "    Batch 12 / 128: loss 0.6923\n",
      "    ROC-AUC score: 0.7020\n",
      "    Batch 15 / 128: loss 0.6915\n",
      "    ROC-AUC score: 0.6588\n",
      "    Batch 18 / 128: loss 0.6921\n",
      "    ROC-AUC score: 0.5794\n",
      "    Batch 21 / 128: loss 0.6909\n",
      "    ROC-AUC score: 0.7103\n",
      "    Batch 24 / 128: loss 0.6911\n",
      "    ROC-AUC score: 0.6627\n",
      "    Batch 27 / 128: loss 0.6863\n",
      "    ROC-AUC score: 0.9023\n",
      "    Batch 30 / 128: loss 0.6877\n",
      "    ROC-AUC score: 0.7611\n",
      "    Batch 33 / 128: loss 0.6861\n",
      "    ROC-AUC score: 0.8268\n",
      "    Batch 36 / 128: loss 0.6852\n",
      "    ROC-AUC score: 0.6548\n",
      "    Batch 39 / 128: loss 0.6828\n",
      "    ROC-AUC score: 0.6194\n",
      "    Batch 42 / 128: loss 0.6794\n",
      "    ROC-AUC score: 0.6190\n",
      "    Batch 45 / 128: loss 0.6788\n",
      "    ROC-AUC score: 0.8375\n",
      "    Batch 48 / 128: loss 0.6750\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 51 / 128: loss 0.6735\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 54 / 128: loss 0.6740\n",
      "    ROC-AUC score: 0.8958\n",
      "    Batch 57 / 128: loss 0.6690\n",
      "    ROC-AUC score: 0.8135\n",
      "    Batch 60 / 128: loss 0.6691\n",
      "    ROC-AUC score: 0.8458\n",
      "    Batch 63 / 128: loss 0.6604\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 66 / 128: loss 0.6680\n",
      "    ROC-AUC score: 0.7682\n",
      "    Batch 69 / 128: loss 0.6613\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 72 / 128: loss 0.6387\n",
      "    ROC-AUC score: 0.9567\n",
      "    Batch 75 / 128: loss 0.6578\n",
      "    ROC-AUC score: 0.8353\n",
      "    Batch 78 / 128: loss 0.6567\n",
      "    ROC-AUC score: 0.6833\n",
      "    Batch 81 / 128: loss 0.6512\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 84 / 128: loss 0.6425\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 87 / 128: loss 0.6422\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 90 / 128: loss 0.6208\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 93 / 128: loss 0.6355\n",
      "    ROC-AUC score: 0.9773\n",
      "    Batch 96 / 128: loss 0.6404\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 99 / 128: loss 0.6315\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 102 / 128: loss 0.6227\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 105 / 128: loss 0.6222\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 108 / 128: loss 0.6119\n",
      "    ROC-AUC score: 0.9792\n",
      "    Batch 111 / 128: loss 0.6175\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 114 / 128: loss 0.6041\n",
      "    ROC-AUC score: 0.9393\n",
      "    Batch 117 / 128: loss 0.6022\n",
      "    ROC-AUC score: 0.9750\n",
      "    Batch 120 / 128: loss 0.5830\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 123 / 128: loss 0.5909\n",
      "    ROC-AUC score: 0.9437\n",
      "    Batch 126 / 128: loss 0.5926\n",
      "    ROC-AUC score: 0.9514\n",
      "Epoch 2 / 5\n",
      "    Batch 3 / 128: loss 0.5880\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 6 / 128: loss 0.5904\n",
      "    ROC-AUC score: 0.9417\n",
      "    Batch 9 / 128: loss 0.5519\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 12 / 128: loss 0.5725\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 15 / 128: loss 0.5888\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 128: loss 0.5410\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 21 / 128: loss 0.5697\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 24 / 128: loss 0.5354\n",
      "    ROC-AUC score: 0.9727\n",
      "    Batch 27 / 128: loss 0.5562\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 30 / 128: loss 0.5198\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 128: loss 0.5053\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 36 / 128: loss 0.5064\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 39 / 128: loss 0.5337\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 42 / 128: loss 0.5056\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 45 / 128: loss 0.5030\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 48 / 128: loss 0.5473\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 51 / 128: loss 0.5326\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 128: loss 0.4850\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 57 / 128: loss 0.4776\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 60 / 128: loss 0.4901\n",
      "    ROC-AUC score: 0.8833\n",
      "    Batch 63 / 128: loss 0.5271\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 66 / 128: loss 0.4985\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 69 / 128: loss 0.4771\n",
      "    ROC-AUC score: 0.8704\n",
      "    Batch 72 / 128: loss 0.4553\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 128: loss 0.4740\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 78 / 128: loss 0.4448\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 81 / 128: loss 0.4864\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 84 / 128: loss 0.4535\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 87 / 128: loss 0.5233\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 90 / 128: loss 0.4779\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 93 / 128: loss 0.4683\n",
      "    ROC-AUC score: 0.9182\n",
      "    Batch 96 / 128: loss 0.4403\n",
      "    ROC-AUC score: 0.9843\n",
      "    Batch 99 / 128: loss 0.3920\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 102 / 128: loss 0.4390\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 105 / 128: loss 0.4823\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 108 / 128: loss 0.4535\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 111 / 128: loss 0.4838\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 114 / 128: loss 0.4729\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 117 / 128: loss 0.4591\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 120 / 128: loss 0.4861\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 123 / 128: loss 0.4680\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 126 / 128: loss 0.4958\n",
      "    ROC-AUC score: 0.9883\n",
      "Epoch 3 / 5\n",
      "    Batch 3 / 128: loss 0.4047\n",
      "    ROC-AUC score: 0.9838\n",
      "    Batch 6 / 128: loss 0.4162\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 128: loss 0.4462\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 128: loss 0.4240\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 15 / 128: loss 0.4213\n",
      "    ROC-AUC score: 0.9844\n",
      "    Batch 18 / 128: loss 0.4456\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 128: loss 0.4434\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 24 / 128: loss 0.4655\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 27 / 128: loss 0.4242\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 30 / 128: loss 0.4377\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 128: loss 0.4530\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 36 / 128: loss 0.3651\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 39 / 128: loss 0.4188\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 42 / 128: loss 0.4197\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 45 / 128: loss 0.5156\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 48 / 128: loss 0.4089\n",
      "    ROC-AUC score: 0.9717\n",
      "    Batch 51 / 128: loss 0.4656\n",
      "    ROC-AUC score: 0.8802\n",
      "    Batch 54 / 128: loss 0.4469\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 57 / 128: loss 0.3930\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 60 / 128: loss 0.4392\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 63 / 128: loss 0.4078\n",
      "    ROC-AUC score: 0.9921\n",
      "    Batch 66 / 128: loss 0.4122\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 69 / 128: loss 0.4429\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 72 / 128: loss 0.4023\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 128: loss 0.3833\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 78 / 128: loss 0.3860\n",
      "    ROC-AUC score: 0.9798\n",
      "    Batch 81 / 128: loss 0.3823\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 84 / 128: loss 0.4544\n",
      "    ROC-AUC score: 0.9805\n",
      "    Batch 87 / 128: loss 0.3949\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 90 / 128: loss 0.4041\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 93 / 128: loss 0.4520\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 96 / 128: loss 0.4349\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 99 / 128: loss 0.3686\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 102 / 128: loss 0.4328\n",
      "    ROC-AUC score: 0.9740\n",
      "    Batch 105 / 128: loss 0.4225\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 108 / 128: loss 0.4111\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 111 / 128: loss 0.3986\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 114 / 128: loss 0.4097\n",
      "    ROC-AUC score: 0.9919\n",
      "    Batch 117 / 128: loss 0.3776\n",
      "    ROC-AUC score: 0.9882\n",
      "    Batch 120 / 128: loss 0.3701\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 123 / 128: loss 0.4242\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 126 / 128: loss 0.3885\n",
      "    ROC-AUC score: 1.0000\n",
      "Epoch 4 / 5\n",
      "    Batch 3 / 128: loss 0.3693\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 6 / 128: loss 0.3411\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 128: loss 0.4327\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 12 / 128: loss 0.3271\n",
      "    ROC-AUC score: 0.9957\n",
      "    Batch 15 / 128: loss 0.4216\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 128: loss 0.4006\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 21 / 128: loss 0.3563\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 24 / 128: loss 0.3278\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 128: loss 0.4769\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 30 / 128: loss 0.3505\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 33 / 128: loss 0.4269\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 36 / 128: loss 0.4440\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 39 / 128: loss 0.3660\n",
      "    ROC-AUC score: 0.9567\n",
      "    Batch 42 / 128: loss 0.5077\n",
      "    ROC-AUC score: 0.9843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 45 / 128: loss 0.5219\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 48 / 128: loss 0.3757\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 51 / 128: loss 0.3741\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 128: loss 0.3623\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 57 / 128: loss 0.3531\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 60 / 128: loss 0.3732\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 63 / 128: loss 0.4087\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 66 / 128: loss 0.3910\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 69 / 128: loss 0.3719\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 72 / 128: loss 0.3186\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 128: loss 0.4112\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 78 / 128: loss 0.3843\n",
      "    ROC-AUC score: 0.9569\n",
      "    Batch 81 / 128: loss 0.4016\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 84 / 128: loss 0.4176\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 87 / 128: loss 0.4040\n",
      "    ROC-AUC score: 0.9667\n",
      "    Batch 90 / 128: loss 0.3865\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 93 / 128: loss 0.4492\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 128: loss 0.4094\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 99 / 128: loss 0.3077\n",
      "    ROC-AUC score: 0.9917\n",
      "    Batch 102 / 128: loss 0.3393\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 105 / 128: loss 0.3819\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 108 / 128: loss 0.3520\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 111 / 128: loss 0.3556\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 114 / 128: loss 0.3665\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 117 / 128: loss 0.3770\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 120 / 128: loss 0.3848\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 123 / 128: loss 0.4401\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 126 / 128: loss 0.4161\n",
      "    ROC-AUC score: 1.0000\n",
      "Epoch 5 / 5\n",
      "    Batch 3 / 128: loss 0.3543\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 6 / 128: loss 0.3680\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 9 / 128: loss 0.3980\n",
      "    ROC-AUC score: 0.9273\n",
      "    Batch 12 / 128: loss 0.4514\n",
      "    ROC-AUC score: 0.9766\n",
      "    Batch 15 / 128: loss 0.4031\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 18 / 128: loss 0.4098\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 21 / 128: loss 0.3731\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 24 / 128: loss 0.3520\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 27 / 128: loss 0.3451\n",
      "    ROC-AUC score: 0.9875\n",
      "    Batch 30 / 128: loss 0.3594\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 33 / 128: loss 0.3621\n",
      "    ROC-AUC score: 0.9654\n",
      "    Batch 36 / 128: loss 0.3691\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 39 / 128: loss 0.4634\n",
      "    ROC-AUC score: 0.9804\n",
      "    Batch 42 / 128: loss 0.3801\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 45 / 128: loss 0.3950\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 48 / 128: loss 0.4332\n",
      "    ROC-AUC score: 0.9958\n",
      "    Batch 51 / 128: loss 0.3318\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 54 / 128: loss 0.3430\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 57 / 128: loss 0.4198\n",
      "    ROC-AUC score: 0.9833\n",
      "    Batch 60 / 128: loss 0.3155\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 63 / 128: loss 0.3622\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 66 / 128: loss 0.4259\n",
      "    ROC-AUC score: 0.9952\n",
      "    Batch 69 / 128: loss 0.3165\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 72 / 128: loss 0.3924\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 75 / 128: loss 0.3190\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 78 / 128: loss 0.3391\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 81 / 128: loss 0.3600\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 84 / 128: loss 0.3982\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 87 / 128: loss 0.3702\n",
      "    ROC-AUC score: 0.9373\n",
      "    Batch 90 / 128: loss 0.3824\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 93 / 128: loss 0.3378\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 96 / 128: loss 0.3983\n",
      "    ROC-AUC score: 0.9412\n",
      "    Batch 99 / 128: loss 0.3227\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 102 / 128: loss 0.4108\n",
      "    ROC-AUC score: 0.9833\n",
      "    Batch 105 / 128: loss 0.3563\n",
      "    ROC-AUC score: 0.9922\n",
      "    Batch 108 / 128: loss 0.3966\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 111 / 128: loss 0.3532\n",
      "    ROC-AUC score: 0.9802\n",
      "    Batch 114 / 128: loss 0.3700\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 117 / 128: loss 0.3978\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 120 / 128: loss 0.3701\n",
      "    ROC-AUC score: 1.0000\n",
      "    Batch 123 / 128: loss 0.4602\n",
      "    ROC-AUC score: 0.9961\n",
      "    Batch 126 / 128: loss 0.3578\n",
      "    ROC-AUC score: 1.0000\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 400], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 128\n",
      "    Batch 2 / 128\n",
      "    Batch 3 / 128\n",
      "    Batch 4 / 128\n",
      "    Batch 5 / 128\n",
      "    Batch 6 / 128\n",
      "    Batch 7 / 128\n",
      "    Batch 8 / 128\n",
      "    Batch 9 / 128\n",
      "    Batch 10 / 128\n",
      "    Batch 11 / 128\n",
      "    Batch 12 / 128\n",
      "    Batch 13 / 128\n",
      "    Batch 14 / 128\n",
      "    Batch 15 / 128\n",
      "    Batch 16 / 128\n",
      "    Batch 17 / 128\n",
      "    Batch 18 / 128\n",
      "    Batch 19 / 128\n",
      "    Batch 20 / 128\n",
      "    Batch 21 / 128\n",
      "    Batch 22 / 128\n",
      "    Batch 23 / 128\n",
      "    Batch 24 / 128\n",
      "    Batch 25 / 128\n",
      "    Batch 26 / 128\n",
      "    Batch 27 / 128\n",
      "    Batch 28 / 128\n",
      "    Batch 29 / 128\n",
      "    Batch 30 / 128\n",
      "    Batch 31 / 128\n",
      "    Batch 32 / 128\n",
      "    Batch 33 / 128\n",
      "    Batch 34 / 128\n",
      "    Batch 35 / 128\n",
      "    Batch 36 / 128\n",
      "    Batch 37 / 128\n",
      "    Batch 38 / 128\n",
      "    Batch 39 / 128\n",
      "    Batch 40 / 128\n",
      "    Batch 41 / 128\n",
      "    Batch 42 / 128\n",
      "    Batch 43 / 128\n",
      "    Batch 44 / 128\n",
      "    Batch 45 / 128\n",
      "    Batch 46 / 128\n",
      "    Batch 47 / 128\n",
      "    Batch 48 / 128\n",
      "    Batch 49 / 128\n",
      "    Batch 50 / 128\n",
      "    Batch 51 / 128\n",
      "    Batch 52 / 128\n",
      "    Batch 53 / 128\n",
      "    Batch 54 / 128\n",
      "    Batch 55 / 128\n",
      "    Batch 56 / 128\n",
      "    Batch 57 / 128\n",
      "    Batch 58 / 128\n",
      "    Batch 59 / 128\n",
      "    Batch 60 / 128\n",
      "    Batch 61 / 128\n",
      "    Batch 62 / 128\n",
      "    Batch 63 / 128\n",
      "    Batch 64 / 128\n",
      "    Batch 65 / 128\n",
      "    Batch 66 / 128\n",
      "    Batch 67 / 128\n",
      "    Batch 68 / 128\n",
      "    Batch 69 / 128\n",
      "    Batch 70 / 128\n",
      "    Batch 71 / 128\n",
      "    Batch 72 / 128\n",
      "    Batch 73 / 128\n",
      "    Batch 74 / 128\n",
      "    Batch 75 / 128\n",
      "    Batch 76 / 128\n",
      "    Batch 77 / 128\n",
      "    Batch 78 / 128\n",
      "    Batch 79 / 128\n",
      "    Batch 80 / 128\n",
      "    Batch 81 / 128\n",
      "    Batch 82 / 128\n",
      "    Batch 83 / 128\n",
      "    Batch 84 / 128\n",
      "    Batch 85 / 128\n",
      "    Batch 86 / 128\n",
      "    Batch 87 / 128\n",
      "    Batch 88 / 128\n",
      "    Batch 89 / 128\n",
      "    Batch 90 / 128\n",
      "    Batch 91 / 128\n",
      "    Batch 92 / 128\n",
      "    Batch 93 / 128\n",
      "    Batch 94 / 128\n",
      "    Batch 95 / 128\n",
      "    Batch 96 / 128\n",
      "    Batch 97 / 128\n",
      "    Batch 98 / 128\n",
      "    Batch 99 / 128\n",
      "    Batch 100 / 128\n",
      "    Batch 101 / 128\n",
      "    Batch 102 / 128\n",
      "    Batch 103 / 128\n",
      "    Batch 104 / 128\n",
      "    Batch 105 / 128\n",
      "    Batch 106 / 128\n",
      "    Batch 107 / 128\n",
      "    Batch 108 / 128\n",
      "    Batch 109 / 128\n",
      "    Batch 110 / 128\n",
      "    Batch 111 / 128\n",
      "    Batch 112 / 128\n",
      "    Batch 113 / 128\n",
      "    Batch 114 / 128\n",
      "    Batch 115 / 128\n",
      "    Batch 116 / 128\n",
      "    Batch 117 / 128\n",
      "    Batch 118 / 128\n",
      "    Batch 119 / 128\n",
      "    Batch 120 / 128\n",
      "    Batch 121 / 128\n",
      "    Batch 122 / 128\n",
      "    Batch 123 / 128\n",
      "    Batch 124 / 128\n",
      "    Batch 125 / 128\n",
      "    Batch 126 / 128\n",
      "    Batch 127 / 128\n",
      "    Batch 128 / 128\n",
      "ROC-AUC score: 0.9875\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 128\n",
      "    Batch 2 / 128\n",
      "    Batch 3 / 128\n",
      "    Batch 4 / 128\n",
      "    Batch 5 / 128\n",
      "    Batch 6 / 128\n",
      "    Batch 7 / 128\n",
      "    Batch 8 / 128\n",
      "    Batch 9 / 128\n",
      "    Batch 10 / 128\n",
      "    Batch 11 / 128\n",
      "    Batch 12 / 128\n",
      "    Batch 13 / 128\n",
      "    Batch 14 / 128\n",
      "    Batch 15 / 128\n",
      "    Batch 16 / 128\n",
      "    Batch 17 / 128\n",
      "    Batch 18 / 128\n",
      "    Batch 19 / 128\n",
      "    Batch 20 / 128\n",
      "    Batch 21 / 128\n",
      "    Batch 22 / 128\n",
      "    Batch 23 / 128\n",
      "    Batch 24 / 128\n",
      "    Batch 25 / 128\n",
      "    Batch 26 / 128\n",
      "    Batch 27 / 128\n",
      "    Batch 28 / 128\n",
      "    Batch 29 / 128\n",
      "    Batch 30 / 128\n",
      "    Batch 31 / 128\n",
      "    Batch 32 / 128\n",
      "    Batch 33 / 128\n",
      "    Batch 34 / 128\n",
      "    Batch 35 / 128\n",
      "    Batch 36 / 128\n",
      "    Batch 37 / 128\n",
      "    Batch 38 / 128\n",
      "    Batch 39 / 128\n",
      "    Batch 40 / 128\n",
      "    Batch 41 / 128\n",
      "    Batch 42 / 128\n",
      "    Batch 43 / 128\n",
      "    Batch 44 / 128\n",
      "    Batch 45 / 128\n",
      "    Batch 46 / 128\n",
      "    Batch 47 / 128\n",
      "    Batch 48 / 128\n",
      "    Batch 49 / 128\n",
      "    Batch 50 / 128\n",
      "    Batch 51 / 128\n",
      "    Batch 52 / 128\n",
      "    Batch 53 / 128\n",
      "    Batch 54 / 128\n",
      "    Batch 55 / 128\n",
      "    Batch 56 / 128\n",
      "    Batch 57 / 128\n",
      "    Batch 58 / 128\n",
      "    Batch 59 / 128\n",
      "    Batch 60 / 128\n",
      "    Batch 61 / 128\n",
      "    Batch 62 / 128\n",
      "    Batch 63 / 128\n",
      "    Batch 64 / 128\n",
      "    Batch 65 / 128\n",
      "    Batch 66 / 128\n",
      "    Batch 67 / 128\n",
      "    Batch 68 / 128\n",
      "    Batch 69 / 128\n",
      "    Batch 70 / 128\n",
      "    Batch 71 / 128\n",
      "    Batch 72 / 128\n",
      "    Batch 73 / 128\n",
      "    Batch 74 / 128\n",
      "    Batch 75 / 128\n",
      "    Batch 76 / 128\n",
      "    Batch 77 / 128\n",
      "    Batch 78 / 128\n",
      "    Batch 79 / 128\n",
      "    Batch 80 / 128\n",
      "    Batch 81 / 128\n",
      "    Batch 82 / 128\n",
      "    Batch 83 / 128\n",
      "    Batch 84 / 128\n",
      "    Batch 85 / 128\n",
      "    Batch 86 / 128\n",
      "    Batch 87 / 128\n",
      "    Batch 88 / 128\n",
      "    Batch 89 / 128\n",
      "    Batch 90 / 128\n",
      "    Batch 91 / 128\n",
      "    Batch 92 / 128\n",
      "    Batch 93 / 128\n",
      "    Batch 94 / 128\n",
      "    Batch 95 / 128\n",
      "    Batch 96 / 128\n",
      "    Batch 97 / 128\n",
      "    Batch 98 / 128\n",
      "    Batch 99 / 128\n",
      "    Batch 100 / 128\n",
      "    Batch 101 / 128\n",
      "    Batch 102 / 128\n",
      "    Batch 103 / 128\n",
      "    Batch 104 / 128\n",
      "    Batch 105 / 128\n",
      "    Batch 106 / 128\n",
      "    Batch 107 / 128\n",
      "    Batch 108 / 128\n",
      "    Batch 109 / 128\n",
      "    Batch 110 / 128\n",
      "    Batch 111 / 128\n",
      "    Batch 112 / 128\n",
      "    Batch 113 / 128\n",
      "    Batch 114 / 128\n",
      "    Batch 115 / 128\n",
      "    Batch 116 / 128\n",
      "    Batch 117 / 128\n",
      "    Batch 118 / 128\n",
      "    Batch 119 / 128\n",
      "    Batch 120 / 128\n",
      "    Batch 121 / 128\n",
      "    Batch 122 / 128\n",
      "    Batch 123 / 128\n",
      "    Batch 124 / 128\n",
      "    Batch 125 / 128\n",
      "    Batch 126 / 128\n",
      "    Batch 127 / 128\n",
      "    Batch 128 / 128\n",
      "Threshold: 1.0154, accuracy: 0.9631\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.96      2033\n",
      "         1.0       0.96      0.96      0.96      2033\n",
      "\n",
      "    accuracy                           0.96      4066\n",
      "   macro avg       0.96      0.96      0.96      4066\n",
      "weighted avg       0.96      0.96      0.96      4066\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: val\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2112\n",
      "Number of temporal edges: 14122\n",
      "Number of examples/datapoints: 4092\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the validation dataset after training.\n",
      "    Batch 3 / 128: loss 0.5280, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 6 / 128: loss 0.5803, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 9 / 128: loss 0.4164, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 12 / 128: loss 0.4157, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9636\n",
      "    Batch 15 / 128: loss 0.4418, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 18 / 128: loss 0.4187, accuracy 0.9479\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 21 / 128: loss 0.5153, accuracy 0.8438\n",
      "    ROC-AUC score: 0.6508\n",
      "    Batch 24 / 128: loss 0.6067, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8219\n",
      "    Batch 27 / 128: loss 0.4413, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 30 / 128: loss 0.4700, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 33 / 128: loss 0.4823, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 36 / 128: loss 0.4443, accuracy 0.9271\n",
      "    ROC-AUC score: 0.9091\n",
      "    Batch 39 / 128: loss 0.4851, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 42 / 128: loss 0.4897, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 45 / 128: loss 0.4825, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 48 / 128: loss 0.3787, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9960\n",
      "    Batch 51 / 128: loss 0.4096, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 54 / 128: loss 0.4130, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 57 / 128: loss 0.3856, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 60 / 128: loss 0.3967, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 63 / 128: loss 0.4213, accuracy 0.9375\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 66 / 128: loss 0.5393, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8664\n",
      "    Batch 69 / 128: loss 0.4843, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8583\n",
      "    Batch 72 / 128: loss 0.4212, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9654\n",
      "    Batch 75 / 128: loss 0.5095, accuracy 0.8854\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 78 / 128: loss 0.5512, accuracy 0.8854\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 81 / 128: loss 0.5209, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 84 / 128: loss 0.4645, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 87 / 128: loss 0.4801, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8353\n",
      "    Batch 90 / 128: loss 0.4585, accuracy 0.8750\n",
      "    ROC-AUC score: 0.8929\n",
      "    Batch 93 / 128: loss 0.4867, accuracy 0.8958\n",
      "    ROC-AUC score: 0.8542\n",
      "    Batch 96 / 128: loss 0.4297, accuracy 0.9062\n",
      "    ROC-AUC score: 0.9841\n",
      "    Batch 99 / 128: loss 0.5152, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 102 / 128: loss 0.5111, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 105 / 128: loss 0.4547, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9757\n",
      "    Batch 108 / 128: loss 0.5825, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 111 / 128: loss 0.5673, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 114 / 128: loss 0.4895, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8292\n",
      "    Batch 117 / 128: loss 0.4955, accuracy 0.8854\n",
      "    ROC-AUC score: 0.7792\n",
      "    Batch 120 / 128: loss 0.5856, accuracy 0.8438\n",
      "    ROC-AUC score: 0.7529\n",
      "    Batch 123 / 128: loss 0.4476, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 126 / 128: loss 0.5101, accuracy 0.9167\n",
      "    ROC-AUC score: 0.9688\n",
      "Loss 0.4806, accuracy 0.8930\n",
      "ROC-AUC score: 0.8810\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.93      0.90      2046\n",
      "         1.0       0.93      0.85      0.89      2046\n",
      "\n",
      "    accuracy                           0.89      4092\n",
      "   macro avg       0.90      0.89      0.89      4092\n",
      "weighted avg       0.90      0.89      0.89      4092\n",
      "\n",
      "Finished validating.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'val',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the validation dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished validating.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contact/ia-contact.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 274\n",
      "Number of static edges: 2472\n",
      "Number of temporal edges: 21183\n",
      "Number of examples/datapoints: 4106\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 129: loss 0.6200, accuracy 0.8229\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 6 / 129: loss 0.5635, accuracy 0.8021\n",
      "    ROC-AUC score: 0.6587\n",
      "    Batch 9 / 129: loss 0.5801, accuracy 0.7812\n",
      "    ROC-AUC score: 0.6353\n",
      "    Batch 12 / 129: loss 0.5559, accuracy 0.8646\n",
      "    ROC-AUC score: 0.9682\n",
      "    Batch 15 / 129: loss 0.5860, accuracy 0.8125\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 18 / 129: loss 0.6457, accuracy 0.7812\n",
      "    ROC-AUC score: 0.7421\n",
      "    Batch 21 / 129: loss 0.5867, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 24 / 129: loss 0.5562, accuracy 0.8333\n",
      "    ROC-AUC score: 0.7804\n",
      "    Batch 27 / 129: loss 0.5862, accuracy 0.8542\n",
      "    ROC-AUC score: 0.7897\n",
      "    Batch 30 / 129: loss 0.6381, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8516\n",
      "    Batch 33 / 129: loss 0.6794, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 36 / 129: loss 0.5648, accuracy 0.8333\n",
      "    ROC-AUC score: 0.7765\n",
      "    Batch 39 / 129: loss 0.5673, accuracy 0.8229\n",
      "    ROC-AUC score: 0.7778\n",
      "    Batch 42 / 129: loss 0.6589, accuracy 0.8021\n",
      "    ROC-AUC score: 0.6157\n",
      "    Batch 45 / 129: loss 0.5537, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8281\n",
      "    Batch 48 / 129: loss 0.5341, accuracy 0.8229\n",
      "    ROC-AUC score: 0.6333\n",
      "    Batch 51 / 129: loss 0.6418, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 54 / 129: loss 0.5777, accuracy 0.7917\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 57 / 129: loss 0.5185, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 60 / 129: loss 0.5365, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8409\n",
      "    Batch 63 / 129: loss 0.6023, accuracy 0.8229\n",
      "    ROC-AUC score: 0.7056\n",
      "    Batch 66 / 129: loss 0.5547, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 69 / 129: loss 0.4698, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9297\n",
      "    Batch 72 / 129: loss 0.5835, accuracy 0.7812\n",
      "    ROC-AUC score: 0.7529\n",
      "    Batch 75 / 129: loss 0.6145, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8477\n",
      "    Batch 78 / 129: loss 0.5947, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 81 / 129: loss 0.5514, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 84 / 129: loss 0.5215, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8392\n",
      "    Batch 87 / 129: loss 0.4685, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8214\n",
      "    Batch 90 / 129: loss 0.5675, accuracy 0.8021\n",
      "    ROC-AUC score: 0.7804\n",
      "    Batch 93 / 129: loss 0.5335, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8261\n",
      "    Batch 96 / 129: loss 0.5175, accuracy 0.8438\n",
      "    ROC-AUC score: 0.7765\n",
      "    Batch 99 / 129: loss 0.4957, accuracy 0.8125\n",
      "    ROC-AUC score: 0.7571\n",
      "    Batch 102 / 129: loss 0.6140, accuracy 0.7396\n",
      "    ROC-AUC score: 0.6078\n",
      "    Batch 105 / 129: loss 0.5860, accuracy 0.7604\n",
      "    ROC-AUC score: 0.6392\n",
      "    Batch 108 / 129: loss 0.6440, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 111 / 129: loss 0.5648, accuracy 0.7917\n",
      "    ROC-AUC score: 0.7216\n",
      "    Batch 114 / 129: loss 0.5439, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9433\n",
      "    Batch 117 / 129: loss 0.6103, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8627\n",
      "    Batch 120 / 129: loss 0.5446, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8056\n",
      "    Batch 123 / 129: loss 0.5445, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9150\n",
      "    Batch 126 / 129: loss 0.5760, accuracy 0.7917\n",
      "    ROC-AUC score: 0.7734\n",
      "    Batch 129 / 129: loss 0.5925, accuracy 0.7568\n",
      "    ROC-AUC score: 0.5714\n",
      "Loss 0.5732, accuracy 0.8122\n",
      "ROC-AUC score: 0.7897\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.90      0.83      2053\n",
      "         1.0       0.88      0.72      0.79      2053\n",
      "\n",
      "    accuracy                           0.81      4106\n",
      "   macro avg       0.82      0.81      0.81      4106\n",
      "weighted avg       0.82      0.81      0.81      4106\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
