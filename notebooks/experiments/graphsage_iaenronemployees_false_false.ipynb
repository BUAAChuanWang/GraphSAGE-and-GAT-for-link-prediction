{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAEnronEmployees\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : False,\n",
    "    \"repeat_examples\" : False,\n",
    "    \n",
    "    \"self_loop\" : False,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0.5,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 3,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 151\n",
      "Number of static edges: 759\n",
      "Number of temporal edges: 15171\n",
      "Number of examples/datapoints: 2054\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()\n",
    "config['input_dim'], config['output_dim'] = input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=151, out_features=151, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=302, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.get_model(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 65\n",
      "    Batch 2 / 65\n",
      "    Batch 3 / 65\n",
      "    Batch 4 / 65\n",
      "    Batch 5 / 65\n",
      "    Batch 6 / 65\n",
      "    Batch 7 / 65\n",
      "    Batch 8 / 65\n",
      "    Batch 9 / 65\n",
      "    Batch 10 / 65\n",
      "    Batch 11 / 65\n",
      "    Batch 12 / 65\n",
      "    Batch 13 / 65\n",
      "    Batch 14 / 65\n",
      "    Batch 15 / 65\n",
      "    Batch 16 / 65\n",
      "    Batch 17 / 65\n",
      "    Batch 18 / 65\n",
      "    Batch 19 / 65\n",
      "    Batch 20 / 65\n",
      "    Batch 21 / 65\n",
      "    Batch 22 / 65\n",
      "    Batch 23 / 65\n",
      "    Batch 24 / 65\n",
      "    Batch 25 / 65\n",
      "    Batch 26 / 65\n",
      "    Batch 27 / 65\n",
      "    Batch 28 / 65\n",
      "    Batch 29 / 65\n",
      "    Batch 30 / 65\n",
      "    Batch 31 / 65\n",
      "    Batch 32 / 65\n",
      "    Batch 33 / 65\n",
      "    Batch 34 / 65\n",
      "    Batch 35 / 65\n",
      "    Batch 36 / 65\n",
      "    Batch 37 / 65\n",
      "    Batch 38 / 65\n",
      "    Batch 39 / 65\n",
      "    Batch 40 / 65\n",
      "    Batch 41 / 65\n",
      "    Batch 42 / 65\n",
      "    Batch 43 / 65\n",
      "    Batch 44 / 65\n",
      "    Batch 45 / 65\n",
      "    Batch 46 / 65\n",
      "    Batch 47 / 65\n",
      "    Batch 48 / 65\n",
      "    Batch 49 / 65\n",
      "    Batch 50 / 65\n",
      "    Batch 51 / 65\n",
      "    Batch 52 / 65\n",
      "    Batch 53 / 65\n",
      "    Batch 54 / 65\n",
      "    Batch 55 / 65\n",
      "    Batch 56 / 65\n",
      "    Batch 57 / 65\n",
      "    Batch 58 / 65\n",
      "    Batch 59 / 65\n",
      "    Batch 60 / 65\n",
      "    Batch 61 / 65\n",
      "    Batch 62 / 65\n",
      "    Batch 63 / 65\n",
      "    Batch 64 / 65\n",
      "    Batch 65 / 65\n",
      "ROC-AUC score: 0.5016\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 3\n",
      "    Batch 3 / 65: loss 0.6938\n",
      "    ROC-AUC score: 0.5101\n",
      "    Batch 6 / 65: loss 0.6930\n",
      "    ROC-AUC score: 0.3333\n",
      "    Batch 9 / 65: loss 0.6926\n",
      "    ROC-AUC score: 0.4250\n",
      "    Batch 12 / 65: loss 0.6936\n",
      "    ROC-AUC score: 0.5455\n",
      "    Batch 15 / 65: loss 0.6939\n",
      "    ROC-AUC score: 0.5362\n",
      "    Batch 18 / 65: loss 0.6926\n",
      "    ROC-AUC score: 0.6078\n",
      "    Batch 21 / 65: loss 0.6936\n",
      "    ROC-AUC score: 0.5078\n",
      "    Batch 24 / 65: loss 0.6935\n",
      "    ROC-AUC score: 0.5451\n",
      "    Batch 27 / 65: loss 0.6924\n",
      "    ROC-AUC score: 0.6133\n",
      "    Batch 30 / 65: loss 0.6928\n",
      "    ROC-AUC score: 0.5385\n",
      "    Batch 33 / 65: loss 0.6922\n",
      "    ROC-AUC score: 0.5913\n",
      "    Batch 36 / 65: loss 0.6928\n",
      "    ROC-AUC score: 0.4683\n",
      "    Batch 39 / 65: loss 0.6928\n",
      "    ROC-AUC score: 0.5466\n",
      "    Batch 42 / 65: loss 0.6926\n",
      "    ROC-AUC score: 0.4444\n",
      "    Batch 45 / 65: loss 0.6933\n",
      "    ROC-AUC score: 0.5091\n",
      "    Batch 48 / 65: loss 0.6929\n",
      "    ROC-AUC score: 0.5625\n",
      "    Batch 51 / 65: loss 0.6918\n",
      "    ROC-AUC score: 0.5451\n",
      "    Batch 54 / 65: loss 0.6932\n",
      "    ROC-AUC score: 0.6623\n",
      "    Batch 57 / 65: loss 0.6922\n",
      "    ROC-AUC score: 0.6151\n",
      "    Batch 60 / 65: loss 0.6929\n",
      "    ROC-AUC score: 0.6314\n",
      "    Batch 63 / 65: loss 0.6931\n",
      "    ROC-AUC score: 0.5961\n",
      "Epoch 2 / 3\n",
      "    Batch 3 / 65: loss 0.6921\n",
      "    ROC-AUC score: 0.4416\n",
      "    Batch 6 / 65: loss 0.6929\n",
      "    ROC-AUC score: 0.5913\n",
      "    Batch 9 / 65: loss 0.6911\n",
      "    ROC-AUC score: 0.8135\n",
      "    Batch 12 / 65: loss 0.6908\n",
      "    ROC-AUC score: 0.7409\n",
      "    Batch 15 / 65: loss 0.6911\n",
      "    ROC-AUC score: 0.7446\n",
      "    Batch 18 / 65: loss 0.6922\n",
      "    ROC-AUC score: 0.7875\n",
      "    Batch 21 / 65: loss 0.6932\n",
      "    ROC-AUC score: 0.4534\n",
      "    Batch 24 / 65: loss 0.6909\n",
      "    ROC-AUC score: 0.8117\n",
      "    Batch 27 / 65: loss 0.6886\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 30 / 65: loss 0.6920\n",
      "    ROC-AUC score: 0.5608\n",
      "    Batch 33 / 65: loss 0.6909\n",
      "    ROC-AUC score: 0.5117\n",
      "    Batch 36 / 65: loss 0.6927\n",
      "    ROC-AUC score: 0.6032\n",
      "    Batch 39 / 65: loss 0.6914\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 42 / 65: loss 0.6910\n",
      "    ROC-AUC score: 0.5250\n",
      "    Batch 45 / 65: loss 0.6951\n",
      "    ROC-AUC score: 0.5425\n",
      "    Batch 48 / 65: loss 0.6878\n",
      "    ROC-AUC score: 0.6753\n",
      "    Batch 51 / 65: loss 0.6922\n",
      "    ROC-AUC score: 0.6353\n",
      "    Batch 54 / 65: loss 0.6916\n",
      "    ROC-AUC score: 0.6902\n",
      "    Batch 57 / 65: loss 0.6951\n",
      "    ROC-AUC score: 0.6955\n",
      "    Batch 60 / 65: loss 0.6920\n",
      "    ROC-AUC score: 0.3318\n",
      "    Batch 63 / 65: loss 0.6904\n",
      "    ROC-AUC score: 0.6944\n",
      "Epoch 3 / 3\n",
      "    Batch 3 / 65: loss 0.6914\n",
      "    ROC-AUC score: 0.7004\n",
      "    Batch 6 / 65: loss 0.6914\n",
      "    ROC-AUC score: 0.6865\n",
      "    Batch 9 / 65: loss 0.6898\n",
      "    ROC-AUC score: 0.6640\n",
      "    Batch 12 / 65: loss 0.6919\n",
      "    ROC-AUC score: 0.6133\n",
      "    Batch 15 / 65: loss 0.6925\n",
      "    ROC-AUC score: 0.7176\n",
      "    Batch 18 / 65: loss 0.6917\n",
      "    ROC-AUC score: 0.6864\n",
      "    Batch 21 / 65: loss 0.6880\n",
      "    ROC-AUC score: 0.8039\n",
      "    Batch 24 / 65: loss 0.6895\n",
      "    ROC-AUC score: 0.7091\n",
      "    Batch 27 / 65: loss 0.6891\n",
      "    ROC-AUC score: 0.7773\n",
      "    Batch 30 / 65: loss 0.6899\n",
      "    ROC-AUC score: 0.6721\n",
      "    Batch 33 / 65: loss 0.6892\n",
      "    ROC-AUC score: 0.7295\n",
      "    Batch 36 / 65: loss 0.6895\n",
      "    ROC-AUC score: 0.4727\n",
      "    Batch 39 / 65: loss 0.6901\n",
      "    ROC-AUC score: 0.6914\n",
      "    Batch 42 / 65: loss 0.6893\n",
      "    ROC-AUC score: 0.7897\n",
      "    Batch 45 / 65: loss 0.6856\n",
      "    ROC-AUC score: 0.8039\n",
      "    Batch 48 / 65: loss 0.6872\n",
      "    ROC-AUC score: 0.7738\n",
      "    Batch 51 / 65: loss 0.6858\n",
      "    ROC-AUC score: 0.7961\n",
      "    Batch 54 / 65: loss 0.6840\n",
      "    ROC-AUC score: 0.6883\n",
      "    Batch 57 / 65: loss 0.6838\n",
      "    ROC-AUC score: 0.7344\n",
      "    Batch 60 / 65: loss 0.6880\n",
      "    ROC-AUC score: 0.6625\n",
      "    Batch 63 / 65: loss 0.6859\n",
      "    ROC-AUC score: 0.7778\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[200, 600, 1000, 1400], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 65\n",
      "    Batch 2 / 65\n",
      "    Batch 3 / 65\n",
      "    Batch 4 / 65\n",
      "    Batch 5 / 65\n",
      "    Batch 6 / 65\n",
      "    Batch 7 / 65\n",
      "    Batch 8 / 65\n",
      "    Batch 9 / 65\n",
      "    Batch 10 / 65\n",
      "    Batch 11 / 65\n",
      "    Batch 12 / 65\n",
      "    Batch 13 / 65\n",
      "    Batch 14 / 65\n",
      "    Batch 15 / 65\n",
      "    Batch 16 / 65\n",
      "    Batch 17 / 65\n",
      "    Batch 18 / 65\n",
      "    Batch 19 / 65\n",
      "    Batch 20 / 65\n",
      "    Batch 21 / 65\n",
      "    Batch 22 / 65\n",
      "    Batch 23 / 65\n",
      "    Batch 24 / 65\n",
      "    Batch 25 / 65\n",
      "    Batch 26 / 65\n",
      "    Batch 27 / 65\n",
      "    Batch 28 / 65\n",
      "    Batch 29 / 65\n",
      "    Batch 30 / 65\n",
      "    Batch 31 / 65\n",
      "    Batch 32 / 65\n",
      "    Batch 33 / 65\n",
      "    Batch 34 / 65\n",
      "    Batch 35 / 65\n",
      "    Batch 36 / 65\n",
      "    Batch 37 / 65\n",
      "    Batch 38 / 65\n",
      "    Batch 39 / 65\n",
      "    Batch 40 / 65\n",
      "    Batch 41 / 65\n",
      "    Batch 42 / 65\n",
      "    Batch 43 / 65\n",
      "    Batch 44 / 65\n",
      "    Batch 45 / 65\n",
      "    Batch 46 / 65\n",
      "    Batch 47 / 65\n",
      "    Batch 48 / 65\n",
      "    Batch 49 / 65\n",
      "    Batch 50 / 65\n",
      "    Batch 51 / 65\n",
      "    Batch 52 / 65\n",
      "    Batch 53 / 65\n",
      "    Batch 54 / 65\n",
      "    Batch 55 / 65\n",
      "    Batch 56 / 65\n",
      "    Batch 57 / 65\n",
      "    Batch 58 / 65\n",
      "    Batch 59 / 65\n",
      "    Batch 60 / 65\n",
      "    Batch 61 / 65\n",
      "    Batch 62 / 65\n",
      "    Batch 63 / 65\n",
      "    Batch 64 / 65\n",
      "    Batch 65 / 65\n",
      "ROC-AUC score: 0.7082\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 65\n",
      "    Batch 2 / 65\n",
      "    Batch 3 / 65\n",
      "    Batch 4 / 65\n",
      "    Batch 5 / 65\n",
      "    Batch 6 / 65\n",
      "    Batch 7 / 65\n",
      "    Batch 8 / 65\n",
      "    Batch 9 / 65\n",
      "    Batch 10 / 65\n",
      "    Batch 11 / 65\n",
      "    Batch 12 / 65\n",
      "    Batch 13 / 65\n",
      "    Batch 14 / 65\n",
      "    Batch 15 / 65\n",
      "    Batch 16 / 65\n",
      "    Batch 17 / 65\n",
      "    Batch 18 / 65\n",
      "    Batch 19 / 65\n",
      "    Batch 20 / 65\n",
      "    Batch 21 / 65\n",
      "    Batch 22 / 65\n",
      "    Batch 23 / 65\n",
      "    Batch 24 / 65\n",
      "    Batch 25 / 65\n",
      "    Batch 26 / 65\n",
      "    Batch 27 / 65\n",
      "    Batch 28 / 65\n",
      "    Batch 29 / 65\n",
      "    Batch 30 / 65\n",
      "    Batch 31 / 65\n",
      "    Batch 32 / 65\n",
      "    Batch 33 / 65\n",
      "    Batch 34 / 65\n",
      "    Batch 35 / 65\n",
      "    Batch 36 / 65\n",
      "    Batch 37 / 65\n",
      "    Batch 38 / 65\n",
      "    Batch 39 / 65\n",
      "    Batch 40 / 65\n",
      "    Batch 41 / 65\n",
      "    Batch 42 / 65\n",
      "    Batch 43 / 65\n",
      "    Batch 44 / 65\n",
      "    Batch 45 / 65\n",
      "    Batch 46 / 65\n",
      "    Batch 47 / 65\n",
      "    Batch 48 / 65\n",
      "    Batch 49 / 65\n",
      "    Batch 50 / 65\n",
      "    Batch 51 / 65\n",
      "    Batch 52 / 65\n",
      "    Batch 53 / 65\n",
      "    Batch 54 / 65\n",
      "    Batch 55 / 65\n",
      "    Batch 56 / 65\n",
      "    Batch 57 / 65\n",
      "    Batch 58 / 65\n",
      "    Batch 59 / 65\n",
      "    Batch 60 / 65\n",
      "    Batch 61 / 65\n",
      "    Batch 62 / 65\n",
      "    Batch 63 / 65\n",
      "    Batch 64 / 65\n",
      "    Batch 65 / 65\n",
      "Threshold: 0.0439, accuracy: 0.6553\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.66      0.66      1027\n",
      "         1.0       0.66      0.65      0.65      1027\n",
      "\n",
      "    accuracy                           0.66      2054\n",
      "   macro avg       0.66      0.66      0.66      2054\n",
      "weighted avg       0.66      0.66      0.66      2054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 151\n",
      "Number of static edges: 1888\n",
      "Number of temporal edges: 37929\n",
      "Number of examples/datapoints: 1660\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 52: loss 0.6948, accuracy 0.5208\n",
      "    ROC-AUC score: 0.4542\n",
      "    Batch 6 / 52: loss 0.6916, accuracy 0.5729\n",
      "    ROC-AUC score: 0.5804\n",
      "    Batch 9 / 52: loss 0.6968, accuracy 0.4896\n",
      "    ROC-AUC score: 0.5749\n",
      "    Batch 12 / 52: loss 0.6898, accuracy 0.5417\n",
      "    ROC-AUC score: 0.6392\n",
      "    Batch 15 / 52: loss 0.6917, accuracy 0.5625\n",
      "    ROC-AUC score: 0.5182\n",
      "    Batch 18 / 52: loss 0.6970, accuracy 0.5208\n",
      "    ROC-AUC score: 0.4719\n",
      "    Batch 21 / 52: loss 0.6861, accuracy 0.6875\n",
      "    ROC-AUC score: 0.7882\n",
      "    Batch 24 / 52: loss 0.6918, accuracy 0.5521\n",
      "    ROC-AUC score: 0.6588\n",
      "    Batch 27 / 52: loss 0.6932, accuracy 0.5312\n",
      "    ROC-AUC score: 0.5042\n",
      "    Batch 30 / 52: loss 0.6886, accuracy 0.5521\n",
      "    ROC-AUC score: 0.7004\n",
      "    Batch 33 / 52: loss 0.6876, accuracy 0.5625\n",
      "    ROC-AUC score: 0.7176\n",
      "    Batch 36 / 52: loss 0.6850, accuracy 0.5625\n",
      "    ROC-AUC score: 0.6232\n",
      "    Batch 39 / 52: loss 0.6897, accuracy 0.6042\n",
      "    ROC-AUC score: 0.6389\n",
      "    Batch 42 / 52: loss 0.6866, accuracy 0.6146\n",
      "    ROC-AUC score: 0.7103\n",
      "    Batch 45 / 52: loss 0.6882, accuracy 0.5833\n",
      "    ROC-AUC score: 0.5773\n",
      "    Batch 48 / 52: loss 0.6967, accuracy 0.5000\n",
      "    ROC-AUC score: 0.5545\n",
      "    Batch 51 / 52: loss 0.6904, accuracy 0.5729\n",
      "    ROC-AUC score: 0.5664\n",
      "Loss 0.6910, accuracy 0.5590\n",
      "ROC-AUC score: 0.6194\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.37      0.46       830\n",
      "         1.0       0.54      0.74      0.63       830\n",
      "\n",
      "    accuracy                           0.56      1660\n",
      "   macro avg       0.57      0.56      0.54      1660\n",
      "weighted avg       0.57      0.56      0.54      1660\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
