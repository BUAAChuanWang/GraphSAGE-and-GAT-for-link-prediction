{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAContactsHypertext\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contacts_hypertext2009/ia-contacts_hypertext2009.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : True,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : False,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : \"True\",\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0.5,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 3,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 1e-3,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contacts_hypertext2009/ia-contacts_hypertext2009.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 113\n",
      "Number of static edges: 1010\n",
      "Number of temporal edges: 6245\n",
      "Number of examples/datapoints: 7886\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()\n",
    "config['input_dim'], config['output_dim'] = input_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=113, out_features=113, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=226, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = utils.get_model(config)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 324\n",
      "    Batch 2 / 324\n",
      "    Batch 3 / 324\n",
      "    Batch 4 / 324\n",
      "    Batch 5 / 324\n",
      "    Batch 6 / 324\n",
      "    Batch 7 / 324\n",
      "    Batch 8 / 324\n",
      "    Batch 9 / 324\n",
      "    Batch 10 / 324\n",
      "    Batch 11 / 324\n",
      "    Batch 12 / 324\n",
      "    Batch 13 / 324\n",
      "    Batch 14 / 324\n",
      "    Batch 15 / 324\n",
      "    Batch 16 / 324\n",
      "    Batch 17 / 324\n",
      "    Batch 18 / 324\n",
      "    Batch 19 / 324\n",
      "    Batch 20 / 324\n",
      "    Batch 21 / 324\n",
      "    Batch 22 / 324\n",
      "    Batch 23 / 324\n",
      "    Batch 24 / 324\n",
      "    Batch 25 / 324\n",
      "    Batch 26 / 324\n",
      "    Batch 27 / 324\n",
      "    Batch 28 / 324\n",
      "    Batch 29 / 324\n",
      "    Batch 30 / 324\n",
      "    Batch 31 / 324\n",
      "    Batch 32 / 324\n",
      "    Batch 33 / 324\n",
      "    Batch 34 / 324\n",
      "    Batch 35 / 324\n",
      "    Batch 36 / 324\n",
      "    Batch 37 / 324\n",
      "    Batch 38 / 324\n",
      "    Batch 39 / 324\n",
      "    Batch 40 / 324\n",
      "    Batch 41 / 324\n",
      "    Batch 42 / 324\n",
      "    Batch 43 / 324\n",
      "    Batch 44 / 324\n",
      "    Batch 45 / 324\n",
      "    Batch 46 / 324\n",
      "    Batch 47 / 324\n",
      "    Batch 48 / 324\n",
      "    Batch 49 / 324\n",
      "    Batch 50 / 324\n",
      "    Batch 51 / 324\n",
      "    Batch 52 / 324\n",
      "    Batch 53 / 324\n",
      "    Batch 54 / 324\n",
      "    Batch 55 / 324\n",
      "    Batch 56 / 324\n",
      "    Batch 57 / 324\n",
      "    Batch 58 / 324\n",
      "    Batch 59 / 324\n",
      "    Batch 60 / 324\n",
      "    Batch 61 / 324\n",
      "    Batch 62 / 324\n",
      "    Batch 63 / 324\n",
      "    Batch 64 / 324\n",
      "    Batch 65 / 324\n",
      "    Batch 66 / 324\n",
      "    Batch 67 / 324\n",
      "    Batch 68 / 324\n",
      "    Batch 69 / 324\n",
      "    Batch 70 / 324\n",
      "    Batch 71 / 324\n",
      "    Batch 72 / 324\n",
      "    Batch 73 / 324\n",
      "    Batch 74 / 324\n",
      "    Batch 75 / 324\n",
      "    Batch 76 / 324\n",
      "    Batch 77 / 324\n",
      "    Batch 78 / 324\n",
      "    Batch 79 / 324\n",
      "    Batch 80 / 324\n",
      "    Batch 81 / 324\n",
      "    Batch 82 / 324\n",
      "    Batch 83 / 324\n",
      "    Batch 84 / 324\n",
      "    Batch 85 / 324\n",
      "    Batch 86 / 324\n",
      "    Batch 87 / 324\n",
      "    Batch 88 / 324\n",
      "    Batch 89 / 324\n",
      "    Batch 90 / 324\n",
      "    Batch 91 / 324\n",
      "    Batch 92 / 324\n",
      "    Batch 93 / 324\n",
      "    Batch 94 / 324\n",
      "    Batch 95 / 324\n",
      "    Batch 96 / 324\n",
      "    Batch 97 / 324\n",
      "    Batch 98 / 324\n",
      "    Batch 99 / 324\n",
      "    Batch 100 / 324\n",
      "    Batch 101 / 324\n",
      "    Batch 102 / 324\n",
      "    Batch 103 / 324\n",
      "    Batch 104 / 324\n",
      "    Batch 105 / 324\n",
      "    Batch 106 / 324\n",
      "    Batch 107 / 324\n",
      "    Batch 108 / 324\n",
      "    Batch 109 / 324\n",
      "    Batch 110 / 324\n",
      "    Batch 111 / 324\n",
      "    Batch 112 / 324\n",
      "    Batch 113 / 324\n",
      "    Batch 114 / 324\n",
      "    Batch 115 / 324\n",
      "    Batch 116 / 324\n",
      "    Batch 117 / 324\n",
      "    Batch 118 / 324\n",
      "    Batch 119 / 324\n",
      "    Batch 120 / 324\n",
      "    Batch 121 / 324\n",
      "    Batch 122 / 324\n",
      "    Batch 123 / 324\n",
      "    Batch 124 / 324\n",
      "    Batch 125 / 324\n",
      "    Batch 126 / 324\n",
      "    Batch 127 / 324\n",
      "    Batch 128 / 324\n",
      "    Batch 129 / 324\n",
      "    Batch 130 / 324\n",
      "    Batch 131 / 324\n",
      "    Batch 132 / 324\n",
      "    Batch 133 / 324\n",
      "    Batch 134 / 324\n",
      "    Batch 135 / 324\n",
      "    Batch 136 / 324\n",
      "    Batch 137 / 324\n",
      "    Batch 138 / 324\n",
      "    Batch 139 / 324\n",
      "    Batch 140 / 324\n",
      "    Batch 141 / 324\n",
      "    Batch 142 / 324\n",
      "    Batch 143 / 324\n",
      "    Batch 144 / 324\n",
      "    Batch 145 / 324\n",
      "    Batch 146 / 324\n",
      "    Batch 147 / 324\n",
      "    Batch 148 / 324\n",
      "    Batch 149 / 324\n",
      "    Batch 150 / 324\n",
      "    Batch 151 / 324\n",
      "    Batch 152 / 324\n",
      "    Batch 153 / 324\n",
      "    Batch 154 / 324\n",
      "    Batch 155 / 324\n",
      "    Batch 156 / 324\n",
      "    Batch 157 / 324\n",
      "    Batch 158 / 324\n",
      "    Batch 159 / 324\n",
      "    Batch 160 / 324\n",
      "    Batch 161 / 324\n",
      "    Batch 162 / 324\n",
      "    Batch 163 / 324\n",
      "    Batch 164 / 324\n",
      "    Batch 165 / 324\n",
      "    Batch 166 / 324\n",
      "    Batch 167 / 324\n",
      "    Batch 168 / 324\n",
      "    Batch 169 / 324\n",
      "    Batch 170 / 324\n",
      "    Batch 171 / 324\n",
      "    Batch 172 / 324\n",
      "    Batch 173 / 324\n",
      "    Batch 174 / 324\n",
      "    Batch 175 / 324\n",
      "    Batch 176 / 324\n",
      "    Batch 177 / 324\n",
      "    Batch 178 / 324\n",
      "    Batch 179 / 324\n",
      "    Batch 180 / 324\n",
      "    Batch 181 / 324\n",
      "    Batch 182 / 324\n",
      "    Batch 183 / 324\n",
      "    Batch 184 / 324\n",
      "    Batch 185 / 324\n",
      "    Batch 186 / 324\n",
      "    Batch 187 / 324\n",
      "    Batch 188 / 324\n",
      "    Batch 189 / 324\n",
      "    Batch 190 / 324\n",
      "    Batch 191 / 324\n",
      "    Batch 192 / 324\n",
      "    Batch 193 / 324\n",
      "    Batch 194 / 324\n",
      "    Batch 195 / 324\n",
      "    Batch 196 / 324\n",
      "    Batch 197 / 324\n",
      "    Batch 198 / 324\n",
      "    Batch 199 / 324\n",
      "    Batch 200 / 324\n",
      "    Batch 201 / 324\n",
      "    Batch 202 / 324\n",
      "    Batch 203 / 324\n",
      "    Batch 204 / 324\n",
      "    Batch 205 / 324\n",
      "    Batch 206 / 324\n",
      "    Batch 207 / 324\n",
      "    Batch 208 / 324\n",
      "    Batch 209 / 324\n",
      "    Batch 210 / 324\n",
      "    Batch 211 / 324\n",
      "    Batch 212 / 324\n",
      "    Batch 213 / 324\n",
      "    Batch 214 / 324\n",
      "    Batch 215 / 324\n",
      "    Batch 216 / 324\n",
      "    Batch 217 / 324\n",
      "    Batch 218 / 324\n",
      "    Batch 219 / 324\n",
      "    Batch 220 / 324\n",
      "    Batch 221 / 324\n",
      "    Batch 222 / 324\n",
      "    Batch 223 / 324\n",
      "    Batch 224 / 324\n",
      "    Batch 225 / 324\n",
      "    Batch 226 / 324\n",
      "    Batch 227 / 324\n",
      "    Batch 228 / 324\n",
      "    Batch 229 / 324\n",
      "    Batch 230 / 324\n",
      "    Batch 231 / 324\n",
      "    Batch 232 / 324\n",
      "    Batch 233 / 324\n",
      "    Batch 234 / 324\n",
      "    Batch 235 / 324\n",
      "    Batch 236 / 324\n",
      "    Batch 237 / 324\n",
      "    Batch 238 / 324\n",
      "    Batch 239 / 324\n",
      "    Batch 240 / 324\n",
      "    Batch 241 / 324\n",
      "    Batch 242 / 324\n",
      "    Batch 243 / 324\n",
      "    Batch 244 / 324\n",
      "    Batch 245 / 324\n",
      "    Batch 246 / 324\n",
      "    Batch 247 / 324\n",
      "    Batch 248 / 324\n",
      "    Batch 249 / 324\n",
      "    Batch 250 / 324\n",
      "    Batch 251 / 324\n",
      "    Batch 252 / 324\n",
      "    Batch 253 / 324\n",
      "    Batch 254 / 324\n",
      "    Batch 255 / 324\n",
      "    Batch 256 / 324\n",
      "    Batch 257 / 324\n",
      "    Batch 258 / 324\n",
      "    Batch 259 / 324\n",
      "    Batch 260 / 324\n",
      "    Batch 261 / 324\n",
      "    Batch 262 / 324\n",
      "    Batch 263 / 324\n",
      "    Batch 264 / 324\n",
      "    Batch 265 / 324\n",
      "    Batch 266 / 324\n",
      "    Batch 267 / 324\n",
      "    Batch 268 / 324\n",
      "    Batch 269 / 324\n",
      "    Batch 270 / 324\n",
      "    Batch 271 / 324\n",
      "    Batch 272 / 324\n",
      "    Batch 273 / 324\n",
      "    Batch 274 / 324\n",
      "    Batch 275 / 324\n",
      "    Batch 276 / 324\n",
      "    Batch 277 / 324\n",
      "    Batch 278 / 324\n",
      "    Batch 279 / 324\n",
      "    Batch 280 / 324\n",
      "    Batch 281 / 324\n",
      "    Batch 282 / 324\n",
      "    Batch 283 / 324\n",
      "    Batch 284 / 324\n",
      "    Batch 285 / 324\n",
      "    Batch 286 / 324\n",
      "    Batch 287 / 324\n",
      "    Batch 288 / 324\n",
      "    Batch 289 / 324\n",
      "    Batch 290 / 324\n",
      "    Batch 291 / 324\n",
      "    Batch 292 / 324\n",
      "    Batch 293 / 324\n",
      "    Batch 294 / 324\n",
      "    Batch 295 / 324\n",
      "    Batch 296 / 324\n",
      "    Batch 297 / 324\n",
      "    Batch 298 / 324\n",
      "    Batch 299 / 324\n",
      "    Batch 300 / 324\n",
      "    Batch 301 / 324\n",
      "    Batch 302 / 324\n",
      "    Batch 303 / 324\n",
      "    Batch 304 / 324\n",
      "    Batch 305 / 324\n",
      "    Batch 306 / 324\n",
      "    Batch 307 / 324\n",
      "    Batch 308 / 324\n",
      "    Batch 309 / 324\n",
      "    Batch 310 / 324\n",
      "    Batch 311 / 324\n",
      "    Batch 312 / 324\n",
      "    Batch 313 / 324\n",
      "    Batch 314 / 324\n",
      "    Batch 315 / 324\n",
      "    Batch 316 / 324\n",
      "    Batch 317 / 324\n",
      "    Batch 318 / 324\n",
      "    Batch 319 / 324\n",
      "    Batch 320 / 324\n",
      "    Batch 321 / 324\n",
      "    Batch 322 / 324\n",
      "    Batch 323 / 324\n",
      "    Batch 324 / 324\n",
      "ROC-AUC score: 0.5960\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 3\n",
      "    Batch 3 / 324: loss 0.6929\n",
      "    ROC-AUC score: 0.7421\n",
      "    Batch 6 / 324: loss 0.6913\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 9 / 324: loss 0.6903\n",
      "    ROC-AUC score: 0.7266\n",
      "    Batch 12 / 324: loss 0.6882\n",
      "    ROC-AUC score: 0.6865\n",
      "    Batch 15 / 324: loss 0.6836\n",
      "    ROC-AUC score: 0.7937\n",
      "    Batch 18 / 324: loss 0.6755\n",
      "    ROC-AUC score: 0.8175\n",
      "    Batch 21 / 324: loss 0.6823\n",
      "    ROC-AUC score: 0.8359\n",
      "    Batch 24 / 324: loss 0.6539\n",
      "    ROC-AUC score: 0.8340\n",
      "    Batch 27 / 324: loss 0.6611\n",
      "    ROC-AUC score: 0.5789\n",
      "    Batch 30 / 324: loss 0.6642\n",
      "    ROC-AUC score: 0.6941\n",
      "    Batch 33 / 324: loss 0.6628\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 36 / 324: loss 0.6357\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 39 / 324: loss 0.6261\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 42 / 324: loss 0.6468\n",
      "    ROC-AUC score: 0.8219\n",
      "    Batch 45 / 324: loss 0.6407\n",
      "    ROC-AUC score: 0.6825\n",
      "    Batch 48 / 324: loss 0.6208\n",
      "    ROC-AUC score: 0.8139\n",
      "    Batch 51 / 324: loss 0.6343\n",
      "    ROC-AUC score: 0.8413\n",
      "    Batch 54 / 324: loss 0.5941\n",
      "    ROC-AUC score: 0.7461\n",
      "    Batch 57 / 324: loss 0.6350\n",
      "    ROC-AUC score: 0.8196\n",
      "    Batch 60 / 324: loss 0.6127\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 63 / 324: loss 0.5908\n",
      "    ROC-AUC score: 0.8157\n",
      "    Batch 66 / 324: loss 0.6357\n",
      "    ROC-AUC score: 0.8730\n",
      "    Batch 69 / 324: loss 0.6115\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 72 / 324: loss 0.6172\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 75 / 324: loss 0.6200\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 78 / 324: loss 0.5957\n",
      "    ROC-AUC score: 0.8178\n",
      "    Batch 81 / 324: loss 0.6324\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 84 / 324: loss 0.5272\n",
      "    ROC-AUC score: 0.8988\n",
      "    Batch 87 / 324: loss 0.5919\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 90 / 324: loss 0.5720\n",
      "    ROC-AUC score: 0.5873\n",
      "    Batch 93 / 324: loss 0.6084\n",
      "    ROC-AUC score: 0.7186\n",
      "    Batch 96 / 324: loss 0.6207\n",
      "    ROC-AUC score: 0.7733\n",
      "    Batch 99 / 324: loss 0.5054\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 102 / 324: loss 0.5582\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 105 / 324: loss 0.6048\n",
      "    ROC-AUC score: 0.8458\n",
      "    Batch 108 / 324: loss 0.5891\n",
      "    ROC-AUC score: 0.8178\n",
      "    Batch 111 / 324: loss 0.5675\n",
      "    ROC-AUC score: 0.8340\n",
      "    Batch 114 / 324: loss 0.5283\n",
      "    ROC-AUC score: 0.7817\n",
      "    Batch 117 / 324: loss 0.5754\n",
      "    ROC-AUC score: 0.9773\n",
      "    Batch 120 / 324: loss 0.5375\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 123 / 324: loss 0.5189\n",
      "    ROC-AUC score: 0.8864\n",
      "    Batch 126 / 324: loss 0.5802\n",
      "    ROC-AUC score: 0.8961\n",
      "    Batch 129 / 324: loss 0.4860\n",
      "    ROC-AUC score: 0.9500\n",
      "    Batch 132 / 324: loss 0.5848\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 135 / 324: loss 0.5648\n",
      "    ROC-AUC score: 0.7895\n",
      "    Batch 138 / 324: loss 0.4823\n",
      "    ROC-AUC score: 0.8175\n",
      "    Batch 141 / 324: loss 0.5071\n",
      "    ROC-AUC score: 0.7381\n",
      "    Batch 144 / 324: loss 0.5203\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 147 / 324: loss 0.6009\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 150 / 324: loss 0.4798\n",
      "    ROC-AUC score: 0.9555\n",
      "    Batch 153 / 324: loss 0.5460\n",
      "    ROC-AUC score: 0.9271\n",
      "    Batch 156 / 324: loss 0.6127\n",
      "    ROC-AUC score: 0.7250\n",
      "    Batch 159 / 324: loss 0.5383\n",
      "    ROC-AUC score: 0.8810\n",
      "    Batch 162 / 324: loss 0.5379\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 165 / 324: loss 0.5190\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 168 / 324: loss 0.5433\n",
      "    ROC-AUC score: 0.8516\n",
      "    Batch 171 / 324: loss 0.5012\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 174 / 324: loss 0.5947\n",
      "    ROC-AUC score: 0.8135\n",
      "    Batch 177 / 324: loss 0.5965\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 180 / 324: loss 0.4967\n",
      "    ROC-AUC score: 0.8644\n",
      "    Batch 183 / 324: loss 0.5768\n",
      "    ROC-AUC score: 0.8615\n",
      "    Batch 186 / 324: loss 0.5446\n",
      "    ROC-AUC score: 0.7857\n",
      "    Batch 189 / 324: loss 0.4779\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 192 / 324: loss 0.5872\n",
      "    ROC-AUC score: 0.8039\n",
      "    Batch 195 / 324: loss 0.5645\n",
      "    ROC-AUC score: 0.7216\n",
      "    Batch 198 / 324: loss 0.6400\n",
      "    ROC-AUC score: 0.8874\n",
      "    Batch 201 / 324: loss 0.5934\n",
      "    ROC-AUC score: 0.8417\n",
      "    Batch 204 / 324: loss 0.4846\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 207 / 324: loss 0.5894\n",
      "    ROC-AUC score: 0.6786\n",
      "    Batch 210 / 324: loss 0.5201\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 213 / 324: loss 0.5058\n",
      "    ROC-AUC score: 0.8818\n",
      "    Batch 216 / 324: loss 0.4757\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 219 / 324: loss 0.4770\n",
      "    ROC-AUC score: 0.8599\n",
      "    Batch 222 / 324: loss 0.5818\n",
      "    ROC-AUC score: 0.7843\n",
      "    Batch 225 / 324: loss 0.5459\n",
      "    ROC-AUC score: 0.8792\n",
      "    Batch 228 / 324: loss 0.4992\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 231 / 324: loss 0.6024\n",
      "    ROC-AUC score: 0.9127\n",
      "    Batch 234 / 324: loss 0.5075\n",
      "    ROC-AUC score: 0.8502\n",
      "    Batch 237 / 324: loss 0.5550\n",
      "    ROC-AUC score: 0.8532\n",
      "    Batch 240 / 324: loss 0.5302\n",
      "    ROC-AUC score: 0.7383\n",
      "    Batch 243 / 324: loss 0.6252\n",
      "    ROC-AUC score: 0.8599\n",
      "    Batch 246 / 324: loss 0.4680\n",
      "    ROC-AUC score: 0.8485\n",
      "    Batch 249 / 324: loss 0.4981\n",
      "    ROC-AUC score: 0.8458\n",
      "    Batch 252 / 324: loss 0.5169\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 255 / 324: loss 0.5654\n",
      "    ROC-AUC score: 0.8259\n",
      "    Batch 258 / 324: loss 0.4738\n",
      "    ROC-AUC score: 0.9722\n",
      "    Batch 261 / 324: loss 0.6282\n",
      "    ROC-AUC score: 0.6055\n",
      "    Batch 264 / 324: loss 0.5318\n",
      "    ROC-AUC score: 0.9264\n",
      "    Batch 267 / 324: loss 0.5260\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 270 / 324: loss 0.5217\n",
      "    ROC-AUC score: 0.8114\n",
      "    Batch 273 / 324: loss 0.6026\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 276 / 324: loss 0.6022\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 279 / 324: loss 0.5006\n",
      "    ROC-AUC score: 0.7619\n",
      "    Batch 282 / 324: loss 0.5363\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 285 / 324: loss 0.4651\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 288 / 324: loss 0.5412\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 291 / 324: loss 0.5606\n",
      "    ROC-AUC score: 0.8359\n",
      "    Batch 294 / 324: loss 0.5611\n",
      "    ROC-AUC score: 0.7750\n",
      "    Batch 297 / 324: loss 0.4904\n",
      "    ROC-AUC score: 0.9453\n",
      "    Batch 300 / 324: loss 0.5403\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 303 / 324: loss 0.5560\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 306 / 324: loss 0.5334\n",
      "    ROC-AUC score: 0.7765\n",
      "    Batch 309 / 324: loss 0.5369\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 312 / 324: loss 0.5812\n",
      "    ROC-AUC score: 0.8708\n",
      "    Batch 315 / 324: loss 0.5451\n",
      "    ROC-AUC score: 0.7583\n",
      "    Batch 318 / 324: loss 0.5933\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 321 / 324: loss 0.5516\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 324 / 324: loss 0.4820\n",
      "    ROC-AUC score: 0.7798\n",
      "Epoch 2 / 3\n",
      "    Batch 3 / 324: loss 0.4912\n",
      "    ROC-AUC score: 0.8294\n",
      "    Batch 6 / 324: loss 0.4986\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 9 / 324: loss 0.5253\n",
      "    ROC-AUC score: 0.8543\n",
      "    Batch 12 / 324: loss 0.4698\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 15 / 324: loss 0.4684\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 18 / 324: loss 0.4820\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 21 / 324: loss 0.4615\n",
      "    ROC-AUC score: 0.9531\n",
      "    Batch 24 / 324: loss 0.5723\n",
      "    ROC-AUC score: 0.9474\n",
      "    Batch 27 / 324: loss 0.5398\n",
      "    ROC-AUC score: 0.7451\n",
      "    Batch 30 / 324: loss 0.5508\n",
      "    ROC-AUC score: 0.7852\n",
      "    Batch 33 / 324: loss 0.5501\n",
      "    ROC-AUC score: 0.8623\n",
      "    Batch 36 / 324: loss 0.5745\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 39 / 324: loss 0.5538\n",
      "    ROC-AUC score: 0.8392\n",
      "    Batch 42 / 324: loss 0.4714\n",
      "    ROC-AUC score: 0.8627\n",
      "    Batch 45 / 324: loss 0.5295\n",
      "    ROC-AUC score: 0.8438\n",
      "    Batch 48 / 324: loss 0.5173\n",
      "    ROC-AUC score: 0.8711\n",
      "    Batch 51 / 324: loss 0.5048\n",
      "    ROC-AUC score: 0.8789\n",
      "    Batch 54 / 324: loss 0.4528\n",
      "    ROC-AUC score: 0.8701\n",
      "    Batch 57 / 324: loss 0.4999\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 60 / 324: loss 0.5696\n",
      "    ROC-AUC score: 0.7569\n",
      "    Batch 63 / 324: loss 0.5624\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 66 / 324: loss 0.4994\n",
      "    ROC-AUC score: 0.7958\n",
      "    Batch 69 / 324: loss 0.5775\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 72 / 324: loss 0.4550\n",
      "    ROC-AUC score: 0.9414\n",
      "    Batch 75 / 324: loss 0.5907\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 78 / 324: loss 0.6997\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 81 / 324: loss 0.5115\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 84 / 324: loss 0.5070\n",
      "    ROC-AUC score: 0.9190\n",
      "    Batch 87 / 324: loss 0.5402\n",
      "    ROC-AUC score: 0.8792\n",
      "    Batch 90 / 324: loss 0.4364\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 93 / 324: loss 0.5001\n",
      "    ROC-AUC score: 0.8588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 96 / 324: loss 0.5222\n",
      "    ROC-AUC score: 0.7667\n",
      "    Batch 99 / 324: loss 0.5208\n",
      "    ROC-AUC score: 0.8818\n",
      "    Batch 102 / 324: loss 0.5559\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 105 / 324: loss 0.5341\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 108 / 324: loss 0.5131\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 111 / 324: loss 0.5122\n",
      "    ROC-AUC score: 0.8532\n",
      "    Batch 114 / 324: loss 0.5938\n",
      "    ROC-AUC score: 0.7667\n",
      "    Batch 117 / 324: loss 0.5760\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 120 / 324: loss 0.5306\n",
      "    ROC-AUC score: 0.7725\n",
      "    Batch 123 / 324: loss 0.5258\n",
      "    ROC-AUC score: 0.6431\n",
      "    Batch 126 / 324: loss 0.6032\n",
      "    ROC-AUC score: 0.8157\n",
      "    Batch 129 / 324: loss 0.4909\n",
      "    ROC-AUC score: 0.8686\n",
      "    Batch 132 / 324: loss 0.5365\n",
      "    ROC-AUC score: 0.8225\n",
      "    Batch 135 / 324: loss 0.4627\n",
      "    ROC-AUC score: 0.9524\n",
      "    Batch 138 / 324: loss 0.5312\n",
      "    ROC-AUC score: 0.8477\n",
      "    Batch 141 / 324: loss 0.4366\n",
      "    ROC-AUC score: 0.9603\n",
      "    Batch 144 / 324: loss 0.5077\n",
      "    ROC-AUC score: 0.9683\n",
      "    Batch 147 / 324: loss 0.4770\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 150 / 324: loss 0.4722\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 153 / 324: loss 0.4203\n",
      "    ROC-AUC score: 0.9833\n",
      "    Batch 156 / 324: loss 0.5101\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 159 / 324: loss 0.5307\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 162 / 324: loss 0.5226\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 165 / 324: loss 0.4731\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 168 / 324: loss 0.5192\n",
      "    ROC-AUC score: 0.9258\n",
      "    Batch 171 / 324: loss 0.4762\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 174 / 324: loss 0.6152\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 177 / 324: loss 0.6099\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 180 / 324: loss 0.5679\n",
      "    ROC-AUC score: 0.8636\n",
      "    Batch 183 / 324: loss 0.5427\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 186 / 324: loss 0.5017\n",
      "    ROC-AUC score: 0.7451\n",
      "    Batch 189 / 324: loss 0.5652\n",
      "    ROC-AUC score: 0.7817\n",
      "    Batch 192 / 324: loss 0.5408\n",
      "    ROC-AUC score: 0.8784\n",
      "    Batch 195 / 324: loss 0.5248\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 198 / 324: loss 0.4833\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 201 / 324: loss 0.4518\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 204 / 324: loss 0.5477\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 207 / 324: loss 0.4772\n",
      "    ROC-AUC score: 0.9686\n",
      "    Batch 210 / 324: loss 0.5661\n",
      "    ROC-AUC score: 0.8008\n",
      "    Batch 213 / 324: loss 0.5190\n",
      "    ROC-AUC score: 0.9365\n",
      "    Batch 216 / 324: loss 0.5133\n",
      "    ROC-AUC score: 0.8708\n",
      "    Batch 219 / 324: loss 0.5675\n",
      "    ROC-AUC score: 0.7381\n",
      "    Batch 222 / 324: loss 0.5408\n",
      "    ROC-AUC score: 0.8826\n",
      "    Batch 225 / 324: loss 0.5609\n",
      "    ROC-AUC score: 0.7579\n",
      "    Batch 228 / 324: loss 0.5462\n",
      "    ROC-AUC score: 0.9325\n",
      "    Batch 231 / 324: loss 0.5355\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 234 / 324: loss 0.5177\n",
      "    ROC-AUC score: 0.8500\n",
      "    Batch 237 / 324: loss 0.5774\n",
      "    ROC-AUC score: 0.7659\n",
      "    Batch 240 / 324: loss 0.5021\n",
      "    ROC-AUC score: 0.7817\n",
      "    Batch 243 / 324: loss 0.5386\n",
      "    ROC-AUC score: 0.7667\n",
      "    Batch 246 / 324: loss 0.4937\n",
      "    ROC-AUC score: 0.8615\n",
      "    Batch 249 / 324: loss 0.4983\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 252 / 324: loss 0.5224\n",
      "    ROC-AUC score: 0.8711\n",
      "    Batch 255 / 324: loss 0.4520\n",
      "    ROC-AUC score: 0.8875\n",
      "    Batch 258 / 324: loss 0.5334\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 261 / 324: loss 0.4686\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 264 / 324: loss 0.5375\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 267 / 324: loss 0.4545\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 270 / 324: loss 0.5144\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 273 / 324: loss 0.5618\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 276 / 324: loss 0.4991\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 279 / 324: loss 0.6523\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 282 / 324: loss 0.5156\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 285 / 324: loss 0.4983\n",
      "    ROC-AUC score: 0.8292\n",
      "    Batch 288 / 324: loss 0.5342\n",
      "    ROC-AUC score: 0.7804\n",
      "    Batch 291 / 324: loss 0.5732\n",
      "    ROC-AUC score: 0.8413\n",
      "    Batch 294 / 324: loss 0.4904\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 297 / 324: loss 0.5035\n",
      "    ROC-AUC score: 0.9141\n",
      "    Batch 300 / 324: loss 0.5490\n",
      "    ROC-AUC score: 0.8690\n",
      "    Batch 303 / 324: loss 0.5184\n",
      "    ROC-AUC score: 0.8268\n",
      "    Batch 306 / 324: loss 0.5196\n",
      "    ROC-AUC score: 0.8208\n",
      "    Batch 309 / 324: loss 0.5545\n",
      "    ROC-AUC score: 0.7692\n",
      "    Batch 312 / 324: loss 0.5175\n",
      "    ROC-AUC score: 0.8275\n",
      "    Batch 315 / 324: loss 0.4744\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 318 / 324: loss 0.5406\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 321 / 324: loss 0.6039\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 324 / 324: loss 0.5053\n",
      "    ROC-AUC score: 0.9405\n",
      "Epoch 3 / 3\n",
      "    Batch 3 / 324: loss 0.5855\n",
      "    ROC-AUC score: 0.7305\n",
      "    Batch 6 / 324: loss 0.5343\n",
      "    ROC-AUC score: 0.8765\n",
      "    Batch 9 / 324: loss 0.4762\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 12 / 324: loss 0.5390\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 15 / 324: loss 0.4639\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 18 / 324: loss 0.5221\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 21 / 324: loss 0.5721\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 24 / 324: loss 0.5780\n",
      "    ROC-AUC score: 0.8867\n",
      "    Batch 27 / 324: loss 0.5548\n",
      "    ROC-AUC score: 0.8549\n",
      "    Batch 30 / 324: loss 0.4219\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 33 / 324: loss 0.4554\n",
      "    ROC-AUC score: 0.8542\n",
      "    Batch 36 / 324: loss 0.5193\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 39 / 324: loss 0.6020\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 42 / 324: loss 0.5389\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 45 / 324: loss 0.4751\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 48 / 324: loss 0.4081\n",
      "    ROC-AUC score: 0.9082\n",
      "    Batch 51 / 324: loss 0.5554\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 54 / 324: loss 0.5322\n",
      "    ROC-AUC score: 0.8627\n",
      "    Batch 57 / 324: loss 0.5166\n",
      "    ROC-AUC score: 0.9150\n",
      "    Batch 60 / 324: loss 0.5744\n",
      "    ROC-AUC score: 0.8611\n",
      "    Batch 63 / 324: loss 0.4975\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 66 / 324: loss 0.5333\n",
      "    ROC-AUC score: 0.7539\n",
      "    Batch 69 / 324: loss 0.4815\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 72 / 324: loss 0.5239\n",
      "    ROC-AUC score: 0.7738\n",
      "    Batch 75 / 324: loss 0.4982\n",
      "    ROC-AUC score: 0.7857\n",
      "    Batch 78 / 324: loss 0.5445\n",
      "    ROC-AUC score: 0.8360\n",
      "    Batch 81 / 324: loss 0.4617\n",
      "    ROC-AUC score: 0.9492\n",
      "    Batch 84 / 324: loss 0.5302\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 87 / 324: loss 0.5156\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 90 / 324: loss 0.5281\n",
      "    ROC-AUC score: 0.8392\n",
      "    Batch 93 / 324: loss 0.5679\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 96 / 324: loss 0.4612\n",
      "    ROC-AUC score: 0.8353\n",
      "    Batch 99 / 324: loss 0.5575\n",
      "    ROC-AUC score: 0.8281\n",
      "    Batch 102 / 324: loss 0.6079\n",
      "    ROC-AUC score: 0.7216\n",
      "    Batch 105 / 324: loss 0.5199\n",
      "    ROC-AUC score: 0.8906\n",
      "    Batch 108 / 324: loss 0.4449\n",
      "    ROC-AUC score: 0.9297\n",
      "    Batch 111 / 324: loss 0.5325\n",
      "    ROC-AUC score: 0.7667\n",
      "    Batch 114 / 324: loss 0.5471\n",
      "    ROC-AUC score: 0.7686\n",
      "    Batch 117 / 324: loss 0.4962\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 120 / 324: loss 0.5795\n",
      "    ROC-AUC score: 0.8373\n",
      "    Batch 123 / 324: loss 0.7178\n",
      "    ROC-AUC score: 0.7750\n",
      "    Batch 126 / 324: loss 0.4487\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 129 / 324: loss 0.4640\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 132 / 324: loss 0.5224\n",
      "    ROC-AUC score: 0.8945\n",
      "    Batch 135 / 324: loss 0.5119\n",
      "    ROC-AUC score: 0.8608\n",
      "    Batch 138 / 324: loss 0.4687\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 141 / 324: loss 0.4866\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 144 / 324: loss 0.6155\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 147 / 324: loss 0.5173\n",
      "    ROC-AUC score: 0.8157\n",
      "    Batch 150 / 324: loss 0.5415\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 153 / 324: loss 0.4693\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 156 / 324: loss 0.4348\n",
      "    ROC-AUC score: 0.9167\n",
      "    Batch 159 / 324: loss 0.5062\n",
      "    ROC-AUC score: 0.8918\n",
      "    Batch 162 / 324: loss 0.5219\n",
      "    ROC-AUC score: 0.9028\n",
      "    Batch 165 / 324: loss 0.4832\n",
      "    ROC-AUC score: 0.8056\n",
      "    Batch 168 / 324: loss 0.5300\n",
      "    ROC-AUC score: 0.8078\n",
      "    Batch 171 / 324: loss 0.4822\n",
      "    ROC-AUC score: 0.8421\n",
      "    Batch 174 / 324: loss 0.5046\n",
      "    ROC-AUC score: 0.8462\n",
      "    Batch 177 / 324: loss 0.5461\n",
      "    ROC-AUC score: 0.9608\n",
      "    Batch 180 / 324: loss 0.5247\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 183 / 324: loss 0.5765\n",
      "    ROC-AUC score: 0.7344\n",
      "    Batch 186 / 324: loss 0.5389\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 189 / 324: loss 0.5713\n",
      "    ROC-AUC score: 0.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 192 / 324: loss 0.4489\n",
      "    ROC-AUC score: 0.9529\n",
      "    Batch 195 / 324: loss 0.4603\n",
      "    ROC-AUC score: 0.9514\n",
      "    Batch 198 / 324: loss 0.4438\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 201 / 324: loss 0.5386\n",
      "    ROC-AUC score: 0.8917\n",
      "    Batch 204 / 324: loss 0.5266\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 207 / 324: loss 0.5085\n",
      "    ROC-AUC score: 0.8917\n",
      "    Batch 210 / 324: loss 0.4718\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 213 / 324: loss 0.5234\n",
      "    ROC-AUC score: 0.9444\n",
      "    Batch 216 / 324: loss 0.5230\n",
      "    ROC-AUC score: 0.7373\n",
      "    Batch 219 / 324: loss 0.4256\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 222 / 324: loss 0.5618\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 225 / 324: loss 0.4709\n",
      "    ROC-AUC score: 0.8810\n",
      "    Batch 228 / 324: loss 0.4726\n",
      "    ROC-AUC score: 0.8980\n",
      "    Batch 231 / 324: loss 0.4883\n",
      "    ROC-AUC score: 0.7895\n",
      "    Batch 234 / 324: loss 0.4765\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 237 / 324: loss 0.4844\n",
      "    ROC-AUC score: 0.9490\n",
      "    Batch 240 / 324: loss 0.4804\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 243 / 324: loss 0.5709\n",
      "    ROC-AUC score: 0.9231\n",
      "    Batch 246 / 324: loss 0.5951\n",
      "    ROC-AUC score: 0.9555\n",
      "    Batch 249 / 324: loss 0.6855\n",
      "    ROC-AUC score: 0.7695\n",
      "    Batch 252 / 324: loss 0.5485\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 255 / 324: loss 0.4768\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 258 / 324: loss 0.4846\n",
      "    ROC-AUC score: 0.8543\n",
      "    Batch 261 / 324: loss 0.5325\n",
      "    ROC-AUC score: 0.7695\n",
      "    Batch 264 / 324: loss 0.5165\n",
      "    ROC-AUC score: 0.8961\n",
      "    Batch 267 / 324: loss 0.5448\n",
      "    ROC-AUC score: 0.7617\n",
      "    Batch 270 / 324: loss 0.5294\n",
      "    ROC-AUC score: 0.8008\n",
      "    Batch 273 / 324: loss 0.4146\n",
      "    ROC-AUC score: 0.9481\n",
      "    Batch 276 / 324: loss 0.5692\n",
      "    ROC-AUC score: 0.7143\n",
      "    Batch 279 / 324: loss 0.4881\n",
      "    ROC-AUC score: 0.9375\n",
      "    Batch 282 / 324: loss 0.6046\n",
      "    ROC-AUC score: 0.7208\n",
      "    Batch 285 / 324: loss 0.5489\n",
      "    ROC-AUC score: 0.8543\n",
      "    Batch 288 / 324: loss 0.5223\n",
      "    ROC-AUC score: 0.9136\n",
      "    Batch 291 / 324: loss 0.5255\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 294 / 324: loss 0.5628\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 297 / 324: loss 0.5382\n",
      "    ROC-AUC score: 0.8078\n",
      "    Batch 300 / 324: loss 0.5705\n",
      "    ROC-AUC score: 0.8157\n",
      "    Batch 303 / 324: loss 0.5428\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 306 / 324: loss 0.5425\n",
      "    ROC-AUC score: 0.8355\n",
      "    Batch 309 / 324: loss 0.4895\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 312 / 324: loss 0.5483\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 315 / 324: loss 0.5588\n",
      "    ROC-AUC score: 0.8599\n",
      "    Batch 318 / 324: loss 0.5292\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 321 / 324: loss 0.5838\n",
      "    ROC-AUC score: 0.8730\n",
      "    Batch 324 / 324: loss 0.4113\n",
      "    ROC-AUC score: 1.0000\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[300], gamma=0.7)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 324\n",
      "    Batch 2 / 324\n",
      "    Batch 3 / 324\n",
      "    Batch 4 / 324\n",
      "    Batch 5 / 324\n",
      "    Batch 6 / 324\n",
      "    Batch 7 / 324\n",
      "    Batch 8 / 324\n",
      "    Batch 9 / 324\n",
      "    Batch 10 / 324\n",
      "    Batch 11 / 324\n",
      "    Batch 12 / 324\n",
      "    Batch 13 / 324\n",
      "    Batch 14 / 324\n",
      "    Batch 15 / 324\n",
      "    Batch 16 / 324\n",
      "    Batch 17 / 324\n",
      "    Batch 18 / 324\n",
      "    Batch 19 / 324\n",
      "    Batch 20 / 324\n",
      "    Batch 21 / 324\n",
      "    Batch 22 / 324\n",
      "    Batch 23 / 324\n",
      "    Batch 24 / 324\n",
      "    Batch 25 / 324\n",
      "    Batch 26 / 324\n",
      "    Batch 27 / 324\n",
      "    Batch 28 / 324\n",
      "    Batch 29 / 324\n",
      "    Batch 30 / 324\n",
      "    Batch 31 / 324\n",
      "    Batch 32 / 324\n",
      "    Batch 33 / 324\n",
      "    Batch 34 / 324\n",
      "    Batch 35 / 324\n",
      "    Batch 36 / 324\n",
      "    Batch 37 / 324\n",
      "    Batch 38 / 324\n",
      "    Batch 39 / 324\n",
      "    Batch 40 / 324\n",
      "    Batch 41 / 324\n",
      "    Batch 42 / 324\n",
      "    Batch 43 / 324\n",
      "    Batch 44 / 324\n",
      "    Batch 45 / 324\n",
      "    Batch 46 / 324\n",
      "    Batch 47 / 324\n",
      "    Batch 48 / 324\n",
      "    Batch 49 / 324\n",
      "    Batch 50 / 324\n",
      "    Batch 51 / 324\n",
      "    Batch 52 / 324\n",
      "    Batch 53 / 324\n",
      "    Batch 54 / 324\n",
      "    Batch 55 / 324\n",
      "    Batch 56 / 324\n",
      "    Batch 57 / 324\n",
      "    Batch 58 / 324\n",
      "    Batch 59 / 324\n",
      "    Batch 60 / 324\n",
      "    Batch 61 / 324\n",
      "    Batch 62 / 324\n",
      "    Batch 63 / 324\n",
      "    Batch 64 / 324\n",
      "    Batch 65 / 324\n",
      "    Batch 66 / 324\n",
      "    Batch 67 / 324\n",
      "    Batch 68 / 324\n",
      "    Batch 69 / 324\n",
      "    Batch 70 / 324\n",
      "    Batch 71 / 324\n",
      "    Batch 72 / 324\n",
      "    Batch 73 / 324\n",
      "    Batch 74 / 324\n",
      "    Batch 75 / 324\n",
      "    Batch 76 / 324\n",
      "    Batch 77 / 324\n",
      "    Batch 78 / 324\n",
      "    Batch 79 / 324\n",
      "    Batch 80 / 324\n",
      "    Batch 81 / 324\n",
      "    Batch 82 / 324\n",
      "    Batch 83 / 324\n",
      "    Batch 84 / 324\n",
      "    Batch 85 / 324\n",
      "    Batch 86 / 324\n",
      "    Batch 87 / 324\n",
      "    Batch 88 / 324\n",
      "    Batch 89 / 324\n",
      "    Batch 90 / 324\n",
      "    Batch 91 / 324\n",
      "    Batch 92 / 324\n",
      "    Batch 93 / 324\n",
      "    Batch 94 / 324\n",
      "    Batch 95 / 324\n",
      "    Batch 96 / 324\n",
      "    Batch 97 / 324\n",
      "    Batch 98 / 324\n",
      "    Batch 99 / 324\n",
      "    Batch 100 / 324\n",
      "    Batch 101 / 324\n",
      "    Batch 102 / 324\n",
      "    Batch 103 / 324\n",
      "    Batch 104 / 324\n",
      "    Batch 105 / 324\n",
      "    Batch 106 / 324\n",
      "    Batch 107 / 324\n",
      "    Batch 108 / 324\n",
      "    Batch 109 / 324\n",
      "    Batch 110 / 324\n",
      "    Batch 111 / 324\n",
      "    Batch 112 / 324\n",
      "    Batch 113 / 324\n",
      "    Batch 114 / 324\n",
      "    Batch 115 / 324\n",
      "    Batch 116 / 324\n",
      "    Batch 117 / 324\n",
      "    Batch 118 / 324\n",
      "    Batch 119 / 324\n",
      "    Batch 120 / 324\n",
      "    Batch 121 / 324\n",
      "    Batch 122 / 324\n",
      "    Batch 123 / 324\n",
      "    Batch 124 / 324\n",
      "    Batch 125 / 324\n",
      "    Batch 126 / 324\n",
      "    Batch 127 / 324\n",
      "    Batch 128 / 324\n",
      "    Batch 129 / 324\n",
      "    Batch 130 / 324\n",
      "    Batch 131 / 324\n",
      "    Batch 132 / 324\n",
      "    Batch 133 / 324\n",
      "    Batch 134 / 324\n",
      "    Batch 135 / 324\n",
      "    Batch 136 / 324\n",
      "    Batch 137 / 324\n",
      "    Batch 138 / 324\n",
      "    Batch 139 / 324\n",
      "    Batch 140 / 324\n",
      "    Batch 141 / 324\n",
      "    Batch 142 / 324\n",
      "    Batch 143 / 324\n",
      "    Batch 144 / 324\n",
      "    Batch 145 / 324\n",
      "    Batch 146 / 324\n",
      "    Batch 147 / 324\n",
      "    Batch 148 / 324\n",
      "    Batch 149 / 324\n",
      "    Batch 150 / 324\n",
      "    Batch 151 / 324\n",
      "    Batch 152 / 324\n",
      "    Batch 153 / 324\n",
      "    Batch 154 / 324\n",
      "    Batch 155 / 324\n",
      "    Batch 156 / 324\n",
      "    Batch 157 / 324\n",
      "    Batch 158 / 324\n",
      "    Batch 159 / 324\n",
      "    Batch 160 / 324\n",
      "    Batch 161 / 324\n",
      "    Batch 162 / 324\n",
      "    Batch 163 / 324\n",
      "    Batch 164 / 324\n",
      "    Batch 165 / 324\n",
      "    Batch 166 / 324\n",
      "    Batch 167 / 324\n",
      "    Batch 168 / 324\n",
      "    Batch 169 / 324\n",
      "    Batch 170 / 324\n",
      "    Batch 171 / 324\n",
      "    Batch 172 / 324\n",
      "    Batch 173 / 324\n",
      "    Batch 174 / 324\n",
      "    Batch 175 / 324\n",
      "    Batch 176 / 324\n",
      "    Batch 177 / 324\n",
      "    Batch 178 / 324\n",
      "    Batch 179 / 324\n",
      "    Batch 180 / 324\n",
      "    Batch 181 / 324\n",
      "    Batch 182 / 324\n",
      "    Batch 183 / 324\n",
      "    Batch 184 / 324\n",
      "    Batch 185 / 324\n",
      "    Batch 186 / 324\n",
      "    Batch 187 / 324\n",
      "    Batch 188 / 324\n",
      "    Batch 189 / 324\n",
      "    Batch 190 / 324\n",
      "    Batch 191 / 324\n",
      "    Batch 192 / 324\n",
      "    Batch 193 / 324\n",
      "    Batch 194 / 324\n",
      "    Batch 195 / 324\n",
      "    Batch 196 / 324\n",
      "    Batch 197 / 324\n",
      "    Batch 198 / 324\n",
      "    Batch 199 / 324\n",
      "    Batch 200 / 324\n",
      "    Batch 201 / 324\n",
      "    Batch 202 / 324\n",
      "    Batch 203 / 324\n",
      "    Batch 204 / 324\n",
      "    Batch 205 / 324\n",
      "    Batch 206 / 324\n",
      "    Batch 207 / 324\n",
      "    Batch 208 / 324\n",
      "    Batch 209 / 324\n",
      "    Batch 210 / 324\n",
      "    Batch 211 / 324\n",
      "    Batch 212 / 324\n",
      "    Batch 213 / 324\n",
      "    Batch 214 / 324\n",
      "    Batch 215 / 324\n",
      "    Batch 216 / 324\n",
      "    Batch 217 / 324\n",
      "    Batch 218 / 324\n",
      "    Batch 219 / 324\n",
      "    Batch 220 / 324\n",
      "    Batch 221 / 324\n",
      "    Batch 222 / 324\n",
      "    Batch 223 / 324\n",
      "    Batch 224 / 324\n",
      "    Batch 225 / 324\n",
      "    Batch 226 / 324\n",
      "    Batch 227 / 324\n",
      "    Batch 228 / 324\n",
      "    Batch 229 / 324\n",
      "    Batch 230 / 324\n",
      "    Batch 231 / 324\n",
      "    Batch 232 / 324\n",
      "    Batch 233 / 324\n",
      "    Batch 234 / 324\n",
      "    Batch 235 / 324\n",
      "    Batch 236 / 324\n",
      "    Batch 237 / 324\n",
      "    Batch 238 / 324\n",
      "    Batch 239 / 324\n",
      "    Batch 240 / 324\n",
      "    Batch 241 / 324\n",
      "    Batch 242 / 324\n",
      "    Batch 243 / 324\n",
      "    Batch 244 / 324\n",
      "    Batch 245 / 324\n",
      "    Batch 246 / 324\n",
      "    Batch 247 / 324\n",
      "    Batch 248 / 324\n",
      "    Batch 249 / 324\n",
      "    Batch 250 / 324\n",
      "    Batch 251 / 324\n",
      "    Batch 252 / 324\n",
      "    Batch 253 / 324\n",
      "    Batch 254 / 324\n",
      "    Batch 255 / 324\n",
      "    Batch 256 / 324\n",
      "    Batch 257 / 324\n",
      "    Batch 258 / 324\n",
      "    Batch 259 / 324\n",
      "    Batch 260 / 324\n",
      "    Batch 261 / 324\n",
      "    Batch 262 / 324\n",
      "    Batch 263 / 324\n",
      "    Batch 264 / 324\n",
      "    Batch 265 / 324\n",
      "    Batch 266 / 324\n",
      "    Batch 267 / 324\n",
      "    Batch 268 / 324\n",
      "    Batch 269 / 324\n",
      "    Batch 270 / 324\n",
      "    Batch 271 / 324\n",
      "    Batch 272 / 324\n",
      "    Batch 273 / 324\n",
      "    Batch 274 / 324\n",
      "    Batch 275 / 324\n",
      "    Batch 276 / 324\n",
      "    Batch 277 / 324\n",
      "    Batch 278 / 324\n",
      "    Batch 279 / 324\n",
      "    Batch 280 / 324\n",
      "    Batch 281 / 324\n",
      "    Batch 282 / 324\n",
      "    Batch 283 / 324\n",
      "    Batch 284 / 324\n",
      "    Batch 285 / 324\n",
      "    Batch 286 / 324\n",
      "    Batch 287 / 324\n",
      "    Batch 288 / 324\n",
      "    Batch 289 / 324\n",
      "    Batch 290 / 324\n",
      "    Batch 291 / 324\n",
      "    Batch 292 / 324\n",
      "    Batch 293 / 324\n",
      "    Batch 294 / 324\n",
      "    Batch 295 / 324\n",
      "    Batch 296 / 324\n",
      "    Batch 297 / 324\n",
      "    Batch 298 / 324\n",
      "    Batch 299 / 324\n",
      "    Batch 300 / 324\n",
      "    Batch 301 / 324\n",
      "    Batch 302 / 324\n",
      "    Batch 303 / 324\n",
      "    Batch 304 / 324\n",
      "    Batch 305 / 324\n",
      "    Batch 306 / 324\n",
      "    Batch 307 / 324\n",
      "    Batch 308 / 324\n",
      "    Batch 309 / 324\n",
      "    Batch 310 / 324\n",
      "    Batch 311 / 324\n",
      "    Batch 312 / 324\n",
      "    Batch 313 / 324\n",
      "    Batch 314 / 324\n",
      "    Batch 315 / 324\n",
      "    Batch 316 / 324\n",
      "    Batch 317 / 324\n",
      "    Batch 318 / 324\n",
      "    Batch 319 / 324\n",
      "    Batch 320 / 324\n",
      "    Batch 321 / 324\n",
      "    Batch 322 / 324\n",
      "    Batch 323 / 324\n",
      "    Batch 324 / 324\n",
      "ROC-AUC score: 0.8704\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().numpy())\n",
    "            y_scores.extend(scores.detach().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 324\n",
      "    Batch 2 / 324\n",
      "    Batch 3 / 324\n",
      "    Batch 4 / 324\n",
      "    Batch 5 / 324\n",
      "    Batch 6 / 324\n",
      "    Batch 7 / 324\n",
      "    Batch 8 / 324\n",
      "    Batch 9 / 324\n",
      "    Batch 10 / 324\n",
      "    Batch 11 / 324\n",
      "    Batch 12 / 324\n",
      "    Batch 13 / 324\n",
      "    Batch 14 / 324\n",
      "    Batch 15 / 324\n",
      "    Batch 16 / 324\n",
      "    Batch 17 / 324\n",
      "    Batch 18 / 324\n",
      "    Batch 19 / 324\n",
      "    Batch 20 / 324\n",
      "    Batch 21 / 324\n",
      "    Batch 22 / 324\n",
      "    Batch 23 / 324\n",
      "    Batch 24 / 324\n",
      "    Batch 25 / 324\n",
      "    Batch 26 / 324\n",
      "    Batch 27 / 324\n",
      "    Batch 28 / 324\n",
      "    Batch 29 / 324\n",
      "    Batch 30 / 324\n",
      "    Batch 31 / 324\n",
      "    Batch 32 / 324\n",
      "    Batch 33 / 324\n",
      "    Batch 34 / 324\n",
      "    Batch 35 / 324\n",
      "    Batch 36 / 324\n",
      "    Batch 37 / 324\n",
      "    Batch 38 / 324\n",
      "    Batch 39 / 324\n",
      "    Batch 40 / 324\n",
      "    Batch 41 / 324\n",
      "    Batch 42 / 324\n",
      "    Batch 43 / 324\n",
      "    Batch 44 / 324\n",
      "    Batch 45 / 324\n",
      "    Batch 46 / 324\n",
      "    Batch 47 / 324\n",
      "    Batch 48 / 324\n",
      "    Batch 49 / 324\n",
      "    Batch 50 / 324\n",
      "    Batch 51 / 324\n",
      "    Batch 52 / 324\n",
      "    Batch 53 / 324\n",
      "    Batch 54 / 324\n",
      "    Batch 55 / 324\n",
      "    Batch 56 / 324\n",
      "    Batch 57 / 324\n",
      "    Batch 58 / 324\n",
      "    Batch 59 / 324\n",
      "    Batch 60 / 324\n",
      "    Batch 61 / 324\n",
      "    Batch 62 / 324\n",
      "    Batch 63 / 324\n",
      "    Batch 64 / 324\n",
      "    Batch 65 / 324\n",
      "    Batch 66 / 324\n",
      "    Batch 67 / 324\n",
      "    Batch 68 / 324\n",
      "    Batch 69 / 324\n",
      "    Batch 70 / 324\n",
      "    Batch 71 / 324\n",
      "    Batch 72 / 324\n",
      "    Batch 73 / 324\n",
      "    Batch 74 / 324\n",
      "    Batch 75 / 324\n",
      "    Batch 76 / 324\n",
      "    Batch 77 / 324\n",
      "    Batch 78 / 324\n",
      "    Batch 79 / 324\n",
      "    Batch 80 / 324\n",
      "    Batch 81 / 324\n",
      "    Batch 82 / 324\n",
      "    Batch 83 / 324\n",
      "    Batch 84 / 324\n",
      "    Batch 85 / 324\n",
      "    Batch 86 / 324\n",
      "    Batch 87 / 324\n",
      "    Batch 88 / 324\n",
      "    Batch 89 / 324\n",
      "    Batch 90 / 324\n",
      "    Batch 91 / 324\n",
      "    Batch 92 / 324\n",
      "    Batch 93 / 324\n",
      "    Batch 94 / 324\n",
      "    Batch 95 / 324\n",
      "    Batch 96 / 324\n",
      "    Batch 97 / 324\n",
      "    Batch 98 / 324\n",
      "    Batch 99 / 324\n",
      "    Batch 100 / 324\n",
      "    Batch 101 / 324\n",
      "    Batch 102 / 324\n",
      "    Batch 103 / 324\n",
      "    Batch 104 / 324\n",
      "    Batch 105 / 324\n",
      "    Batch 106 / 324\n",
      "    Batch 107 / 324\n",
      "    Batch 108 / 324\n",
      "    Batch 109 / 324\n",
      "    Batch 110 / 324\n",
      "    Batch 111 / 324\n",
      "    Batch 112 / 324\n",
      "    Batch 113 / 324\n",
      "    Batch 114 / 324\n",
      "    Batch 115 / 324\n",
      "    Batch 116 / 324\n",
      "    Batch 117 / 324\n",
      "    Batch 118 / 324\n",
      "    Batch 119 / 324\n",
      "    Batch 120 / 324\n",
      "    Batch 121 / 324\n",
      "    Batch 122 / 324\n",
      "    Batch 123 / 324\n",
      "    Batch 124 / 324\n",
      "    Batch 125 / 324\n",
      "    Batch 126 / 324\n",
      "    Batch 127 / 324\n",
      "    Batch 128 / 324\n",
      "    Batch 129 / 324\n",
      "    Batch 130 / 324\n",
      "    Batch 131 / 324\n",
      "    Batch 132 / 324\n",
      "    Batch 133 / 324\n",
      "    Batch 134 / 324\n",
      "    Batch 135 / 324\n",
      "    Batch 136 / 324\n",
      "    Batch 137 / 324\n",
      "    Batch 138 / 324\n",
      "    Batch 139 / 324\n",
      "    Batch 140 / 324\n",
      "    Batch 141 / 324\n",
      "    Batch 142 / 324\n",
      "    Batch 143 / 324\n",
      "    Batch 144 / 324\n",
      "    Batch 145 / 324\n",
      "    Batch 146 / 324\n",
      "    Batch 147 / 324\n",
      "    Batch 148 / 324\n",
      "    Batch 149 / 324\n",
      "    Batch 150 / 324\n",
      "    Batch 151 / 324\n",
      "    Batch 152 / 324\n",
      "    Batch 153 / 324\n",
      "    Batch 154 / 324\n",
      "    Batch 155 / 324\n",
      "    Batch 156 / 324\n",
      "    Batch 157 / 324\n",
      "    Batch 158 / 324\n",
      "    Batch 159 / 324\n",
      "    Batch 160 / 324\n",
      "    Batch 161 / 324\n",
      "    Batch 162 / 324\n",
      "    Batch 163 / 324\n",
      "    Batch 164 / 324\n",
      "    Batch 165 / 324\n",
      "    Batch 166 / 324\n",
      "    Batch 167 / 324\n",
      "    Batch 168 / 324\n",
      "    Batch 169 / 324\n",
      "    Batch 170 / 324\n",
      "    Batch 171 / 324\n",
      "    Batch 172 / 324\n",
      "    Batch 173 / 324\n",
      "    Batch 174 / 324\n",
      "    Batch 175 / 324\n",
      "    Batch 176 / 324\n",
      "    Batch 177 / 324\n",
      "    Batch 178 / 324\n",
      "    Batch 179 / 324\n",
      "    Batch 180 / 324\n",
      "    Batch 181 / 324\n",
      "    Batch 182 / 324\n",
      "    Batch 183 / 324\n",
      "    Batch 184 / 324\n",
      "    Batch 185 / 324\n",
      "    Batch 186 / 324\n",
      "    Batch 187 / 324\n",
      "    Batch 188 / 324\n",
      "    Batch 189 / 324\n",
      "    Batch 190 / 324\n",
      "    Batch 191 / 324\n",
      "    Batch 192 / 324\n",
      "    Batch 193 / 324\n",
      "    Batch 194 / 324\n",
      "    Batch 195 / 324\n",
      "    Batch 196 / 324\n",
      "    Batch 197 / 324\n",
      "    Batch 198 / 324\n",
      "    Batch 199 / 324\n",
      "    Batch 200 / 324\n",
      "    Batch 201 / 324\n",
      "    Batch 202 / 324\n",
      "    Batch 203 / 324\n",
      "    Batch 204 / 324\n",
      "    Batch 205 / 324\n",
      "    Batch 206 / 324\n",
      "    Batch 207 / 324\n",
      "    Batch 208 / 324\n",
      "    Batch 209 / 324\n",
      "    Batch 210 / 324\n",
      "    Batch 211 / 324\n",
      "    Batch 212 / 324\n",
      "    Batch 213 / 324\n",
      "    Batch 214 / 324\n",
      "    Batch 215 / 324\n",
      "    Batch 216 / 324\n",
      "    Batch 217 / 324\n",
      "    Batch 218 / 324\n",
      "    Batch 219 / 324\n",
      "    Batch 220 / 324\n",
      "    Batch 221 / 324\n",
      "    Batch 222 / 324\n",
      "    Batch 223 / 324\n",
      "    Batch 224 / 324\n",
      "    Batch 225 / 324\n",
      "    Batch 226 / 324\n",
      "    Batch 227 / 324\n",
      "    Batch 228 / 324\n",
      "    Batch 229 / 324\n",
      "    Batch 230 / 324\n",
      "    Batch 231 / 324\n",
      "    Batch 232 / 324\n",
      "    Batch 233 / 324\n",
      "    Batch 234 / 324\n",
      "    Batch 235 / 324\n",
      "    Batch 236 / 324\n",
      "    Batch 237 / 324\n",
      "    Batch 238 / 324\n",
      "    Batch 239 / 324\n",
      "    Batch 240 / 324\n",
      "    Batch 241 / 324\n",
      "    Batch 242 / 324\n",
      "    Batch 243 / 324\n",
      "    Batch 244 / 324\n",
      "    Batch 245 / 324\n",
      "    Batch 246 / 324\n",
      "    Batch 247 / 324\n",
      "    Batch 248 / 324\n",
      "    Batch 249 / 324\n",
      "    Batch 250 / 324\n",
      "    Batch 251 / 324\n",
      "    Batch 252 / 324\n",
      "    Batch 253 / 324\n",
      "    Batch 254 / 324\n",
      "    Batch 255 / 324\n",
      "    Batch 256 / 324\n",
      "    Batch 257 / 324\n",
      "    Batch 258 / 324\n",
      "    Batch 259 / 324\n",
      "    Batch 260 / 324\n",
      "    Batch 261 / 324\n",
      "    Batch 262 / 324\n",
      "    Batch 263 / 324\n",
      "    Batch 264 / 324\n",
      "    Batch 265 / 324\n",
      "    Batch 266 / 324\n",
      "    Batch 267 / 324\n",
      "    Batch 268 / 324\n",
      "    Batch 269 / 324\n",
      "    Batch 270 / 324\n",
      "    Batch 271 / 324\n",
      "    Batch 272 / 324\n",
      "    Batch 273 / 324\n",
      "    Batch 274 / 324\n",
      "    Batch 275 / 324\n",
      "    Batch 276 / 324\n",
      "    Batch 277 / 324\n",
      "    Batch 278 / 324\n",
      "    Batch 279 / 324\n",
      "    Batch 280 / 324\n",
      "    Batch 281 / 324\n",
      "    Batch 282 / 324\n",
      "    Batch 283 / 324\n",
      "    Batch 284 / 324\n",
      "    Batch 285 / 324\n",
      "    Batch 286 / 324\n",
      "    Batch 287 / 324\n",
      "    Batch 288 / 324\n",
      "    Batch 289 / 324\n",
      "    Batch 290 / 324\n",
      "    Batch 291 / 324\n",
      "    Batch 292 / 324\n",
      "    Batch 293 / 324\n",
      "    Batch 294 / 324\n",
      "    Batch 295 / 324\n",
      "    Batch 296 / 324\n",
      "    Batch 297 / 324\n",
      "    Batch 298 / 324\n",
      "    Batch 299 / 324\n",
      "    Batch 300 / 324\n",
      "    Batch 301 / 324\n",
      "    Batch 302 / 324\n",
      "    Batch 303 / 324\n",
      "    Batch 304 / 324\n",
      "    Batch 305 / 324\n",
      "    Batch 306 / 324\n",
      "    Batch 307 / 324\n",
      "    Batch 308 / 324\n",
      "    Batch 309 / 324\n",
      "    Batch 310 / 324\n",
      "    Batch 311 / 324\n",
      "    Batch 312 / 324\n",
      "    Batch 313 / 324\n",
      "    Batch 314 / 324\n",
      "    Batch 315 / 324\n",
      "    Batch 316 / 324\n",
      "    Batch 317 / 324\n",
      "    Batch 318 / 324\n",
      "    Batch 319 / 324\n",
      "    Batch 320 / 324\n",
      "    Batch 321 / 324\n",
      "    Batch 322 / 324\n",
      "    Batch 323 / 324\n",
      "    Batch 324 / 324\n",
      "Threshold: 0.2843, accuracy: 0.7952\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.80      0.80      0.80      5181\n",
      "         1.0       0.80      0.80      0.80      5181\n",
      "\n",
      "    accuracy                           0.80     10362\n",
      "   macro avg       0.80      0.80      0.80     10362\n",
      "weighted avg       0.80      0.80      0.80     10362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().numpy())\n",
    "        y_pred.extend(predictions.detach().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-contacts_hypertext2009/ia-contacts_hypertext2009.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 113\n",
      "Number of static edges: 2096\n",
      "Number of temporal edges: 15613\n",
      "Number of examples/datapoints: 10362\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 324: loss 0.6056, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8139\n",
      "    Batch 6 / 324: loss 0.5310, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8826\n",
      "    Batch 9 / 324: loss 0.4481, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9750\n",
      "    Batch 12 / 324: loss 0.4469, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 15 / 324: loss 0.5885, accuracy 0.8021\n",
      "    ROC-AUC score: 0.9264\n",
      "    Batch 18 / 324: loss 0.5813, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9008\n",
      "    Batch 21 / 324: loss 0.4877, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 24 / 324: loss 0.5549, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9333\n",
      "    Batch 27 / 324: loss 0.5305, accuracy 0.8542\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 30 / 324: loss 0.4778, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8961\n",
      "    Batch 33 / 324: loss 0.5345, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8909\n",
      "    Batch 36 / 324: loss 0.5396, accuracy 0.7500\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 39 / 324: loss 0.4953, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 42 / 324: loss 0.4307, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9372\n",
      "    Batch 45 / 324: loss 0.5929, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9109\n",
      "    Batch 48 / 324: loss 0.5941, accuracy 0.7604\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 51 / 324: loss 0.5773, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 54 / 324: loss 0.6013, accuracy 0.7500\n",
      "    ROC-AUC score: 0.7583\n",
      "    Batch 57 / 324: loss 0.5299, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 60 / 324: loss 0.5613, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8945\n",
      "    Batch 63 / 324: loss 0.5186, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9059\n",
      "    Batch 66 / 324: loss 0.6064, accuracy 0.7812\n",
      "    ROC-AUC score: 0.7569\n",
      "    Batch 69 / 324: loss 0.5985, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8118\n",
      "    Batch 72 / 324: loss 0.5749, accuracy 0.7708\n",
      "    ROC-AUC score: 0.6667\n",
      "    Batch 75 / 324: loss 0.5105, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8984\n",
      "    Batch 78 / 324: loss 0.6071, accuracy 0.7083\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 81 / 324: loss 0.4831, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8294\n",
      "    Batch 84 / 324: loss 0.4722, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8988\n",
      "    Batch 87 / 324: loss 0.4819, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 90 / 324: loss 0.5844, accuracy 0.7604\n",
      "    ROC-AUC score: 0.7542\n",
      "    Batch 93 / 324: loss 0.5784, accuracy 0.7396\n",
      "    ROC-AUC score: 0.7965\n",
      "    Batch 96 / 324: loss 0.4712, accuracy 0.8958\n",
      "    ROC-AUC score: 0.9206\n",
      "    Batch 99 / 324: loss 0.5777, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 102 / 324: loss 0.4520, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8889\n",
      "    Batch 105 / 324: loss 0.5284, accuracy 0.7708\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 108 / 324: loss 0.4850, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 111 / 324: loss 0.4610, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8874\n",
      "    Batch 114 / 324: loss 0.4576, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9157\n",
      "    Batch 117 / 324: loss 0.4333, accuracy 0.7812\n",
      "    ROC-AUC score: 0.9255\n",
      "    Batch 120 / 324: loss 0.5345, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9405\n",
      "    Batch 123 / 324: loss 0.5108, accuracy 0.7812\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 126 / 324: loss 0.5976, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 129 / 324: loss 0.4715, accuracy 0.7812\n",
      "    ROC-AUC score: 0.7636\n",
      "    Batch 132 / 324: loss 0.4232, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9352\n",
      "    Batch 135 / 324: loss 0.4927, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 138 / 324: loss 0.4019, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9042\n",
      "    Batch 141 / 324: loss 0.5759, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 144 / 324: loss 0.4955, accuracy 0.8750\n",
      "    ROC-AUC score: 0.9864\n",
      "    Batch 147 / 324: loss 0.5956, accuracy 0.7188\n",
      "    ROC-AUC score: 0.6883\n",
      "    Batch 150 / 324: loss 0.4308, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9773\n",
      "    Batch 153 / 324: loss 0.4846, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 156 / 324: loss 0.5509, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8135\n",
      "    Batch 159 / 324: loss 0.5540, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8627\n",
      "    Batch 162 / 324: loss 0.4984, accuracy 0.7917\n",
      "    ROC-AUC score: 0.7778\n",
      "    Batch 165 / 324: loss 0.4961, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9805\n",
      "    Batch 168 / 324: loss 0.5150, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8492\n",
      "    Batch 171 / 324: loss 0.4440, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8510\n",
      "    Batch 174 / 324: loss 0.4728, accuracy 0.8125\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 177 / 324: loss 0.4612, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8785\n",
      "    Batch 180 / 324: loss 0.5681, accuracy 0.7083\n",
      "    ROC-AUC score: 0.7961\n",
      "    Batch 183 / 324: loss 0.5020, accuracy 0.8229\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 186 / 324: loss 0.5834, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8471\n",
      "    Batch 189 / 324: loss 0.5439, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 192 / 324: loss 0.5234, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8157\n",
      "    Batch 195 / 324: loss 0.5396, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8532\n",
      "    Batch 198 / 324: loss 0.4900, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 201 / 324: loss 0.4879, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9150\n",
      "    Batch 204 / 324: loss 0.4717, accuracy 0.8333\n",
      "    ROC-AUC score: 0.8941\n",
      "    Batch 207 / 324: loss 0.5163, accuracy 0.7396\n",
      "    ROC-AUC score: 0.9216\n",
      "    Batch 210 / 324: loss 0.5350, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8594\n",
      "    Batch 213 / 324: loss 0.5561, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9563\n",
      "    Batch 216 / 324: loss 0.4438, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9336\n",
      "    Batch 219 / 324: loss 0.4942, accuracy 0.8021\n",
      "    ROC-AUC score: 0.8500\n",
      "    Batch 222 / 324: loss 0.5158, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9176\n",
      "    Batch 225 / 324: loss 0.5040, accuracy 0.7708\n",
      "    ROC-AUC score: 0.8571\n",
      "    Batch 228 / 324: loss 0.5364, accuracy 0.7500\n",
      "    ROC-AUC score: 0.9125\n",
      "    Batch 231 / 324: loss 0.5812, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8947\n",
      "    Batch 234 / 324: loss 0.6041, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8175\n",
      "    Batch 237 / 324: loss 0.5637, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8398\n",
      "    Batch 240 / 324: loss 0.5175, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8824\n",
      "    Batch 243 / 324: loss 0.5342, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8292\n",
      "    Batch 246 / 324: loss 0.4756, accuracy 0.8542\n",
      "    ROC-AUC score: 0.9766\n",
      "    Batch 249 / 324: loss 0.5310, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 252 / 324: loss 0.4964, accuracy 0.8333\n",
      "    ROC-AUC score: 0.9647\n",
      "    Batch 255 / 324: loss 0.5172, accuracy 0.8125\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 258 / 324: loss 0.4699, accuracy 0.8854\n",
      "    ROC-AUC score: 0.8849\n",
      "    Batch 261 / 324: loss 0.4957, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9286\n",
      "    Batch 264 / 324: loss 0.4710, accuracy 0.8438\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 267 / 324: loss 0.5476, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8907\n",
      "    Batch 270 / 324: loss 0.5070, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8863\n",
      "    Batch 273 / 324: loss 0.5609, accuracy 0.7292\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 276 / 324: loss 0.5478, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8785\n",
      "    Batch 279 / 324: loss 0.5276, accuracy 0.7604\n",
      "    ROC-AUC score: 0.8254\n",
      "    Batch 282 / 324: loss 0.5171, accuracy 0.7917\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 285 / 324: loss 0.4516, accuracy 0.8646\n",
      "    ROC-AUC score: 0.8542\n",
      "    Batch 288 / 324: loss 0.5362, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8532\n",
      "    Batch 291 / 324: loss 0.4489, accuracy 0.8125\n",
      "    ROC-AUC score: 0.8907\n",
      "    Batch 294 / 324: loss 0.5379, accuracy 0.7708\n",
      "    ROC-AUC score: 0.7686\n",
      "    Batch 297 / 324: loss 0.5303, accuracy 0.8438\n",
      "    ROC-AUC score: 0.8555\n",
      "    Batch 300 / 324: loss 0.4536, accuracy 0.7917\n",
      "    ROC-AUC score: 0.9725\n",
      "    Batch 303 / 324: loss 0.4783, accuracy 0.8229\n",
      "    ROC-AUC score: 0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 306 / 324: loss 0.5842, accuracy 0.6979\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 309 / 324: loss 0.5252, accuracy 0.7500\n",
      "    ROC-AUC score: 0.8214\n",
      "    Batch 312 / 324: loss 0.4765, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 315 / 324: loss 0.5365, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8375\n",
      "    Batch 318 / 324: loss 0.5319, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8867\n",
      "    Batch 321 / 324: loss 0.4911, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8052\n",
      "    Batch 324 / 324: loss 0.5065, accuracy 0.8222\n",
      "    ROC-AUC score: 0.9333\n",
      "Loss 0.5182, accuracy 0.7895\n",
      "ROC-AUC score: 0.8692\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.78      0.79      5181\n",
      "         1.0       0.79      0.79      0.79      5181\n",
      "\n",
      "    accuracy                           0.79     10362\n",
      "   macro avg       0.79      0.79      0.79     10362\n",
      "weighted avg       0.79      0.79      0.79     10362\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().numpy())\n",
    "    y_scores.extend(scores.detach().numpy())\n",
    "    y_pred.extend(predictions.detach().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().numpy(), scores.detach().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
