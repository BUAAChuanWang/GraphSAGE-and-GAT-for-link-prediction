{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "src_path = os.path.join(os.path.dirname(os.path.abspath('')), 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "\n",
    "from datasets import link_prediction\n",
    "from layers import MeanAggregator, LSTMAggregator, MaxPoolAggregator, MeanPoolAggregator\n",
    "import models\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up arguments for datasets, models and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"task\" : \"link_prediction\",\n",
    "    \n",
    "    \"dataset\" : \"IAEnronEmployees\",\n",
    "    \"dataset_path\" : \"/Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\",\n",
    "    \"mode\" : \"train\",\n",
    "    \"generate_neg_examples\" : True,\n",
    "    \n",
    "    \"duplicate_examples\" : False,\n",
    "    \"repeat_examples\" : True,\n",
    "    \n",
    "    \"self_loop\" : True,\n",
    "    \"normalize_adj\" : False,\n",
    "    \n",
    "    \"cuda\" : True,\n",
    "    \"model\" : \"GraphSAGE\",\n",
    "    \"agg_class\" : \"MaxPoolAggregator\",\n",
    "    \"hidden_dims\" : [64],\n",
    "    \"dropout\" : 0,\n",
    "    \"num_samples\" : -1,\n",
    "    \n",
    "    \"epochs\" : 9,\n",
    "    \"batch_size\" : 32,\n",
    "    \"lr\" : 5e-4,\n",
    "    \"weight_decay\" : 5e-4,\n",
    "    \"stats_per_batch\" : 3,\n",
    "    \"visdom\" : True,\n",
    "    \n",
    "    \"load\" : False,\n",
    "    \"save\" : False\n",
    "}\n",
    "config = args\n",
    "config['num_layers'] = len(config['hidden_dims']) + 1\n",
    "\n",
    "if config['cuda'] and torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "config['device'] = device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset, dataloader and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: train\n",
      "Number of vertices: 151\n",
      "Number of static edges: 993\n",
      "Number of temporal edges: 18711\n",
      "Number of examples/datapoints: 2206\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'train',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=True, collate_fn=dataset.collate_wrapper)\n",
    "input_dim, output_dim = dataset.get_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GraphSAGE(\n",
      "  (aggregators): ModuleList(\n",
      "    (0): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=151, out_features=151, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (1): MaxPoolAggregator(\n",
      "      (fc1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (fcs): ModuleList(\n",
      "    (0): Linear(in_features=302, out_features=64, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (bns): ModuleList(\n",
      "    (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "agg_class = utils.get_agg_class(config['agg_class'])\n",
    "model = models.GraphSAGE(input_dim, config['hidden_dims'],\n",
    "                         output_dim, config['dropout'],\n",
    "                         agg_class, config['num_samples'],\n",
    "                         config['device'])\n",
    "model.to(config['device'])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score for the untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset before training.\n",
      "    Batch 1 / 69\n",
      "    Batch 2 / 69\n",
      "    Batch 3 / 69\n",
      "    Batch 4 / 69\n",
      "    Batch 5 / 69\n",
      "    Batch 6 / 69\n",
      "    Batch 7 / 69\n",
      "    Batch 8 / 69\n",
      "    Batch 9 / 69\n",
      "    Batch 10 / 69\n",
      "    Batch 11 / 69\n",
      "    Batch 12 / 69\n",
      "    Batch 13 / 69\n",
      "    Batch 14 / 69\n",
      "    Batch 15 / 69\n",
      "    Batch 16 / 69\n",
      "    Batch 17 / 69\n",
      "    Batch 18 / 69\n",
      "    Batch 19 / 69\n",
      "    Batch 20 / 69\n",
      "    Batch 21 / 69\n",
      "    Batch 22 / 69\n",
      "    Batch 23 / 69\n",
      "    Batch 24 / 69\n",
      "    Batch 25 / 69\n",
      "    Batch 26 / 69\n",
      "    Batch 27 / 69\n",
      "    Batch 28 / 69\n",
      "    Batch 29 / 69\n",
      "    Batch 30 / 69\n",
      "    Batch 31 / 69\n",
      "    Batch 32 / 69\n",
      "    Batch 33 / 69\n",
      "    Batch 34 / 69\n",
      "    Batch 35 / 69\n",
      "    Batch 36 / 69\n",
      "    Batch 37 / 69\n",
      "    Batch 38 / 69\n",
      "    Batch 39 / 69\n",
      "    Batch 40 / 69\n",
      "    Batch 41 / 69\n",
      "    Batch 42 / 69\n",
      "    Batch 43 / 69\n",
      "    Batch 44 / 69\n",
      "    Batch 45 / 69\n",
      "    Batch 46 / 69\n",
      "    Batch 47 / 69\n",
      "    Batch 48 / 69\n",
      "    Batch 49 / 69\n",
      "    Batch 50 / 69\n",
      "    Batch 51 / 69\n",
      "    Batch 52 / 69\n",
      "    Batch 53 / 69\n",
      "    Batch 54 / 69\n",
      "    Batch 55 / 69\n",
      "    Batch 56 / 69\n",
      "    Batch 57 / 69\n",
      "    Batch 58 / 69\n",
      "    Batch 59 / 69\n",
      "    Batch 60 / 69\n",
      "    Batch 61 / 69\n",
      "    Batch 62 / 69\n",
      "    Batch 63 / 69\n",
      "    Batch 64 / 69\n",
      "    Batch 65 / 69\n",
      "    Batch 66 / 69\n",
      "    Batch 67 / 69\n",
      "    Batch 68 / 69\n",
      "    Batch 69 / 69\n",
      "ROC-AUC score: 0.4862\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset before training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().cpu().numpy())\n",
    "            y_scores.extend(scores.detach().cpu().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Training.\n",
      "Epoch 1 / 9\n",
      "    Batch 3 / 69: loss 0.6938\n",
      "    ROC-AUC score: 0.3506\n",
      "    Batch 6 / 69: loss 0.6930\n",
      "    ROC-AUC score: 0.5142\n",
      "    Batch 9 / 69: loss 0.6934\n",
      "    ROC-AUC score: 0.2863\n",
      "    Batch 12 / 69: loss 0.6928\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 15 / 69: loss 0.6929\n",
      "    ROC-AUC score: 0.4841\n",
      "    Batch 18 / 69: loss 0.6928\n",
      "    ROC-AUC score: 0.7109\n",
      "    Batch 21 / 69: loss 0.6932\n",
      "    ROC-AUC score: 0.5352\n",
      "    Batch 24 / 69: loss 0.6929\n",
      "    ROC-AUC score: 0.3843\n",
      "    Batch 27 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.4534\n",
      "    Batch 30 / 69: loss 0.6926\n",
      "    ROC-AUC score: 0.4575\n",
      "    Batch 33 / 69: loss 0.6925\n",
      "    ROC-AUC score: 0.4219\n",
      "    Batch 36 / 69: loss 0.6919\n",
      "    ROC-AUC score: 0.6235\n",
      "    Batch 39 / 69: loss 0.6926\n",
      "    ROC-AUC score: 0.6923\n",
      "    Batch 42 / 69: loss 0.6908\n",
      "    ROC-AUC score: 0.7461\n",
      "    Batch 45 / 69: loss 0.6893\n",
      "    ROC-AUC score: 0.5583\n",
      "    Batch 48 / 69: loss 0.6887\n",
      "    ROC-AUC score: 0.7529\n",
      "    Batch 51 / 69: loss 0.6894\n",
      "    ROC-AUC score: 0.6431\n",
      "    Batch 54 / 69: loss 0.6909\n",
      "    ROC-AUC score: 0.7166\n",
      "    Batch 57 / 69: loss 0.6859\n",
      "    ROC-AUC score: 0.6468\n",
      "    Batch 60 / 69: loss 0.6840\n",
      "    ROC-AUC score: 0.7750\n",
      "    Batch 63 / 69: loss 0.6825\n",
      "    ROC-AUC score: 0.7500\n",
      "    Batch 66 / 69: loss 0.6834\n",
      "    ROC-AUC score: 0.5216\n",
      "    Batch 69 / 69: loss 0.6835\n",
      "    ROC-AUC score: 0.6875\n",
      "Epoch 2 / 9\n",
      "    Batch 3 / 69: loss 0.6931\n",
      "    ROC-AUC score: 0.6715\n",
      "    Batch 6 / 69: loss 0.6778\n",
      "    ROC-AUC score: 0.6836\n",
      "    Batch 9 / 69: loss 0.6619\n",
      "    ROC-AUC score: 0.9177\n",
      "    Batch 12 / 69: loss 0.6769\n",
      "    ROC-AUC score: 0.6375\n",
      "    Batch 15 / 69: loss 0.6659\n",
      "    ROC-AUC score: 0.7571\n",
      "    Batch 18 / 69: loss 0.6818\n",
      "    ROC-AUC score: 0.7686\n",
      "    Batch 21 / 69: loss 0.6488\n",
      "    ROC-AUC score: 0.7611\n",
      "    Batch 24 / 69: loss 0.6529\n",
      "    ROC-AUC score: 0.7368\n",
      "    Batch 27 / 69: loss 0.6675\n",
      "    ROC-AUC score: 0.6923\n",
      "    Batch 30 / 69: loss 0.6545\n",
      "    ROC-AUC score: 0.8583\n",
      "    Batch 33 / 69: loss 0.6369\n",
      "    ROC-AUC score: 0.9137\n",
      "    Batch 36 / 69: loss 0.6664\n",
      "    ROC-AUC score: 0.7937\n",
      "    Batch 39 / 69: loss 0.6743\n",
      "    ROC-AUC score: 0.6902\n",
      "    Batch 42 / 69: loss 0.6505\n",
      "    ROC-AUC score: 0.5794\n",
      "    Batch 45 / 69: loss 0.6636\n",
      "    ROC-AUC score: 0.8086\n",
      "    Batch 48 / 69: loss 0.6156\n",
      "    ROC-AUC score: 0.8225\n",
      "    Batch 51 / 69: loss 0.6684\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 54 / 69: loss 0.6665\n",
      "    ROC-AUC score: 0.7708\n",
      "    Batch 57 / 69: loss 0.6699\n",
      "    ROC-AUC score: 0.8138\n",
      "    Batch 60 / 69: loss 0.6614\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 63 / 69: loss 0.6448\n",
      "    ROC-AUC score: 0.8333\n",
      "    Batch 66 / 69: loss 0.6623\n",
      "    ROC-AUC score: 0.7059\n",
      "    Batch 69 / 69: loss 0.6456\n",
      "    ROC-AUC score: 0.6652\n",
      "Epoch 3 / 9\n",
      "    Batch 3 / 69: loss 0.6316\n",
      "    ROC-AUC score: 0.6836\n",
      "    Batch 6 / 69: loss 0.6229\n",
      "    ROC-AUC score: 0.7817\n",
      "    Batch 9 / 69: loss 0.6282\n",
      "    ROC-AUC score: 0.7542\n",
      "    Batch 12 / 69: loss 0.6124\n",
      "    ROC-AUC score: 0.6865\n",
      "    Batch 15 / 69: loss 0.6467\n",
      "    ROC-AUC score: 0.6055\n",
      "    Batch 18 / 69: loss 0.6000\n",
      "    ROC-AUC score: 0.7216\n",
      "    Batch 21 / 69: loss 0.6184\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 24 / 69: loss 0.5731\n",
      "    ROC-AUC score: 0.6721\n",
      "    Batch 27 / 69: loss 0.6384\n",
      "    ROC-AUC score: 0.6270\n",
      "    Batch 30 / 69: loss 0.6284\n",
      "    ROC-AUC score: 0.8615\n",
      "    Batch 33 / 69: loss 0.6275\n",
      "    ROC-AUC score: 0.8039\n",
      "    Batch 36 / 69: loss 0.5986\n",
      "    ROC-AUC score: 0.6406\n",
      "    Batch 39 / 69: loss 0.5781\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 42 / 69: loss 0.6376\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 45 / 69: loss 0.6426\n",
      "    ROC-AUC score: 0.7305\n",
      "    Batch 48 / 69: loss 0.6293\n",
      "    ROC-AUC score: 0.6599\n",
      "    Batch 51 / 69: loss 0.6352\n",
      "    ROC-AUC score: 0.8057\n",
      "    Batch 54 / 69: loss 0.6027\n",
      "    ROC-AUC score: 0.8502\n",
      "    Batch 57 / 69: loss 0.6532\n",
      "    ROC-AUC score: 0.6706\n",
      "    Batch 60 / 69: loss 0.6264\n",
      "    ROC-AUC score: 0.6667\n",
      "    Batch 63 / 69: loss 0.6018\n",
      "    ROC-AUC score: 0.7148\n",
      "    Batch 66 / 69: loss 0.5810\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 69 / 69: loss 0.6295\n",
      "    ROC-AUC score: 0.7454\n",
      "Epoch 4 / 9\n",
      "    Batch 3 / 69: loss 0.6089\n",
      "    ROC-AUC score: 0.6926\n",
      "    Batch 6 / 69: loss 0.6157\n",
      "    ROC-AUC score: 0.7733\n",
      "    Batch 9 / 69: loss 0.6137\n",
      "    ROC-AUC score: 0.7750\n",
      "    Batch 12 / 69: loss 0.5759\n",
      "    ROC-AUC score: 0.6914\n",
      "    Batch 15 / 69: loss 0.5567\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 18 / 69: loss 0.5966\n",
      "    ROC-AUC score: 0.7328\n",
      "    Batch 21 / 69: loss 0.5540\n",
      "    ROC-AUC score: 0.8833\n",
      "    Batch 24 / 69: loss 0.5668\n",
      "    ROC-AUC score: 0.7333\n",
      "    Batch 27 / 69: loss 0.5972\n",
      "    ROC-AUC score: 0.8569\n",
      "    Batch 30 / 69: loss 0.6685\n",
      "    ROC-AUC score: 0.6641\n",
      "    Batch 33 / 69: loss 0.5704\n",
      "    ROC-AUC score: 0.7681\n",
      "    Batch 36 / 69: loss 0.6034\n",
      "    ROC-AUC score: 0.6953\n",
      "    Batch 39 / 69: loss 0.6264\n",
      "    ROC-AUC score: 0.8078\n",
      "    Batch 42 / 69: loss 0.5661\n",
      "    ROC-AUC score: 0.7031\n",
      "    Batch 45 / 69: loss 0.5764\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 48 / 69: loss 0.5655\n",
      "    ROC-AUC score: 0.7262\n",
      "    Batch 51 / 69: loss 0.5393\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 54 / 69: loss 0.5410\n",
      "    ROC-AUC score: 0.7341\n",
      "    Batch 57 / 69: loss 0.5697\n",
      "    ROC-AUC score: 0.6836\n",
      "    Batch 60 / 69: loss 0.6269\n",
      "    ROC-AUC score: 0.8667\n",
      "    Batch 63 / 69: loss 0.5826\n",
      "    ROC-AUC score: 0.8235\n",
      "    Batch 66 / 69: loss 0.5997\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 69 / 69: loss 0.6397\n",
      "    ROC-AUC score: 0.7200\n",
      "Epoch 5 / 9\n",
      "    Batch 3 / 69: loss 0.5737\n",
      "    ROC-AUC score: 0.8381\n",
      "    Batch 6 / 69: loss 0.5463\n",
      "    ROC-AUC score: 0.8745\n",
      "    Batch 9 / 69: loss 0.6420\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 12 / 69: loss 0.5462\n",
      "    ROC-AUC score: 0.8381\n",
      "    Batch 15 / 69: loss 0.6473\n",
      "    ROC-AUC score: 0.6682\n",
      "    Batch 18 / 69: loss 0.5859\n",
      "    ROC-AUC score: 0.6980\n",
      "    Batch 21 / 69: loss 0.5794\n",
      "    ROC-AUC score: 0.7422\n",
      "    Batch 24 / 69: loss 0.6323\n",
      "    ROC-AUC score: 0.6824\n",
      "    Batch 27 / 69: loss 0.5851\n",
      "    ROC-AUC score: 0.8083\n",
      "    Batch 30 / 69: loss 0.5376\n",
      "    ROC-AUC score: 0.8016\n",
      "    Batch 33 / 69: loss 0.5168\n",
      "    ROC-AUC score: 0.9020\n",
      "    Batch 36 / 69: loss 0.4982\n",
      "    ROC-AUC score: 0.8826\n",
      "    Batch 39 / 69: loss 0.4904\n",
      "    ROC-AUC score: 0.8042\n",
      "    Batch 42 / 69: loss 0.5411\n",
      "    ROC-AUC score: 0.7166\n",
      "    Batch 45 / 69: loss 0.6326\n",
      "    ROC-AUC score: 0.6073\n",
      "    Batch 48 / 69: loss 0.5657\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 51 / 69: loss 0.5442\n",
      "    ROC-AUC score: 0.8442\n",
      "    Batch 54 / 69: loss 0.5038\n",
      "    ROC-AUC score: 0.9294\n",
      "    Batch 57 / 69: loss 0.5914\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 60 / 69: loss 0.5689\n",
      "    ROC-AUC score: 0.8452\n",
      "    Batch 63 / 69: loss 0.6018\n",
      "    ROC-AUC score: 0.6431\n",
      "    Batch 66 / 69: loss 0.6708\n",
      "    ROC-AUC score: 0.7176\n",
      "    Batch 69 / 69: loss 0.5632\n",
      "    ROC-AUC score: 0.7946\n",
      "Epoch 6 / 9\n",
      "    Batch 3 / 69: loss 0.4960\n",
      "    ROC-AUC score: 0.6559\n",
      "    Batch 6 / 69: loss 0.5117\n",
      "    ROC-AUC score: 0.8314\n",
      "    Batch 9 / 69: loss 0.5525\n",
      "    ROC-AUC score: 0.7854\n",
      "    Batch 12 / 69: loss 0.5392\n",
      "    ROC-AUC score: 0.9484\n",
      "    Batch 15 / 69: loss 0.5697\n",
      "    ROC-AUC score: 0.7897\n",
      "    Batch 18 / 69: loss 0.5908\n",
      "    ROC-AUC score: 0.7976\n",
      "    Batch 21 / 69: loss 0.5411\n",
      "    ROC-AUC score: 0.8359\n",
      "    Batch 24 / 69: loss 0.6039\n",
      "    ROC-AUC score: 0.7692\n",
      "    Batch 27 / 69: loss 0.5526\n",
      "    ROC-AUC score: 0.7579\n",
      "    Batch 30 / 69: loss 0.6057\n",
      "    ROC-AUC score: 0.8214\n",
      "    Batch 33 / 69: loss 0.4976\n",
      "    ROC-AUC score: 0.8706\n",
      "    Batch 36 / 69: loss 0.5477\n",
      "    ROC-AUC score: 0.6761\n",
      "    Batch 39 / 69: loss 0.5710\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 42 / 69: loss 0.5191\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 45 / 69: loss 0.5798\n",
      "    ROC-AUC score: 0.9393\n",
      "    Batch 48 / 69: loss 0.5546\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 51 / 69: loss 0.5895\n",
      "    ROC-AUC score: 0.8750\n",
      "    Batch 54 / 69: loss 0.5901\n",
      "    ROC-AUC score: 0.6111\n",
      "    Batch 57 / 69: loss 0.5445\n",
      "    ROC-AUC score: 0.7969\n",
      "    Batch 60 / 69: loss 0.5974\n",
      "    ROC-AUC score: 0.8175\n",
      "    Batch 63 / 69: loss 0.6164\n",
      "    ROC-AUC score: 0.7403\n",
      "    Batch 66 / 69: loss 0.5764\n",
      "    ROC-AUC score: 0.7273\n",
      "    Batch 69 / 69: loss 0.6050\n",
      "    ROC-AUC score: 0.6250\n",
      "Epoch 7 / 9\n",
      "    Batch 3 / 69: loss 0.5515\n",
      "    ROC-AUC score: 0.7662\n",
      "    Batch 6 / 69: loss 0.5210\n",
      "    ROC-AUC score: 0.7792\n",
      "    Batch 9 / 69: loss 0.5763\n",
      "    ROC-AUC score: 0.8009\n",
      "    Batch 12 / 69: loss 0.5138\n",
      "    ROC-AUC score: 0.8196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 15 / 69: loss 0.5131\n",
      "    ROC-AUC score: 0.8421\n",
      "    Batch 18 / 69: loss 0.5461\n",
      "    ROC-AUC score: 0.8340\n",
      "    Batch 21 / 69: loss 0.4725\n",
      "    ROC-AUC score: 0.9102\n",
      "    Batch 24 / 69: loss 0.5213\n",
      "    ROC-AUC score: 0.8136\n",
      "    Batch 27 / 69: loss 0.5595\n",
      "    ROC-AUC score: 0.8664\n",
      "    Batch 30 / 69: loss 0.5429\n",
      "    ROC-AUC score: 0.8214\n",
      "    Batch 33 / 69: loss 0.6428\n",
      "    ROC-AUC score: 0.7579\n",
      "    Batch 36 / 69: loss 0.5221\n",
      "    ROC-AUC score: 0.8375\n",
      "    Batch 39 / 69: loss 0.5951\n",
      "    ROC-AUC score: 0.8219\n",
      "    Batch 42 / 69: loss 0.4984\n",
      "    ROC-AUC score: 0.8413\n",
      "    Batch 45 / 69: loss 0.6780\n",
      "    ROC-AUC score: 0.7698\n",
      "    Batch 48 / 69: loss 0.5135\n",
      "    ROC-AUC score: 0.9531\n",
      "    Batch 51 / 69: loss 0.6514\n",
      "    ROC-AUC score: 0.7222\n",
      "    Batch 54 / 69: loss 0.5903\n",
      "    ROC-AUC score: 0.7020\n",
      "    Batch 57 / 69: loss 0.5434\n",
      "    ROC-AUC score: 0.8431\n",
      "    Batch 60 / 69: loss 0.5283\n",
      "    ROC-AUC score: 0.8242\n",
      "    Batch 63 / 69: loss 0.6380\n",
      "    ROC-AUC score: 0.6316\n",
      "    Batch 66 / 69: loss 0.5656\n",
      "    ROC-AUC score: 0.7540\n",
      "    Batch 69 / 69: loss 0.5563\n",
      "    ROC-AUC score: 0.8307\n",
      "Epoch 8 / 9\n",
      "    Batch 3 / 69: loss 0.5627\n",
      "    ROC-AUC score: 0.8178\n",
      "    Batch 6 / 69: loss 0.5571\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 9 / 69: loss 0.6133\n",
      "    ROC-AUC score: 0.8008\n",
      "    Batch 12 / 69: loss 0.6017\n",
      "    ROC-AUC score: 0.7373\n",
      "    Batch 15 / 69: loss 0.5409\n",
      "    ROC-AUC score: 0.8008\n",
      "    Batch 18 / 69: loss 0.4557\n",
      "    ROC-AUC score: 0.9312\n",
      "    Batch 21 / 69: loss 0.5484\n",
      "    ROC-AUC score: 0.7412\n",
      "    Batch 24 / 69: loss 0.5627\n",
      "    ROC-AUC score: 0.9423\n",
      "    Batch 27 / 69: loss 0.5911\n",
      "    ROC-AUC score: 0.9451\n",
      "    Batch 30 / 69: loss 0.5031\n",
      "    ROC-AUC score: 0.9062\n",
      "    Batch 33 / 69: loss 0.5592\n",
      "    ROC-AUC score: 0.7344\n",
      "    Batch 36 / 69: loss 0.6474\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 39 / 69: loss 0.5103\n",
      "    ROC-AUC score: 0.8097\n",
      "    Batch 42 / 69: loss 0.4824\n",
      "    ROC-AUC score: 0.8907\n",
      "    Batch 45 / 69: loss 0.6159\n",
      "    ROC-AUC score: 0.6710\n",
      "    Batch 48 / 69: loss 0.5197\n",
      "    ROC-AUC score: 0.9000\n",
      "    Batch 51 / 69: loss 0.5758\n",
      "    ROC-AUC score: 0.7292\n",
      "    Batch 54 / 69: loss 0.5579\n",
      "    ROC-AUC score: 0.6825\n",
      "    Batch 57 / 69: loss 0.5787\n",
      "    ROC-AUC score: 0.8730\n",
      "    Batch 60 / 69: loss 0.5547\n",
      "    ROC-AUC score: 0.8770\n",
      "    Batch 63 / 69: loss 0.5499\n",
      "    ROC-AUC score: 0.9307\n",
      "    Batch 66 / 69: loss 0.5108\n",
      "    ROC-AUC score: 0.7935\n",
      "    Batch 69 / 69: loss 0.5572\n",
      "    ROC-AUC score: 0.7822\n",
      "Epoch 9 / 9\n",
      "    Batch 3 / 69: loss 0.5210\n",
      "    ROC-AUC score: 0.7692\n",
      "    Batch 6 / 69: loss 0.5749\n",
      "    ROC-AUC score: 0.6389\n",
      "    Batch 9 / 69: loss 0.5144\n",
      "    ROC-AUC score: 0.8413\n",
      "    Batch 12 / 69: loss 0.5189\n",
      "    ROC-AUC score: 0.7647\n",
      "    Batch 15 / 69: loss 0.5496\n",
      "    ROC-AUC score: 0.6349\n",
      "    Batch 18 / 69: loss 0.5589\n",
      "    ROC-AUC score: 0.9098\n",
      "    Batch 21 / 69: loss 0.5283\n",
      "    ROC-AUC score: 0.8381\n",
      "    Batch 24 / 69: loss 0.5671\n",
      "    ROC-AUC score: 0.8039\n",
      "    Batch 27 / 69: loss 0.5624\n",
      "    ROC-AUC score: 0.8727\n",
      "    Batch 30 / 69: loss 0.6019\n",
      "    ROC-AUC score: 0.9048\n",
      "    Batch 33 / 69: loss 0.5524\n",
      "    ROC-AUC score: 0.8902\n",
      "    Batch 36 / 69: loss 0.5231\n",
      "    ROC-AUC score: 0.7958\n",
      "    Batch 39 / 69: loss 0.5402\n",
      "    ROC-AUC score: 0.8208\n",
      "    Batch 42 / 69: loss 0.5321\n",
      "    ROC-AUC score: 0.8701\n",
      "    Batch 45 / 69: loss 0.5338\n",
      "    ROC-AUC score: 0.6667\n",
      "    Batch 48 / 69: loss 0.5162\n",
      "    ROC-AUC score: 0.8095\n",
      "    Batch 51 / 69: loss 0.5601\n",
      "    ROC-AUC score: 0.8138\n",
      "    Batch 54 / 69: loss 0.6721\n",
      "    ROC-AUC score: 0.8135\n",
      "    Batch 57 / 69: loss 0.5418\n",
      "    ROC-AUC score: 0.8627\n",
      "    Batch 60 / 69: loss 0.5522\n",
      "    ROC-AUC score: 0.7540\n",
      "    Batch 63 / 69: loss 0.6059\n",
      "    ROC-AUC score: 0.6250\n",
      "    Batch 66 / 69: loss 0.5232\n",
      "    ROC-AUC score: 0.8583\n",
      "    Batch 69 / 69: loss 0.5658\n",
      "    ROC-AUC score: 0.8036\n",
      "Finished training.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    use_visdom = config['visdom']\n",
    "    if use_visdom:\n",
    "        vis = visdom.Visdom()\n",
    "        loss_window = None\n",
    "    criterion = utils.get_criterion(config['task'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'],\n",
    "                           weight_decay=config['weight_decay'])\n",
    "    epochs = config['epochs']\n",
    "    stats_per_batch = config['stats_per_batch']\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    # scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.8)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[300, 600], gamma=0.5)\n",
    "    model.train()\n",
    "    print('--------------------------------')\n",
    "    print('Training.')\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch {} / {}'.format(epoch+1, epochs))\n",
    "        running_loss = 0.0\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            loss = criterion(scores, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                running_loss += loss.item()\n",
    "            if (idx + 1) % stats_per_batch == 0:\n",
    "                running_loss /= stats_per_batch\n",
    "                print('    Batch {} / {}: loss {:.4f}'.format(\n",
    "                    idx+1, num_batches, running_loss))\n",
    "                if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "                    area = roc_auc_score(labels.detach().cpu().numpy(), scores.detach().cpu().numpy())\n",
    "                    print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "                running_loss = 0.0\n",
    "                num_correct, num_examples = 0, 0\n",
    "            if use_visdom:\n",
    "                if loss_window is None:\n",
    "                    loss_window = vis.line(\n",
    "                        Y=[loss.item()],\n",
    "                        X=[epoch*num_batches+idx],\n",
    "                        opts=dict(xlabel='batch', ylabel='Loss', title='Training Loss', legend=['Loss']))\n",
    "                else:\n",
    "                    vis.line(\n",
    "                        [loss.item()],\n",
    "                        [epoch*num_batches+idx],\n",
    "                        win=loss_window,\n",
    "                        update='append')\n",
    "            scheduler.step()\n",
    "    if use_visdom:\n",
    "        vis.close(win=loss_window)\n",
    "    print('Finished training.')\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config['load']:\n",
    "    if config['save']:\n",
    "        print('--------------------------------')\n",
    "        directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                                'trained_models')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        fname = utils.get_fname(config)\n",
    "        path = os.path.join(directory, fname)\n",
    "        print('Saving model at {}'.format(path))\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print('Finished saving model.')\n",
    "        print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute ROC-AUC score after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Computing ROC-AUC score for the training dataset after training.\n",
      "    Batch 1 / 69\n",
      "    Batch 2 / 69\n",
      "    Batch 3 / 69\n",
      "    Batch 4 / 69\n",
      "    Batch 5 / 69\n",
      "    Batch 6 / 69\n",
      "    Batch 7 / 69\n",
      "    Batch 8 / 69\n",
      "    Batch 9 / 69\n",
      "    Batch 10 / 69\n",
      "    Batch 11 / 69\n",
      "    Batch 12 / 69\n",
      "    Batch 13 / 69\n",
      "    Batch 14 / 69\n",
      "    Batch 15 / 69\n",
      "    Batch 16 / 69\n",
      "    Batch 17 / 69\n",
      "    Batch 18 / 69\n",
      "    Batch 19 / 69\n",
      "    Batch 20 / 69\n",
      "    Batch 21 / 69\n",
      "    Batch 22 / 69\n",
      "    Batch 23 / 69\n",
      "    Batch 24 / 69\n",
      "    Batch 25 / 69\n",
      "    Batch 26 / 69\n",
      "    Batch 27 / 69\n",
      "    Batch 28 / 69\n",
      "    Batch 29 / 69\n",
      "    Batch 30 / 69\n",
      "    Batch 31 / 69\n",
      "    Batch 32 / 69\n",
      "    Batch 33 / 69\n",
      "    Batch 34 / 69\n",
      "    Batch 35 / 69\n",
      "    Batch 36 / 69\n",
      "    Batch 37 / 69\n",
      "    Batch 38 / 69\n",
      "    Batch 39 / 69\n",
      "    Batch 40 / 69\n",
      "    Batch 41 / 69\n",
      "    Batch 42 / 69\n",
      "    Batch 43 / 69\n",
      "    Batch 44 / 69\n",
      "    Batch 45 / 69\n",
      "    Batch 46 / 69\n",
      "    Batch 47 / 69\n",
      "    Batch 48 / 69\n",
      "    Batch 49 / 69\n",
      "    Batch 50 / 69\n",
      "    Batch 51 / 69\n",
      "    Batch 52 / 69\n",
      "    Batch 53 / 69\n",
      "    Batch 54 / 69\n",
      "    Batch 55 / 69\n",
      "    Batch 56 / 69\n",
      "    Batch 57 / 69\n",
      "    Batch 58 / 69\n",
      "    Batch 59 / 69\n",
      "    Batch 60 / 69\n",
      "    Batch 61 / 69\n",
      "    Batch 62 / 69\n",
      "    Batch 63 / 69\n",
      "    Batch 64 / 69\n",
      "    Batch 65 / 69\n",
      "    Batch 66 / 69\n",
      "    Batch 67 / 69\n",
      "    Batch 68 / 69\n",
      "    Batch 69 / 69\n",
      "ROC-AUC score: 0.8168\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    print('--------------------------------')\n",
    "    print('Computing ROC-AUC score for the training dataset after training.')\n",
    "    y_true, y_scores = [], []\n",
    "    num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "    with torch.no_grad():\n",
    "        for (idx, batch) in enumerate(loader):\n",
    "            edges, features, node_layers, mappings, rows, labels = batch\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            out = model(features, node_layers, mappings, rows)\n",
    "            all_pairs = torch.mm(out, out.t())\n",
    "            scores = all_pairs[edges.T]\n",
    "            y_true.extend(labels.detach().cpu().numpy())\n",
    "            y_scores.extend(scores.detach().cpu().numpy())\n",
    "            print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_scores = np.array(y_scores).flatten()\n",
    "    area = roc_auc_score(y_true, y_scores)\n",
    "    print('ROC-AUC score: {:.4f}'.format(area))\n",
    "    print('--------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the true positive rate and true negative rate vs threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not config['load']:\n",
    "    tpr, fpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    tnr = 1 - fpr\n",
    "    plt.plot(thresholds, tpr, label='tpr')\n",
    "    plt.plot(thresholds, tnr, label='tnr')\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.title('TPR / TNR vs Threshold')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose an appropriate threshold and generate classification report on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Batch 1 / 69\n",
      "    Batch 2 / 69\n",
      "    Batch 3 / 69\n",
      "    Batch 4 / 69\n",
      "    Batch 5 / 69\n",
      "    Batch 6 / 69\n",
      "    Batch 7 / 69\n",
      "    Batch 8 / 69\n",
      "    Batch 9 / 69\n",
      "    Batch 10 / 69\n",
      "    Batch 11 / 69\n",
      "    Batch 12 / 69\n",
      "    Batch 13 / 69\n",
      "    Batch 14 / 69\n",
      "    Batch 15 / 69\n",
      "    Batch 16 / 69\n",
      "    Batch 17 / 69\n",
      "    Batch 18 / 69\n",
      "    Batch 19 / 69\n",
      "    Batch 20 / 69\n",
      "    Batch 21 / 69\n",
      "    Batch 22 / 69\n",
      "    Batch 23 / 69\n",
      "    Batch 24 / 69\n",
      "    Batch 25 / 69\n",
      "    Batch 26 / 69\n",
      "    Batch 27 / 69\n",
      "    Batch 28 / 69\n",
      "    Batch 29 / 69\n",
      "    Batch 30 / 69\n",
      "    Batch 31 / 69\n",
      "    Batch 32 / 69\n",
      "    Batch 33 / 69\n",
      "    Batch 34 / 69\n",
      "    Batch 35 / 69\n",
      "    Batch 36 / 69\n",
      "    Batch 37 / 69\n",
      "    Batch 38 / 69\n",
      "    Batch 39 / 69\n",
      "    Batch 40 / 69\n",
      "    Batch 41 / 69\n",
      "    Batch 42 / 69\n",
      "    Batch 43 / 69\n",
      "    Batch 44 / 69\n",
      "    Batch 45 / 69\n",
      "    Batch 46 / 69\n",
      "    Batch 47 / 69\n",
      "    Batch 48 / 69\n",
      "    Batch 49 / 69\n",
      "    Batch 50 / 69\n",
      "    Batch 51 / 69\n",
      "    Batch 52 / 69\n",
      "    Batch 53 / 69\n",
      "    Batch 54 / 69\n",
      "    Batch 55 / 69\n",
      "    Batch 56 / 69\n",
      "    Batch 57 / 69\n",
      "    Batch 58 / 69\n",
      "    Batch 59 / 69\n",
      "    Batch 60 / 69\n",
      "    Batch 61 / 69\n",
      "    Batch 62 / 69\n",
      "    Batch 63 / 69\n",
      "    Batch 64 / 69\n",
      "    Batch 65 / 69\n",
      "    Batch 66 / 69\n",
      "    Batch 67 / 69\n",
      "    Batch 68 / 69\n",
      "    Batch 69 / 69\n",
      "Threshold: 0.2193, accuracy: 0.7244\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.72      0.72      1103\n",
      "         1.0       0.72      0.73      0.72      1103\n",
      "\n",
      "    accuracy                           0.72      2206\n",
      "   macro avg       0.72      0.72      0.72      2206\n",
      "weighted avg       0.72      0.72      0.72      2206\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(tpr <= tnr)[0]\n",
    "idx2 = np.where(tpr >= tnr)[0]\n",
    "t = thresholds[idx1[-1]]\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_pred = [], []\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "with torch.no_grad():\n",
    "    for (idx, batch) in enumerate(loader):\n",
    "        edges, features, node_layers, mappings, rows, labels = batch\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        out = model(features, node_layers, mappings, rows)\n",
    "        all_pairs = torch.mm(out, out.t())\n",
    "        scores = all_pairs[edges.T]\n",
    "        predictions = (scores >= t).long()\n",
    "        y_true.extend(labels.detach().cpu().numpy())\n",
    "        y_pred.extend(predictions.detach().cpu().numpy())\n",
    "        total_correct += torch.sum(predictions == labels.long()).item()\n",
    "        total_examples += len(labels) \n",
    "        print('    Batch {} / {}'.format(idx+1, num_batches))\n",
    "print('Threshold: {:.4f}, accuracy: {:.4f}'.format(t, total_correct / total_examples))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "print('Classification report\\n', report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: val\n",
      "Number of vertices: 151\n",
      "Number of static edges: 1681\n",
      "Number of temporal edges: 31354\n",
      "Number of examples/datapoints: 1364\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the validation dataset after training.\n",
      "    Batch 3 / 43: loss 0.6290, accuracy 0.6562\n",
      "    ROC-AUC score: 0.6270\n",
      "    Batch 6 / 43: loss 0.6333, accuracy 0.6979\n",
      "    ROC-AUC score: 0.7530\n",
      "    Batch 9 / 43: loss 0.6722, accuracy 0.6875\n",
      "    ROC-AUC score: 0.7922\n",
      "    Batch 12 / 43: loss 0.6669, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8268\n",
      "    Batch 15 / 43: loss 0.6511, accuracy 0.6667\n",
      "    ROC-AUC score: 0.8000\n",
      "    Batch 18 / 43: loss 0.6285, accuracy 0.7292\n",
      "    ROC-AUC score: 0.8125\n",
      "    Batch 21 / 43: loss 0.5686, accuracy 0.7812\n",
      "    ROC-AUC score: 0.8261\n",
      "    Batch 24 / 43: loss 0.6932, accuracy 0.6250\n",
      "    ROC-AUC score: 0.6235\n",
      "    Batch 27 / 43: loss 0.5595, accuracy 0.6875\n",
      "    ROC-AUC score: 0.6627\n",
      "    Batch 30 / 43: loss 0.5975, accuracy 0.7188\n",
      "    ROC-AUC score: 0.6409\n",
      "    Batch 33 / 43: loss 0.6287, accuracy 0.6146\n",
      "    ROC-AUC score: 0.7422\n",
      "    Batch 36 / 43: loss 0.6081, accuracy 0.7188\n",
      "    ROC-AUC score: 0.8588\n",
      "    Batch 39 / 43: loss 0.6272, accuracy 0.6771\n",
      "    ROC-AUC score: 0.6397\n",
      "    Batch 42 / 43: loss 0.5779, accuracy 0.7396\n",
      "    ROC-AUC score: 0.8045\n",
      "Loss 0.6235, accuracy 0.6935\n",
      "ROC-AUC score: 0.7578\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.65      0.68       682\n",
      "         1.0       0.68      0.74      0.71       682\n",
      "\n",
      "    accuracy                           0.69      1364\n",
      "   macro avg       0.70      0.69      0.69      1364\n",
      "weighted avg       0.70      0.69      0.69      1364\n",
      "\n",
      "Finished validating.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'val',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the validation dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().cpu().numpy())\n",
    "    y_scores.extend(scores.detach().cpu().numpy())\n",
    "    y_pred.extend(predictions.detach().cpu().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().cpu().numpy(), scores.detach().cpu().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished validating.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------\n",
      "Reading dataset from /Users/raunak/Documents/Datasets/temporal-networks-network-repository/ia-enron-employees/ia-enron-employees.edges\n",
      "Finished reading data.\n",
      "Setting up graph.\n",
      "Finished setting up graph.\n",
      "Setting up examples.\n",
      "Finished setting up examples.\n",
      "Dataset properties:\n",
      "Mode: test\n",
      "Number of vertices: 151\n",
      "Number of static edges: 1888\n",
      "Number of temporal edges: 37929\n",
      "Number of examples/datapoints: 1932\n",
      "--------------------------------\n",
      "--------------------------------\n",
      "Computing ROC-AUC score for the test dataset after training.\n",
      "    Batch 3 / 61: loss 0.6704, accuracy 0.6458\n",
      "    ROC-AUC score: 0.7490\n",
      "    Batch 6 / 61: loss 0.5386, accuracy 0.7708\n",
      "    ROC-AUC score: 0.7826\n",
      "    Batch 9 / 61: loss 0.5513, accuracy 0.6458\n",
      "    ROC-AUC score: 0.7136\n",
      "    Batch 12 / 61: loss 0.6796, accuracy 0.6875\n",
      "    ROC-AUC score: 0.6761\n",
      "    Batch 15 / 61: loss 0.6141, accuracy 0.6771\n",
      "    ROC-AUC score: 0.7578\n",
      "    Batch 18 / 61: loss 0.7235, accuracy 0.6458\n",
      "    ROC-AUC score: 0.8532\n",
      "    Batch 21 / 61: loss 0.6065, accuracy 0.7083\n",
      "    ROC-AUC score: 0.8968\n",
      "    Batch 24 / 61: loss 0.5859, accuracy 0.6979\n",
      "    ROC-AUC score: 0.7229\n",
      "    Batch 27 / 61: loss 0.6515, accuracy 0.7188\n",
      "    ROC-AUC score: 0.7383\n",
      "    Batch 30 / 61: loss 0.6918, accuracy 0.6250\n",
      "    ROC-AUC score: 0.6761\n",
      "    Batch 33 / 61: loss 0.7007, accuracy 0.5521\n",
      "    ROC-AUC score: 0.5977\n",
      "    Batch 36 / 61: loss 0.6481, accuracy 0.6458\n",
      "    ROC-AUC score: 0.6984\n",
      "    Batch 39 / 61: loss 0.5672, accuracy 0.6875\n",
      "    ROC-AUC score: 0.8392\n",
      "    Batch 42 / 61: loss 0.6036, accuracy 0.6667\n",
      "    ROC-AUC score: 0.8381\n",
      "    Batch 45 / 61: loss 0.6700, accuracy 0.6354\n",
      "    ROC-AUC score: 0.6588\n",
      "    Batch 48 / 61: loss 0.6676, accuracy 0.6667\n",
      "    ROC-AUC score: 0.6016\n",
      "    Batch 51 / 61: loss 0.6811, accuracy 0.5938\n",
      "    ROC-AUC score: 0.7059\n",
      "    Batch 54 / 61: loss 0.6249, accuracy 0.6354\n",
      "    ROC-AUC score: 0.7381\n",
      "    Batch 57 / 61: loss 0.6132, accuracy 0.6562\n",
      "    ROC-AUC score: 0.8203\n",
      "    Batch 60 / 61: loss 0.6808, accuracy 0.6562\n",
      "    ROC-AUC score: 0.7262\n",
      "Loss 0.6387, accuracy 0.6610\n",
      "ROC-AUC score: 0.7338\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.63      0.65       966\n",
      "         1.0       0.65      0.69      0.67       966\n",
      "\n",
      "    accuracy                           0.66      1932\n",
      "   macro avg       0.66      0.66      0.66      1932\n",
      "weighted avg       0.66      0.66      0.66      1932\n",
      "\n",
      "Finished testing.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "if config['load']:\n",
    "    directory = os.path.join(os.path.dirname(os.getcwd()),\n",
    "                             'trained_models')\n",
    "    fname = utils.get_fname(config)\n",
    "    path = os.path.join(directory, fname)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "dataset_args = (config['task'], config['dataset'], config['dataset_path'],\n",
    "                config['generate_neg_examples'], 'test',\n",
    "                config['duplicate_examples'], config['repeat_examples'],\n",
    "                config['num_layers'], config['self_loop'],\n",
    "                config['normalize_adj'])\n",
    "dataset = utils.get_dataset(dataset_args)\n",
    "loader = DataLoader(dataset=dataset, batch_size=config['batch_size'],\n",
    "                    shuffle=False, collate_fn=dataset.collate_wrapper)\n",
    "criterion = utils.get_criterion(config['task'])\n",
    "stats_per_batch = config['stats_per_batch']\n",
    "num_batches = int(ceil(len(dataset) / config['batch_size']))\n",
    "model.eval()\n",
    "print('--------------------------------')\n",
    "print('Computing ROC-AUC score for the test dataset after training.')\n",
    "running_loss, total_loss = 0.0, 0.0\n",
    "num_correct, num_examples = 0, 0\n",
    "total_correct, total_examples = 0, 0\n",
    "y_true, y_scores, y_pred = [], [], []\n",
    "for (idx, batch) in enumerate(loader):\n",
    "    edges, features, node_layers, mappings, rows, labels = batch\n",
    "    features, labels = features.to(device), labels.to(device)\n",
    "    out = model(features, node_layers, mappings, rows)\n",
    "    all_pairs = torch.mm(out, out.t())\n",
    "    scores = all_pairs[edges.T]\n",
    "    loss = criterion(scores, labels.float())\n",
    "    running_loss += loss.item()\n",
    "    total_loss += loss.item()\n",
    "    predictions = (scores >= t).long()\n",
    "    num_correct += torch.sum(predictions == labels.long()).item()\n",
    "    total_correct += torch.sum(predictions == labels.long()).item()\n",
    "    num_examples += len(labels)\n",
    "    total_examples += len(labels)\n",
    "    y_true.extend(labels.detach().cpu().numpy())\n",
    "    y_scores.extend(scores.detach().cpu().numpy())\n",
    "    y_pred.extend(predictions.detach().cpu().numpy())\n",
    "    if (idx + 1) % stats_per_batch == 0:\n",
    "        running_loss /= stats_per_batch\n",
    "        accuracy = num_correct / num_examples\n",
    "        print('    Batch {} / {}: loss {:.4f}, accuracy {:.4f}'.format(\n",
    "            idx+1, num_batches, running_loss, accuracy))\n",
    "        if (torch.sum(labels.long() == 0).item() > 0) and (torch.sum(labels.long() == 1).item() > 0):\n",
    "            area = roc_auc_score(labels.detach().cpu().numpy(), scores.detach().cpu().numpy())\n",
    "            print('    ROC-AUC score: {:.4f}'.format(area))\n",
    "        running_loss = 0.0\n",
    "        num_correct, num_examples = 0, 0\n",
    "total_loss /= num_batches\n",
    "total_accuracy = total_correct / total_examples\n",
    "print('Loss {:.4f}, accuracy {:.4f}'.format(total_loss, total_accuracy))\n",
    "y_true = np.array(y_true).flatten()\n",
    "y_scores = np.array(y_scores).flatten()\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "report = classification_report(y_true, y_pred)\n",
    "area = roc_auc_score(y_true, y_scores)\n",
    "print('ROC-AUC score: {:.4f}'.format(area))\n",
    "print('Classification report\\n', report)\n",
    "print('Finished testing.')\n",
    "print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
